{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unified STT Notebook\n",
    "\n",
    "**Single notebook for all Speech-to-Text models**\n",
    "\n",
    "This notebook provides a unified interface for:\n",
    "- **STT Models**: Whisper (tiny, base, small, medium, large), Faster-Whisper (optimized)\n",
    "- **Input Formats**: Audio files (MP3, WAV, M4A, FLAC, OGG) and Video files (MP4, MOV, AVI, MKV, etc.)\n",
    "- **Output Formats**: Text transcripts, SRT subtitles, VTT captions, JSON with timestamps\n",
    "\n",
    "The notebook will automatically install only the dependencies you need based on your selections!\n",
    "\n",
    "‚úÖ **Works both locally and in Google Colab** - automatically detects environment and downloads required files.\n",
    "\n",
    "üé¨ **Video Support**: Automatically extracts audio from video files (requires ffmpeg)\n",
    "\n",
    "ü§ñ **Smart Defaults**: \n",
    "- **Colab**: Uses `faster-whisper-medium` (best quality, leverages GPU)\n",
    "- **Local/Mac**: Uses `faster-whisper-base` (fast on CPU, good quality)\n",
    "- You can override the model in the configuration section!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0a) Environment Detection & Setup\n",
    "\n",
    "**This cell automatically detects if you're running in Google Colab or locally.**\n",
    "\n",
    "If in Colab, it will download the required Python modules from the GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Detect if running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"üåê Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"üíª Running locally\")\n",
    "\n",
    "# GitHub repository URL for downloading Python modules\n",
    "GITHUB_RAW_URL = \"https://raw.githubusercontent.com/SVM0N/ttsweb.github.io/main/\"\n",
    "\n",
    "# Required Python modules (in tts_lib folder - shared with TTS notebook)\n",
    "REQUIRED_MODULES = [\n",
    "    \"tts_lib/__init__.py\",\n",
    "    \"tts_lib/config.py\",\n",
    "    \"tts_lib/stt_backends.py\",\n",
    "    \"tts_lib/output_formatters.py\",\n",
    "    \"tts_lib/stt_setup.py\",\n",
    "    \"tts_lib/init_system_stt.py\",\n",
    "    \"tts_lib/stt_examples.py\",\n",
    "    \"tts_lib/cleanup.py\"\n",
    "]\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"\\nüì¶ Setting up Colab environment...\")\n",
    "    print(\"   Downloading required Python modules from GitHub...\")\n",
    "    \n",
    "    import urllib.request\n",
    "    \n",
    "    # Create tts_lib directory\n",
    "    Path(\"tts_lib\").mkdir(exist_ok=True)\n",
    "    \n",
    "    for module in REQUIRED_MODULES:\n",
    "        url = GITHUB_RAW_URL + module\n",
    "        try:\n",
    "            print(f\"   ‚Üí Downloading {module}...\")\n",
    "            urllib.request.urlretrieve(url, module)\n",
    "            print(f\"   ‚úì {module} downloaded\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚úó Failed to download {module}: {e}\")\n",
    "            print(f\"     URL: {url}\")\n",
    "    \n",
    "    # Create files directory for outputs\n",
    "    files_dir = Path(\"files\")\n",
    "    files_dir.mkdir(exist_ok=True)\n",
    "    print(f\"\\n‚úì Created output directory: {files_dir}\")\n",
    "    \n",
    "    # Install ffmpeg for audio processing\n",
    "    print(\"\\nüì¶ Installing system dependencies for audio processing...\")\n",
    "    get_ipython().system('apt-get update -qq')\n",
    "    get_ipython().system('apt-get install -y -qq ffmpeg')\n",
    "    print(\"   ‚úì FFmpeg installed\")\n",
    "    \n",
    "    print(\"\\n‚úì Colab environment setup complete!\")\n",
    "    print(\"  You can now proceed with the rest of the notebook.\")\n",
    "    print(\"\\nüìù Note: To upload audio files, use the file upload button in the sidebar\")\n",
    "    print(\"  or run: from google.colab import files; uploaded = files.upload()\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚úì Local environment detected\")\n",
    "    print(\"  Using local Python modules\")\n",
    "    \n",
    "    # Check if required modules exist locally\n",
    "    missing_modules = []\n",
    "    for module in REQUIRED_MODULES:\n",
    "        if not Path(module).exists():\n",
    "            missing_modules.append(module)\n",
    "    \n",
    "    if missing_modules:\n",
    "        print(f\"\\n‚ö†Ô∏è  Warning: Missing modules: {', '.join(missing_modules)}\")\n",
    "        print(\"  Make sure you're running this notebook from the repository directory\")\n",
    "    else:\n",
    "        print(f\"  ‚úì All required modules found\")\n",
    "    \n",
    "    # Check for ffmpeg on local system\n",
    "    import platform\n",
    "    import subprocess\n",
    "    try:\n",
    "        subprocess.run(['ffmpeg', '-version'], capture_output=True, check=True)\n",
    "        print(\"\\n‚úì FFmpeg detected\")\n",
    "    except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "        print(\"\\n‚ö†Ô∏è  FFmpeg not found. For audio processing:\")\n",
    "        if platform.system() == \"Darwin\":\n",
    "            print(\"   Run: brew install ffmpeg\")\n",
    "        elif platform.system() == \"Linux\":\n",
    "            print(\"   Run: sudo apt-get install ffmpeg\")\n",
    "        else:\n",
    "            print(\"   Download from: https://ffmpeg.org/\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0b) Conda Environment Setup (Optional - Local Only)\n",
    "\n",
    "**This step helps you manage Python packages and avoid conflicts with your system installation.**\n",
    "\n",
    "- If you have **conda** installed, you can create a fresh environment for this notebook\n",
    "- Or use an existing environment by providing its name\n",
    "- At the end of the notebook, you can easily clean up and delete the environment to free storage\n",
    "- **Note**: This section is only relevant for local installations, not Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tts_lib.cleanup import interactive_conda_setup\n",
    "\n",
    "# Run interactive conda environment setup\n",
    "environment_created_by_notebook, environment_name = interactive_conda_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Configuration - Choose Your Setup\n",
    "\n",
    "**Select which STT model and output formats you want to use.**\n",
    "\n",
    "The notebook automatically chooses the best model for your environment:\n",
    "- **Colab**: `faster-whisper-medium` (best quality, uses GPU)  \n",
    "- **Local**: `faster-whisper-base` (fast, good quality, CPU-optimized)\n",
    "\n",
    "You can override this by setting `STT_MODEL` manually in the cell below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# AUDIO/VIDEO FILE CONFIGURATION\n",
    "# ========================================\n",
    "# Path to your audio or video file to transcribe\n",
    "# Supports audio: MP3, WAV, M4A, FLAC, OGG, etc.\n",
    "# Supports video: MP4, MOV, AVI, MKV, WebM, etc. (audio will be extracted)\n",
    "AUDIO_PATH = \"files/audio.mp3\"\n",
    "\n",
    "# ========================================\n",
    "# STT MODEL SELECTION\n",
    "# ========================================\n",
    "# Smart defaults based on environment:\n",
    "#   - Colab (with GPU): faster-whisper-medium (best quality, leverages GPU)\n",
    "#   - Local runtime: faster-whisper-base (fast, good quality, runs on CPU/Mac)\n",
    "#\n",
    "# You can override by uncommenting and setting STT_MODEL manually:\n",
    "# STT_MODEL = \"faster-whisper-small\"\n",
    "\n",
    "# Auto-select model based on environment\n",
    "if 'STT_MODEL' not in locals():\n",
    "    if IN_COLAB:\n",
    "        # Colab has more resources (often GPU), use better model\n",
    "        STT_MODEL = \"faster-whisper-medium\"\n",
    "        print(\"üåê Colab detected: Using faster-whisper-medium (best quality)\")\n",
    "    else:\n",
    "        # Local runtime: optimize for speed on CPU/Mac\n",
    "        STT_MODEL = \"faster-whisper-base\"\n",
    "        print(\"üíª Local detected: Using faster-whisper-base (fast, good quality)\")\n",
    "\n",
    "# Available models (change STT_MODEL above to use):\n",
    "#   - \"whisper-tiny\": Fastest, least accurate (~75MB, ~1GB RAM)\n",
    "#   - \"whisper-base\": Fast, decent accuracy (~150MB, ~1GB RAM)\n",
    "#   - \"whisper-small\": Balanced speed/accuracy (~500MB, ~2GB RAM)\n",
    "#   - \"whisper-medium\": Good accuracy, slower (~1.5GB, ~5GB RAM)\n",
    "#   - \"whisper-large\": Best accuracy, slowest (~3GB, ~10GB RAM)\n",
    "#   - \"faster-whisper-tiny\": Optimized tiny (4x faster)\n",
    "#   - \"faster-whisper-base\": Optimized base (4x faster) ‚≠ê DEFAULT for LOCAL\n",
    "#   - \"faster-whisper-small\": Optimized small (4x faster)\n",
    "#   - \"faster-whisper-medium\": Optimized medium (4x faster) ‚≠ê DEFAULT for COLAB\n",
    "#   - \"faster-whisper-large\": Optimized large (4x faster, needs 10GB RAM)\n",
    "\n",
    "# ========================================\n",
    "# TRANSCRIPTION OPTIONS\n",
    "# ========================================\n",
    "# Language code (None = auto-detect, or use \"en\", \"es\", \"fr\", \"de\", etc.)\n",
    "LANGUAGE = None\n",
    "\n",
    "# Task type: \"transcribe\" or \"translate\" (translate converts to English)\n",
    "TASK = \"transcribe\"\n",
    "\n",
    "# ========================================\n",
    "# OUTPUT FORMATS\n",
    "# ========================================\n",
    "# Select which output formats to generate (can select multiple):\n",
    "OUTPUT_FORMATS = {\n",
    "    \"txt\": True,      # Plain text transcript\n",
    "    \"srt\": True,      # SRT subtitle format\n",
    "    \"vtt\": True,      # WebVTT caption format\n",
    "    \"json\": True,     # JSON with word-level timestamps\n",
    "}\n",
    "\n",
    "# ========================================\n",
    "# DEVICE CONFIGURATION\n",
    "# ========================================\n",
    "# Device to use for STT transcription:\n",
    "#   - \"auto\": Automatically select best device (CUDA > MPS > CPU)\n",
    "#   - \"cuda\": Force CUDA/GPU\n",
    "#   - \"cpu\": Force CPU\n",
    "#   - \"mps\": Force Apple Silicon MPS (not supported by faster-whisper)\n",
    "\n",
    "DEVICE = \"auto\"\n",
    "\n",
    "# ========================================\n",
    "# OUTPUT DIRECTORY\n",
    "# ========================================\n",
    "# Directory where transcripts will be saved\n",
    "OUTPUT_DIR = \"files\"\n",
    "\n",
    "# ========================================\n",
    "# VALIDATION\n",
    "# ========================================\n",
    "if not Path(AUDIO_PATH).exists():\n",
    "    print(f\"‚ö†Ô∏è  WARNING: Audio/video file not found: {AUDIO_PATH}\")\n",
    "    print(\"   Please upload a file or update AUDIO_PATH\")\n",
    "\n",
    "if \"faster-whisper\" in STT_MODEL and DEVICE == \"mps\":\n",
    "    print(\"‚ö†Ô∏è  WARNING: Faster-Whisper does not support MPS (Apple Silicon GPU)\")\n",
    "    print(\"   Will fall back to CPU. Use regular Whisper models for MPS support.\")\n",
    "\n",
    "if not any(OUTPUT_FORMATS.values()):\n",
    "    print(\"‚ö†Ô∏è  WARNING: No output formats selected!\")\n",
    "    print(\"   At least one output format should be enabled\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CONFIGURATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Environment: {'Google Colab' if IN_COLAB else 'Local Runtime'}\")\n",
    "print(f\"Audio/Video File: {AUDIO_PATH}\")\n",
    "print(f\"STT Model: {STT_MODEL}\")\n",
    "print(f\"Language: {LANGUAGE or 'Auto-detect'}\")\n",
    "print(f\"Task: {TASK}\")\n",
    "print(f\"Output Formats: {', '.join([fmt.upper() for fmt, enabled in OUTPUT_FORMATS.items() if enabled])}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5) Apple Silicon (MPS) Fix\n",
    "\n",
    "**Automatically detect and fix Apple Silicon compatibility issues.**\n",
    "\n",
    "If you're on Apple Silicon, this will enable CPU fallback for unsupported operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "# Check if we're on macOS with Apple Silicon\n",
    "is_apple_silicon = (\n",
    "    platform.system() == \"Darwin\" and \n",
    "    platform.machine() == \"arm64\"\n",
    ")\n",
    "\n",
    "if is_apple_silicon:\n",
    "    print(\"üçé Apple Silicon detected\")\n",
    "    print(\"   Enabling MPS fallback for unsupported operations...\")\n",
    "    \n",
    "    # Set environment variable to enable CPU fallback for unsupported MPS operations\n",
    "    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "    \n",
    "    print(\"   ‚úì MPS fallback enabled\")\n",
    "    print(\"   Note: Some operations will fall back to CPU (slightly slower but works)\")\n",
    "else:\n",
    "    print(\"‚úì No Apple Silicon-specific fixes needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Install Dependencies\n",
    "\n",
    "**Running automatic dependency installation...**\n",
    "\n",
    "This will install only what you need based on your configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tts_lib.stt_setup import install_dependencies\n",
    "\n",
    "# Install dependencies based on configuration\n",
    "install_dependencies(\n",
    "    stt_model=STT_MODEL,\n",
    "    output_formats=OUTPUT_FORMATS\n",
    ")\n",
    "\n",
    "print(\"\\nüöÄ Ready to initialize system!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Initialize STT System\n",
    "\n",
    "**Loading STT model...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tts_lib.init_system_stt import initialize_system\n",
    "\n",
    "# Initialize STT backend and config\n",
    "stt, config = initialize_system(\n",
    "    stt_model=STT_MODEL,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    device=DEVICE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Run Transcription\n",
    "\n",
    "Transcribe the audio file and generate output files in selected formats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tts_lib.stt_examples import run_transcription\n",
    "\n",
    "# Run the transcription\n",
    "result = run_transcription(\n",
    "    stt=stt,\n",
    "    config=config,\n",
    "    audio_path=AUDIO_PATH,\n",
    "    output_formats=OUTPUT_FORMATS,\n",
    "    language=LANGUAGE,\n",
    "    task=TASK\n",
    ")\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRANSCRIPTION COMPLETE\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTranscript Preview:\")\n",
    "print(\"-\" * 60)\n",
    "print(result['text'][:500] + (\"...\" if len(result['text']) > 500 else \"\"))\n",
    "print(\"-\" * 60)\n",
    "print(f\"\\nGenerated Files:\")\n",
    "for file_path in result['output_files']:\n",
    "    print(f\"  ‚úì {file_path}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Optional Cleanup Sections\n",
    "\n",
    "The following sections help you manage storage and environments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5a) Delete Conda Environment (Optional)\n",
    "\n",
    "If you created a new environment at the beginning of this notebook, you can delete it here to free up storage space.\n",
    "\n",
    "‚ö†Ô∏è **Warning**: This will permanently delete the environment and all installed packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tts_lib.cleanup import delete_conda_environment\n",
    "\n",
    "# Delete conda environment if created by this notebook\n",
    "if 'environment_created_by_notebook' not in globals():\n",
    "    print(\"‚úó No environment tracking found\")\n",
    "    print(\"This cell only works if you ran the environment setup cell at the beginning\")\n",
    "else:\n",
    "    success, environment_created_by_notebook, environment_name = delete_conda_environment(\n",
    "        environment_name, \n",
    "        environment_created_by_notebook\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5b) Delete Model Caches (Optional)\n",
    "\n",
    "Delete downloaded models and caches to free up disk space.\n",
    "\n",
    "‚ö†Ô∏è **Warning**: Models will need to be re-downloaded if you run the notebook again!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tts_lib.cleanup import interactive_cache_cleanup\n",
    "\n",
    "# Run interactive cache cleanup\n",
    "interactive_cache_cleanup()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
