{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unified TTS Notebook\n",
    "\n",
    "**Single notebook for all TTS models and PDF extraction strategies**\n",
    "\n",
    "This notebook provides a unified interface for:\n",
    "- **TTS Models**: Kokoro (v0.9, v1.0), Silero v5\n",
    "- **PDF Extractors**: Unstructured, PyMuPDF, Apple Vision, Nougat\n",
    "- **Input Formats**: Text strings, PDF files, EPUB books\n",
    "- **Output Formats**: WAV, MP3 with timeline manifests\n",
    "\n",
    "The notebook will automatically install only the dependencies you need based on your selections!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0) Environment Setup (Optional)\n",
    "\n",
    "**This step helps you manage Python packages and avoid conflicts with your system installation.**\n",
    "\n",
    "- If you have **conda** installed, you can create a fresh environment for this notebook\n",
    "- Or use an existing environment by providing its name\n",
    "- At the end of the notebook, you can easily clean up and delete the environment to free storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Flag to track if we created an environment in this notebook\n",
    "environment_created_by_notebook = False\n",
    "environment_name = None\n",
    "\n",
    "# Check if conda is installed\n",
    "try:\n",
    "    result = subprocess.run(['conda', '--version'], capture_output=True, text=True, check=True)\n",
    "    conda_available = True\n",
    "    print(f\"âœ“ Conda detected: {result.stdout.strip()}\")\n",
    "except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "    conda_available = False\n",
    "    print(\"âœ— Conda not found - skipping environment management\")\n",
    "    print(\"Packages will be installed in your current Python environment\")\n",
    "\n",
    "if conda_available:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ENVIRONMENT SETUP OPTIONS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    choice = input(\"\\nDo you want to:\\n  [1] Create a NEW conda environment (recommended)\\n  [2] Use an EXISTING environment\\n  [3] Skip and use current environment\\n\\nEnter choice (1/2/3): \").strip()\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        env_name = input(\"\\nEnter name for new environment (default: tts_unified): \").strip()\n",
    "        if not env_name:\n",
    "            env_name = \"tts_unified\"\n",
    "        \n",
    "        print(f\"\\nâ†’ Creating conda environment: {env_name}\")\n",
    "        print(\"  This may take a few minutes...\")\n",
    "        \n",
    "        try:\n",
    "            subprocess.run(['conda', 'create', '-n', env_name, 'python=3.10', '-y'],\n",
    "                           check=True, capture_output=True)\n",
    "            \n",
    "            environment_created_by_notebook = True\n",
    "            environment_name = env_name\n",
    "            \n",
    "            print(f\"âœ“ Environment '{env_name}' created successfully!\")\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(\"IMPORTANT: Restart your Jupyter kernel and select the new environment:\")\n",
    "            print(f\"  Kernel â†’ Change Kernel â†’ {env_name}\")\n",
    "            print(f\"{'='*60}\\n\")\n",
    "            \n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"âœ— Failed to create environment: {e}\")\n",
    "            print(\"Continuing with current environment...\")\n",
    "    \n",
    "    elif choice == \"2\":\n",
    "        env_name = input(\"\\nEnter name of existing environment: \").strip()\n",
    "        if env_name:\n",
    "            environment_name = env_name\n",
    "            print(f\"\\nâœ“ Using existing environment: {env_name}\")\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(\"IMPORTANT: Make sure your kernel is using this environment:\")\n",
    "            print(f\"  Kernel â†’ Change Kernel â†’ {env_name}\")\n",
    "            print(f\"{'='*60}\\n\")\n",
    "        else:\n",
    "            print(\"âœ— No environment name provided - using current environment\")\n",
    "    \n",
    "    else:\n",
    "        print(\"\\nâœ“ Using current environment\")\n",
    "\n",
    "print(\"\\nYou can now proceed with the rest of the notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Configuration - Choose Your Setup\n",
    "\n",
    "**Select which TTS model, PDF extractor, and formats you want to use.**\n",
    "\n",
    "The notebook will automatically install only the dependencies you need!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CONFIGURATION SUMMARY\n",
      "============================================================\n",
      "TTS Model: kokoro_1.0\n",
      "PDF Extractor: unstructured\n",
      "Input Formats: Text=False, PDF=True, EPUB=False\n",
      "Output Formats: WAV=False, MP3=True\n",
      "Device: auto\n",
      "Output Directory: .\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# TTS MODEL SELECTION\n",
    "# ========================================\n",
    "# Choose ONE of the following:\n",
    "#   - \"kokoro_0.9\": Kokoro v0.9+ (10 voices, English-focused, stable)\n",
    "#   - \"kokoro_1.0\": Kokoro v1.0 (54 voices, 8 languages, latest)\n",
    "#   - \"silero_v5\": Silero v5 (Russian language, 6 speakers)\n",
    "\n",
    "TTS_MODEL = \"kokoro_1.0\"\n",
    "\n",
    "# ========================================\n",
    "# PDF EXTRACTOR SELECTION\n",
    "# ========================================\n",
    "# Choose ONE of the following:\n",
    "#   - \"unstructured\": Advanced layout analysis (recommended, ~500MB dependencies)\n",
    "#   - \"pymupdf\": Fast extraction for clean PDFs (~15MB, lightweight)\n",
    "#   - \"vision\": OCR for scanned PDFs (macOS only)\n",
    "#   - \"nougat\": Academic papers with equations (~1.5GB model)\n",
    "#   - None: Skip PDF extraction (only for text/EPUB input)\n",
    "\n",
    "PDF_EXTRACTOR = \"unstructured\"\n",
    "\n",
    "# ========================================\n",
    "# INPUT FORMATS\n",
    "# ========================================\n",
    "# Enable the input formats you plan to use:\n",
    "\n",
    "ENABLE_TEXT_INPUT = False    # Plain text strings\n",
    "ENABLE_PDF_INPUT = True     # PDF files (requires PDF_EXTRACTOR)\n",
    "ENABLE_EPUB_INPUT = False    # EPUB books\n",
    "\n",
    "# ========================================\n",
    "# OUTPUT FORMATS\n",
    "# ========================================\n",
    "# Enable the output formats you plan to use:\n",
    "\n",
    "ENABLE_WAV_OUTPUT = False    # WAV audio files\n",
    "ENABLE_MP3_OUTPUT = True    # MP3 audio files (requires ffmpeg and pydub)\n",
    "\n",
    "# ========================================\n",
    "# DEVICE CONFIGURATION\n",
    "# ========================================\n",
    "# Device to use for TTS synthesis:\n",
    "#   - \"auto\": Automatically select best device (CUDA > MPS > CPU)\n",
    "#   - \"cuda\": Force CUDA/GPU\n",
    "#   - \"cpu\": Force CPU\n",
    "#   - \"mps\": Force Apple Silicon MPS\n",
    "\n",
    "DEVICE = \"auto\"\n",
    "\n",
    "# ========================================\n",
    "# OUTPUT DIRECTORY\n",
    "# ========================================\n",
    "# Directory where generated files will be saved\n",
    "\n",
    "OUTPUT_DIR = \".\"  # Current directory\n",
    "\n",
    "# ========================================\n",
    "# VALIDATION\n",
    "# ========================================\n",
    "if ENABLE_PDF_INPUT and PDF_EXTRACTOR is None:\n",
    "    print(\"âš ï¸  WARNING: PDF input enabled but no PDF extractor selected!\")\n",
    "    print(\"   Set PDF_EXTRACTOR to 'unstructured', 'pymupdf', 'vision', or 'nougat'\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CONFIGURATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"TTS Model: {TTS_MODEL}\")\n",
    "print(f\"PDF Extractor: {PDF_EXTRACTOR or 'None'}\")\n",
    "print(f\"Input Formats: Text={ENABLE_TEXT_INPUT}, PDF={ENABLE_PDF_INPUT}, EPUB={ENABLE_EPUB_INPUT}\")\n",
    "print(f\"Output Formats: WAV={ENABLE_WAV_OUTPUT}, MP3={ENABLE_MP3_OUTPUT}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "source": "import os\nimport platform\n\n# Check if we're on macOS with Apple Silicon\nis_apple_silicon = (\n    platform.system() == \"Darwin\" and \n    platform.machine() == \"arm64\"\n)\n\nif is_apple_silicon:\n    print(\"ðŸŽ Apple Silicon detected\")\n    print(\"   Enabling MPS fallback for unsupported operations...\")\n    \n    # Set environment variable to enable CPU fallback for unsupported MPS operations\n    # This fixes the 'aten::angle not implemented for MPS' error\n    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n    \n    print(\"   âœ“ MPS fallback enabled\")\n    print(\"   Note: Some operations will fall back to CPU (slightly slower but works)\")\nelse:\n    print(\"âœ“ No Apple Silicon-specific fixes needed\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 1.5) Apple Silicon (MPS) Fix\n\n**Automatically detect and fix Apple Silicon compatibility issues.**\n\nIf you're on Apple Silicon, this will enable CPU fallback for unsupported operations.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Install & Import Dependencies\n",
    "\n",
    "**This cell will automatically install and import only the packages you need based on your configuration above.**\n",
    "\n",
    "This may take a few minutes on first run, but subsequent runs will be faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "INSTALLING DEPENDENCIES\n",
      "============================================================\n",
      "\n",
      "ðŸ“¦ Installing core dependencies...\n",
      "âœ“ torch already installed\n",
      "âœ“ soundfile already installed\n",
      "âœ“ numpy already installed\n",
      "\n",
      "ðŸŽ¤ Installing TTS model dependencies...\n",
      "âœ“ Kokoro already installed\n",
      "\n",
      "ðŸ“„ Installing PDF extractor dependencies...\n",
      "âœ“ unstructured already installed\n",
      "âœ“ detectron2 already installed\n",
      "\n",
      "ðŸŽµ Installing MP3 output dependencies...\n",
      "âœ“ pydub already installed\n",
      "\n",
      "âš ï¸  NOTE: MP3 encoding requires ffmpeg to be installed on your system:\n",
      "   - macOS: brew install ffmpeg\n",
      "   - Linux: sudo apt-get install ffmpeg\n",
      "   - Windows: Download from https://ffmpeg.org/\n",
      "\n",
      "============================================================\n",
      "âœ“ ALL DEPENDENCIES INSTALLED\n",
      "============================================================\n",
      "\n",
      "ðŸ“¥ Importing modules...\n",
      "Logging configured (level: ERROR for noisy libraries)\n",
      "âœ“ Modules imported successfully\n",
      "\n",
      "ðŸš€ Ready to synthesize!\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package using pip.\"\"\"\n",
    "    print(f\"Installing {package}...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "    print(f\"âœ“ {package} installed\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"INSTALLING DEPENDENCIES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Core dependencies (always needed)\n",
    "print(\"\\nðŸ“¦ Installing core dependencies...\")\n",
    "core_packages = [\"torch\", \"soundfile\", \"numpy\"]\n",
    "for pkg in core_packages:\n",
    "    try:\n",
    "        __import__(pkg.replace(\"-\", \"_\"))\n",
    "        print(f\"âœ“ {pkg} already installed\")\n",
    "    except ImportError:\n",
    "        install_package(pkg)\n",
    "\n",
    "# TTS model dependencies\n",
    "print(\"\\nðŸŽ¤ Installing TTS model dependencies...\")\n",
    "if TTS_MODEL.startswith(\"kokoro\"):\n",
    "    kokoro_packages = [\"kokoro>=0.9.4\", \"misaki[en]\"]\n",
    "    for pkg in kokoro_packages:\n",
    "        try:\n",
    "            __import__(\"kokoro\")\n",
    "            print(f\"âœ“ Kokoro already installed\")\n",
    "            break\n",
    "        except ImportError:\n",
    "            install_package(pkg)\n",
    "elif TTS_MODEL == \"silero_v5\":\n",
    "    try:\n",
    "        __import__(\"omegaconf\")\n",
    "        print(f\"âœ“ omegaconf already installed\")\n",
    "    except ImportError:\n",
    "        install_package(\"omegaconf\")\n",
    "    print(\"âœ“ Silero loads via torch.hub (no additional packages needed)\")\n",
    "\n",
    "# PDF extractor dependencies\n",
    "if ENABLE_PDF_INPUT and PDF_EXTRACTOR:\n",
    "    print(\"\\nðŸ“„ Installing PDF extractor dependencies...\")\n",
    "    \n",
    "    if PDF_EXTRACTOR == \"unstructured\":\n",
    "        unstructured_packages = [\n",
    "            \"unstructured[local-inference]\",\n",
    "            \"detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2\"\n",
    "        ]\n",
    "        for pkg in unstructured_packages:\n",
    "            try:\n",
    "                if \"detectron2\" in pkg:\n",
    "                    __import__(\"detectron2\")\n",
    "                    print(f\"âœ“ detectron2 already installed\")\n",
    "                else:\n",
    "                    __import__(\"unstructured\")\n",
    "                    print(f\"âœ“ unstructured already installed\")\n",
    "            except ImportError:\n",
    "                install_package(pkg)\n",
    "    \n",
    "    elif PDF_EXTRACTOR == \"pymupdf\":\n",
    "        try:\n",
    "            __import__(\"fitz\")\n",
    "            print(f\"âœ“ pymupdf already installed\")\n",
    "        except ImportError:\n",
    "            install_package(\"pymupdf\")\n",
    "    \n",
    "    elif PDF_EXTRACTOR == \"vision\":\n",
    "        import platform\n",
    "        if platform.system() != \"Darwin\":\n",
    "            print(\"âš ï¸  WARNING: Vision Framework is only available on macOS!\")\n",
    "        else:\n",
    "            vision_packages = [\"pyobjc-framework-Vision\", \"pyobjc-framework-Quartz\"]\n",
    "            for pkg in vision_packages:\n",
    "                try:\n",
    "                    module_name = pkg.replace(\"-\", \"_\").replace(\"pyobjc_framework_\", \"\")\n",
    "                    __import__(module_name)\n",
    "                    print(f\"âœ“ {pkg} already installed\")\n",
    "                except ImportError:\n",
    "                    install_package(pkg)\n",
    "    \n",
    "    elif PDF_EXTRACTOR == \"nougat\":\n",
    "        nougat_packages = [\"nougat-ocr\", \"transformers\"]\n",
    "        for pkg in nougat_packages:\n",
    "            try:\n",
    "                __import__(pkg.replace(\"-\", \"_\"))\n",
    "                print(f\"âœ“ {pkg} already installed\")\n",
    "            except ImportError:\n",
    "                install_package(pkg)\n",
    "\n",
    "# EPUB dependencies\n",
    "if ENABLE_EPUB_INPUT:\n",
    "    print(\"\\nðŸ“š Installing EPUB dependencies...\")\n",
    "    try:\n",
    "        __import__(\"ebooklib\")\n",
    "        print(f\"âœ“ ebooklib already installed\")\n",
    "    except ImportError:\n",
    "        install_package(\"ebooklib\")\n",
    "\n",
    "# MP3 output dependencies\n",
    "if ENABLE_MP3_OUTPUT:\n",
    "    print(\"\\nðŸŽµ Installing MP3 output dependencies...\")\n",
    "    try:\n",
    "        __import__(\"pydub\")\n",
    "        print(f\"âœ“ pydub already installed\")\n",
    "    except ImportError:\n",
    "        install_package(\"pydub\")\n",
    "    print(\"\\nâš ï¸  NOTE: MP3 encoding requires ffmpeg to be installed on your system:\")\n",
    "    print(\"   - macOS: brew install ffmpeg\")\n",
    "    print(\"   - Linux: sudo apt-get install ffmpeg\")\n",
    "    print(\"   - Windows: Download from https://ffmpeg.org/\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"âœ“ ALL DEPENDENCIES INSTALLED\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Now import the modules\n",
    "print(\"\\nðŸ“¥ Importing modules...\")\n",
    "\n",
    "import io\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Import our modular components\n",
    "from config import TTSConfig, print_device_info, setup_logging\n",
    "from tts_backends import create_backend\n",
    "from tts_utils import wav_to_mp3_bytes, safe_name\n",
    "from manifest import create_manifest, save_manifest\n",
    "\n",
    "# Import PDF extractor if needed\n",
    "if ENABLE_PDF_INPUT and PDF_EXTRACTOR:\n",
    "    from pdf_extractors import get_available_extractors\n",
    "\n",
    "# Import EPUB utilities if needed\n",
    "if ENABLE_EPUB_INPUT:\n",
    "    from tts_utils import extract_chapters_from_epub\n",
    "\n",
    "# Set up logging to reduce noise\n",
    "setup_logging()\n",
    "\n",
    "print(\"âœ“ Modules imported successfully\")\n",
    "print(\"\\nðŸš€ Ready to synthesize!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Initialize TTS System\n",
    "\n",
    "Load the TTS model and PDF extractor based on your configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DEVICE INFORMATION\n",
      "============================================================\n",
      "CPU: Available\n",
      "CUDA: Not available\n",
      "MPS (Apple Silicon): Available\n",
      "============================================================\n",
      "Recommended device: MPS (Apple Silicon acceleration)\n",
      "============================================================\n",
      "Output directory: /Users/simon/Documents/GitHub/ttsweb.github.io\n",
      "Using device: mps\n",
      "\n",
      "TTSConfig(output_dir=/Users/simon/Documents/GitHub/ttsweb.github.io, device=mps)\n",
      "\n",
      "ðŸ“¥ Loading TTS backend: kokoro_1.0...\n",
      "Initializing Kokoro 1.0 backend on mps...\n",
      "âœ“ TTS backend loaded: Kokoro v1.0\n",
      "  Available voices: ['af_heart', 'af_bella', 'af_sarah', 'af_nicole', 'af_sky']...\n",
      "  Default voice: af_heart\n",
      "  Sample rate: 24000 Hz\n",
      "\n",
      "ðŸ“¥ Loading PDF extractor: unstructured...\n",
      "âœ“ PDF extractor loaded: Unstructured (Advanced)\n",
      "  Description: Advanced layout analysis with coordinate extraction. Best for general use.\n",
      "\n",
      "âœ“ System initialized and ready!\n"
     ]
    }
   ],
   "source": [
    "# Print available devices\n",
    "print_device_info()\n",
    "\n",
    "# Create configuration\n",
    "config = TTSConfig(output_dir=OUTPUT_DIR, device=DEVICE)\n",
    "print(f\"\\n{config}\")\n",
    "\n",
    "# Load TTS backend\n",
    "print(f\"\\nðŸ“¥ Loading TTS backend: {TTS_MODEL}...\")\n",
    "tts = create_backend(TTS_MODEL, device=config.device)\n",
    "print(f\"âœ“ TTS backend loaded: {tts.get_name()}\")\n",
    "print(f\"  Available voices: {tts.get_available_voices()[:5]}...\")  # Show first 5\n",
    "print(f\"  Default voice: {tts.get_default_voice()}\")\n",
    "print(f\"  Sample rate: {tts.get_sample_rate()} Hz\")\n",
    "\n",
    "# Load PDF extractor if needed\n",
    "if ENABLE_PDF_INPUT and PDF_EXTRACTOR:\n",
    "    print(f\"\\nðŸ“¥ Loading PDF extractor: {PDF_EXTRACTOR}...\")\n",
    "    extractors = get_available_extractors()\n",
    "    pdf_extractor = extractors[PDF_EXTRACTOR]\n",
    "    print(f\"âœ“ PDF extractor loaded: {pdf_extractor.get_name()}\")\n",
    "    print(f\"  Description: {pdf_extractor.get_description()}\")\n",
    "else:\n",
    "    pdf_extractor = None\n",
    "    print(\"\\nâš ï¸  PDF extraction disabled (PDF_EXTRACTOR not set)\")\n",
    "\n",
    "print(\"\\nâœ“ System initialized and ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Synthesis Functions\n",
    "\n",
    "High-level wrapper functions for easy synthesis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Synthesis functions loaded\n"
     ]
    }
   ],
   "source": [
    "def synth_string(\n",
    "    text,\n",
    "    voice=None,\n",
    "    speed=1.0,\n",
    "    out_format=\"wav\",\n",
    "    basename=\"tts_text\",\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"Synthesize a text string to audio.\"\"\"\n",
    "    if not ENABLE_TEXT_INPUT:\n",
    "        raise ValueError(\"Text input is disabled. Set ENABLE_TEXT_INPUT=True in configuration.\")\n",
    "    \n",
    "    if out_format == \"mp3\" and not ENABLE_MP3_OUTPUT:\n",
    "        raise ValueError(\"MP3 output is disabled. Set ENABLE_MP3_OUTPUT=True in configuration.\")\n",
    "    \n",
    "    voice = voice or tts.get_default_voice()\n",
    "    \n",
    "    elements = [{\n",
    "        \"text\": text,\n",
    "        \"metadata\": {\"page_number\": 1, \"source\": \"string\", \"points\": None}\n",
    "    }]\n",
    "    \n",
    "    # Synthesize\n",
    "    if TTS_MODEL.startswith(\"kokoro\"):\n",
    "        wav_bytes, timeline = tts.synthesize_text_to_wav(\n",
    "            elements, voice=voice, speed=speed, **kwargs\n",
    "        )\n",
    "    else:  # Silero\n",
    "        wav_bytes, timeline = tts.synthesize_text_to_wav(\n",
    "            elements, speaker=voice, **kwargs\n",
    "        )\n",
    "    \n",
    "    # Save audio\n",
    "    out_base = config.get_output_path(basename)\n",
    "    \n",
    "    if out_format.lower() == \"mp3\":\n",
    "        mp3 = wav_to_mp3_bytes(wav_bytes)\n",
    "        audio_path = str(out_base) + \".mp3\"\n",
    "        with open(audio_path, \"wb\") as f:\n",
    "            f.write(mp3)\n",
    "    else:\n",
    "        audio_path = str(out_base) + \".wav\"\n",
    "        with open(audio_path, \"wb\") as f:\n",
    "            f.write(wav_bytes)\n",
    "    \n",
    "    # Save manifest\n",
    "    manifest_path = str(out_base) + \"_manifest.json\"\n",
    "    manifest = create_manifest(Path(audio_path).name, timeline)\n",
    "    save_manifest(manifest, manifest_path)\n",
    "    \n",
    "    return audio_path, manifest_path\n",
    "\n",
    "\n",
    "def synth_pdf(\n",
    "    file_path_or_bytes,\n",
    "    voice=None,\n",
    "    speed=1.0,\n",
    "    out_format=\"wav\",\n",
    "    basename=None,\n",
    "    pages=None,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"Synthesize a PDF to audio.\"\"\"\n",
    "    if not ENABLE_PDF_INPUT:\n",
    "        raise ValueError(\"PDF input is disabled. Set ENABLE_PDF_INPUT=True in configuration.\")\n",
    "    \n",
    "    if pdf_extractor is None:\n",
    "        raise ValueError(\"No PDF extractor configured. Set PDF_EXTRACTOR in configuration.\")\n",
    "    \n",
    "    if out_format == \"mp3\" and not ENABLE_MP3_OUTPUT:\n",
    "        raise ValueError(\"MP3 output is disabled. Set ENABLE_MP3_OUTPUT=True in configuration.\")\n",
    "    \n",
    "    voice = voice or tts.get_default_voice()\n",
    "    \n",
    "    # Load PDF\n",
    "    if isinstance(file_path_or_bytes, (str, Path)):\n",
    "        with open(file_path_or_bytes, \"rb\") as fh:\n",
    "            pdf_bytes = io.BytesIO(fh.read())\n",
    "        stem = Path(file_path_or_bytes).stem\n",
    "    else:\n",
    "        pdf_bytes = file_path_or_bytes\n",
    "        stem = basename or \"document\"\n",
    "    \n",
    "    # Extract text\n",
    "    elements = pdf_extractor.extract(pdf_bytes, pages=pages)\n",
    "    \n",
    "    # Synthesize\n",
    "    if TTS_MODEL.startswith(\"kokoro\"):\n",
    "        wav_bytes, timeline = tts.synthesize_text_to_wav(\n",
    "            elements, voice=voice, speed=speed, **kwargs\n",
    "        )\n",
    "    else:  # Silero\n",
    "        wav_bytes, timeline = tts.synthesize_text_to_wav(\n",
    "            elements, speaker=voice, **kwargs\n",
    "        )\n",
    "    \n",
    "    # Save audio\n",
    "    out_base = config.get_output_path(f\"{basename or stem}_tts\")\n",
    "    \n",
    "    if out_format.lower() == \"mp3\":\n",
    "        mp3 = wav_to_mp3_bytes(wav_bytes)\n",
    "        audio_path = str(out_base) + \".mp3\"\n",
    "        with open(audio_path, \"wb\") as f:\n",
    "            f.write(mp3)\n",
    "    else:\n",
    "        audio_path = str(out_base) + \".wav\"\n",
    "        with open(audio_path, \"wb\") as f:\n",
    "            f.write(wav_bytes)\n",
    "    \n",
    "    # Save manifest\n",
    "    manifest_path = str(out_base) + \"_manifest.json\"\n",
    "    manifest = create_manifest(Path(audio_path).name, timeline)\n",
    "    save_manifest(manifest, manifest_path)\n",
    "    \n",
    "    return audio_path, manifest_path\n",
    "\n",
    "\n",
    "def synth_epub(\n",
    "    file_path_or_bytes,\n",
    "    voice=None,\n",
    "    speed=1.0,\n",
    "    per_chapter_format=\"wav\",\n",
    "    zip_name=None,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"Synthesize an EPUB to per-chapter audio files in a ZIP.\"\"\"\n",
    "    import zipfile\n",
    "    \n",
    "    if not ENABLE_EPUB_INPUT:\n",
    "        raise ValueError(\"EPUB input is disabled. Set ENABLE_EPUB_INPUT=True in configuration.\")\n",
    "    \n",
    "    if per_chapter_format == \"mp3\" and not ENABLE_MP3_OUTPUT:\n",
    "        raise ValueError(\"MP3 output is disabled. Set ENABLE_MP3_OUTPUT=True in configuration.\")\n",
    "    \n",
    "    voice = voice or tts.get_default_voice()\n",
    "    \n",
    "    # Load EPUB\n",
    "    if isinstance(file_path_or_bytes, (str, Path)):\n",
    "        with open(file_path_or_bytes, \"rb\") as fh:\n",
    "            epub_bytes = io.BytesIO(fh.read())\n",
    "        stem = Path(file_path_or_bytes).stem\n",
    "    else:\n",
    "        epub_bytes = file_path_or_bytes\n",
    "        stem = \"book\"\n",
    "    \n",
    "    # Extract chapters\n",
    "    chapters = extract_chapters_from_epub(epub_bytes)\n",
    "    assert chapters, \"No chapters detected in EPUB.\"\n",
    "    \n",
    "    # Create ZIP\n",
    "    zip_buf = io.BytesIO()\n",
    "    with zipfile.ZipFile(zip_buf, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
    "        for idx, (title, body) in enumerate(chapters, 1):\n",
    "            name = f\"{idx:02d}_{safe_name(title)[:40]}\"\n",
    "            \n",
    "            chapter_elements = [{\n",
    "                \"text\": body,\n",
    "                \"metadata\": {\n",
    "                    \"chapter_index\": idx,\n",
    "                    \"chapter_title\": title,\n",
    "                    \"page_number\": 1,\n",
    "                    \"points\": None\n",
    "                }\n",
    "            }]\n",
    "            \n",
    "            # Synthesize chapter\n",
    "            if TTS_MODEL.startswith(\"kokoro\"):\n",
    "                wav_bytes, timeline = tts.synthesize_text_to_wav(\n",
    "                    chapter_elements, voice=voice, speed=speed, **kwargs\n",
    "                )\n",
    "            else:  # Silero\n",
    "                wav_bytes, timeline = tts.synthesize_text_to_wav(\n",
    "                    chapter_elements, speaker=voice, **kwargs\n",
    "                )\n",
    "            \n",
    "            # Add audio to ZIP\n",
    "            if per_chapter_format.lower() == \"mp3\":\n",
    "                data = wav_to_mp3_bytes(wav_bytes)\n",
    "                audio_name = f\"{name}.mp3\"\n",
    "                zf.writestr(audio_name, data)\n",
    "            else:\n",
    "                audio_name = f\"{name}.wav\"\n",
    "                zf.writestr(audio_name, wav_bytes)\n",
    "            \n",
    "            # Add manifest to ZIP\n",
    "            manifest = create_manifest(audio_name, timeline)\n",
    "            zf.writestr(f\"{name}_manifest.json\", json.dumps(manifest, ensure_ascii=False, indent=2))\n",
    "    \n",
    "    # Save ZIP\n",
    "    zip_buf.seek(0)\n",
    "    zpath = str(config.get_output_path(f\"{zip_name or (stem + '_chapters')}.zip\"))\n",
    "    with open(zpath, \"wb\") as f:\n",
    "        f.write(zip_buf.read())\n",
    "    \n",
    "    return zpath\n",
    "\n",
    "\n",
    "print(\"âœ“ Synthesis functions loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Examples\n",
    "\n",
    "Run the examples below to synthesize text, PDFs, and EPUBs.\n",
    "\n",
    "**Note:** Only the examples for enabled input/output formats will work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) String â†’ Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ENABLE_TEXT_INPUT:\n",
    "    print(\"âš ï¸  Text input is disabled. Set ENABLE_TEXT_INPUT=True to use this example.\")\n",
    "else:\n",
    "    # Configuration\n",
    "    VOICE = None  # Use default voice (or specify: \"af_heart\", \"xenia\", etc.)\n",
    "    SPEED = 1.0   # Speech speed (Kokoro only)\n",
    "    FORMAT = \"mp3\" if ENABLE_MP3_OUTPUT else \"wav\"\n",
    "    BASENAME = \"tts_text\"\n",
    "\n",
    "    # Text to synthesize\n",
    "    TEXT = \"\"\"Hello! This is a test of the unified TTS system.\n",
    "    It automatically installs only the dependencies you need.\n",
    "    \"\"\"\n",
    "\n",
    "    # Run synthesis\n",
    "    audio_path, manifest_path = synth_string(\n",
    "        TEXT,\n",
    "        voice=VOICE,\n",
    "        speed=SPEED,\n",
    "        out_format=FORMAT,\n",
    "        basename=BASENAME\n",
    "    )\n",
    "\n",
    "    print(f\"\\nâœ“ Audio saved to: {audio_path}\")\n",
    "    print(f\"âœ“ Manifest saved to: {manifest_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) PDF â†’ Audio (with page selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing PDF with layout analysis (strategy='hi_res')...\n",
      "Warning: No languages specified, defaulting to English.\n",
      "Unstructured 'hi_res' strategy failed: Unable to get page count. Is poppler installed and in PATH?. Falling back to 'fast'.\n",
      "Warning: No languages specified, defaulting to English.\n",
      "Unstructured 'fast' returned 16 raw elements.\n",
      "\n",
      "--- Processing elements (checking for points) ---\n",
      "--- Finished processing elements ---\n",
      "Unstructured: Found 14 text elements from all pages.\n",
      "Synthesizing 14 text elements...\n",
      "WARNING: Defaulting repo_id to hexgrad/Kokoro-82M. Pass repo_id='hexgrad/Kokoro-82M' to suppress this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tts/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/tts/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "The operator 'aten::angle' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNotImplementedError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     16\u001b[39m PAGES = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# Run synthesis\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m audio_path, manifest_path = \u001b[43msynth_pdf\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mPDF_PATH\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvoice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mVOICE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mspeed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSPEED\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43mout_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFORMAT\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPAGES\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mâœ“ Audio saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maudio_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mâœ“ Manifest saved to: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmanifest_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 89\u001b[39m, in \u001b[36msynth_pdf\u001b[39m\u001b[34m(file_path_or_bytes, voice, speed, out_format, basename, pages, **kwargs)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;66;03m# Synthesize\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m TTS_MODEL.startswith(\u001b[33m\"\u001b[39m\u001b[33mkokoro\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     wav_bytes, timeline = \u001b[43mtts\u001b[49m\u001b[43m.\u001b[49m\u001b[43msynthesize_text_to_wav\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[43m        \u001b[49m\u001b[43melements\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvoice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvoice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspeed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Silero\u001b[39;00m\n\u001b[32m     93\u001b[39m     wav_bytes, timeline = tts.synthesize_text_to_wav(\n\u001b[32m     94\u001b[39m         elements, speaker=voice, **kwargs\n\u001b[32m     95\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/ttsweb.github.io/tts_backends.py:126\u001b[39m, in \u001b[36mTTSBackend.synthesize_text_to_wav\u001b[39m\u001b[34m(self, text_or_elements, **kwargs)\u001b[39m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m sent:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m pcm = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msynthesize_sentence\u001b[49m\u001b[43m(\u001b[49m\u001b[43msent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    127\u001b[39m dur = pcm.shape[\u001b[32m0\u001b[39m] / sr\n\u001b[32m    129\u001b[39m timeline.append({\n\u001b[32m    130\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mi\u001b[39m\u001b[33m\"\u001b[39m: sentence_index,\n\u001b[32m    131\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mstart\u001b[39m\u001b[33m\"\u001b[39m: \u001b[38;5;28mround\u001b[39m(t, \u001b[32m3\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m    134\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mlocation\u001b[39m\u001b[33m\"\u001b[39m: element_meta\n\u001b[32m    135\u001b[39m })\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/GitHub/ttsweb.github.io/tts_backends.py:206\u001b[39m, in \u001b[36mKokoroBackend.synthesize_sentence\u001b[39m\u001b[34m(self, text, voice, speed, lang_code, **kwargs)\u001b[39m\n\u001b[32m    203\u001b[39m pipe = \u001b[38;5;28mself\u001b[39m._get_pipeline(lang_code)\n\u001b[32m    204\u001b[39m subchunks = []\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maudio\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpipe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvoice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvoice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mspeed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_pattern\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    207\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubchunks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mappend\u001b[49m\u001b[43m(\u001b[49m\u001b[43maudio\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    209\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m subchunks:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tts/lib/python3.12/site-packages/kokoro/pipeline.py:383\u001b[39m, in \u001b[36mKPipeline.__call__\u001b[39m\u001b[34m(self, text, voice, speed, split_pattern, model)\u001b[39m\n\u001b[32m    381\u001b[39m     logger.warning(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mUnexpected len(ps) == \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(ps)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m > 510 and ps == \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mps\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    382\u001b[39m     ps = ps[:\u001b[32m510\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m output = \u001b[43mKPipeline\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpack\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeed\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m output \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m output.pred_dur \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    385\u001b[39m     KPipeline.join_timestamps(tks, output.pred_dur)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tts/lib/python3.12/site-packages/kokoro/pipeline.py:232\u001b[39m, in \u001b[36mKPipeline.infer\u001b[39m\u001b[34m(model, ps, pack, speed)\u001b[39m\n\u001b[32m    230\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(speed):\n\u001b[32m    231\u001b[39m     speed = speed(\u001b[38;5;28mlen\u001b[39m(ps))\n\u001b[32m--> \u001b[39m\u001b[32m232\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpack\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mps\u001b[49m\u001b[43m)\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_output\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tts/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tts/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tts/lib/python3.12/site-packages/kokoro/model.py:133\u001b[39m, in \u001b[36mKModel.forward\u001b[39m\u001b[34m(self, phonemes, ref_s, speed, return_output)\u001b[39m\n\u001b[32m    131\u001b[39m input_ids = torch.LongTensor([[\u001b[32m0\u001b[39m, *input_ids, \u001b[32m0\u001b[39m]]).to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m    132\u001b[39m ref_s = ref_s.to(\u001b[38;5;28mself\u001b[39m.device)\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m audio, pred_dur = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mforward_with_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_s\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mspeed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    134\u001b[39m audio = audio.squeeze().cpu()\n\u001b[32m    135\u001b[39m pred_dur = pred_dur.cpu() \u001b[38;5;28;01mif\u001b[39;00m pred_dur \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tts/lib/python3.12/site-packages/torch/utils/_contextlib.py:116\u001b[39m, in \u001b[36mcontext_decorator.<locals>.decorate_context\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(func)\n\u001b[32m    114\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecorate_context\u001b[39m(*args, **kwargs):\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tts/lib/python3.12/site-packages/kokoro/model.py:118\u001b[39m, in \u001b[36mKModel.forward_with_tokens\u001b[39m\u001b[34m(self, input_ids, ref_s, speed)\u001b[39m\n\u001b[32m    116\u001b[39m t_en = \u001b[38;5;28mself\u001b[39m.text_encoder(input_ids, input_lengths, text_mask)\n\u001b[32m    117\u001b[39m asr = t_en @ pred_aln_trg\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m audio = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdecoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43masr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF0_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mref_s\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[32;43m128\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m.squeeze()\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m audio, pred_dur\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tts/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tts/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tts/lib/python3.12/site-packages/kokoro/istftnet.py:420\u001b[39m, in \u001b[36mDecoder.forward\u001b[39m\u001b[34m(self, asr, F0_curve, N, s)\u001b[39m\n\u001b[32m    418\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m block.upsample_type != \u001b[33m\"\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    419\u001b[39m         res = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mF0_curve\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tts/lib/python3.12/site-packages/torch/nn/modules/module.py:1736\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1735\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1736\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tts/lib/python3.12/site-packages/torch/nn/modules/module.py:1747\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1742\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1743\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1744\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1745\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1746\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1747\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1749\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1750\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tts/lib/python3.12/site-packages/kokoro/istftnet.py:304\u001b[39m, in \u001b[36mGenerator.forward\u001b[39m\u001b[34m(self, x, s, f0)\u001b[39m\n\u001b[32m    302\u001b[39m     har_source, noi_source, uv = \u001b[38;5;28mself\u001b[39m.m_source(f0)\n\u001b[32m    303\u001b[39m     har_source = har_source.transpose(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m).squeeze(\u001b[32m1\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m304\u001b[39m     har_spec, har_phase = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstft\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhar_source\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    305\u001b[39m     har = torch.cat([har_spec, har_phase], dim=\u001b[32m1\u001b[39m)\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.num_upsamples):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/anaconda3/envs/tts/lib/python3.12/site-packages/kokoro/istftnet.py:94\u001b[39m, in \u001b[36mTorchSTFT.transform\u001b[39m\u001b[34m(self, input_data)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_data):\n\u001b[32m     90\u001b[39m     forward_transform = torch.stft(\n\u001b[32m     91\u001b[39m         input_data,\n\u001b[32m     92\u001b[39m         \u001b[38;5;28mself\u001b[39m.filter_length, \u001b[38;5;28mself\u001b[39m.hop_length, \u001b[38;5;28mself\u001b[39m.win_length, window=\u001b[38;5;28mself\u001b[39m.window.to(input_data.device),\n\u001b[32m     93\u001b[39m         return_complex=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m94\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m torch.abs(forward_transform), \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mangle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mforward_transform\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mNotImplementedError\u001b[39m: The operator 'aten::angle' is not currently implemented for the MPS device. If you want this op to be added in priority during the prototype phase of this feature, please comment on https://github.com/pytorch/pytorch/issues/77764. As a temporary fix, you can set the environment variable `PYTORCH_ENABLE_MPS_FALLBACK=1` to use the CPU as a fallback for this op. WARNING: this will be slower than running natively on MPS."
     ]
    }
   ],
   "source": [
    "if not ENABLE_PDF_INPUT:\n",
    "    print(\"âš ï¸  PDF input is disabled. Set ENABLE_PDF_INPUT=True and PDF_EXTRACTOR to use this example.\")\n",
    "else:\n",
    "    # Configuration\n",
    "    VOICE = None  # Use default voice\n",
    "    SPEED = 1.0\n",
    "    FORMAT = \"mp3\" if ENABLE_MP3_OUTPUT else \"wav\"\n",
    "\n",
    "    # PDF file path\n",
    "    PDF_PATH = \"Case1Writeup.pdf\"  # Change this to your PDF filename\n",
    "\n",
    "    # Page selection (optional)\n",
    "    # None = all pages (default)\n",
    "    # [1, 2, 3] = only pages 1, 2, and 3\n",
    "    # [5] = only page 5\n",
    "    PAGES = None\n",
    "\n",
    "    # Run synthesis\n",
    "    audio_path, manifest_path = synth_pdf(\n",
    "        PDF_PATH,\n",
    "        voice=VOICE,\n",
    "        speed=SPEED,\n",
    "        out_format=FORMAT,\n",
    "        pages=PAGES\n",
    "    )\n",
    "\n",
    "    print(f\"\\nâœ“ Audio saved to: {audio_path}\")\n",
    "    print(f\"âœ“ Manifest saved to: {manifest_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) EPUB â†’ ZIP (Per-Chapter Audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ENABLE_EPUB_INPUT:\n",
    "    print(\"âš ï¸  EPUB input is disabled. Set ENABLE_EPUB_INPUT=True to use this example.\")\n",
    "else:\n",
    "    # Configuration\n",
    "    VOICE = None  # Use default voice\n",
    "    SPEED = 1.0\n",
    "    CHAPTER_FORMAT = \"mp3\" if ENABLE_MP3_OUTPUT else \"wav\"\n",
    "    ZIP_NAME = \"\"  # Optional: custom name for ZIP file\n",
    "\n",
    "    # EPUB file path\n",
    "    EPUB_PATH = \"book.epub\"  # Change this to your EPUB filename\n",
    "\n",
    "    # Run synthesis\n",
    "    zip_path = synth_epub(\n",
    "        EPUB_PATH,\n",
    "        voice=VOICE,\n",
    "        speed=SPEED,\n",
    "        per_chapter_format=CHAPTER_FORMAT,\n",
    "        zip_name=(ZIP_NAME or None)\n",
    "    )\n",
    "\n",
    "    print(f\"\\nâœ“ ZIP archive saved to: {zip_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- **Switching Models**: To use a different TTS model or PDF extractor, change the settings in Section 1 and re-run from there\n",
    "- **Voice Selection**: Each model has different voices. Check the output of Section 3 for available voices\n",
    "- **Manifest Files**: Each audio output includes a JSON manifest with sentence-level timing and coordinates\n",
    "- **Dependencies**: Only the packages needed for your selected configuration were installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup: Delete Environment (Optional)\n",
    "\n",
    "**If you created a new environment at the beginning of this notebook**, you can delete it here to free up storage space.\n",
    "\n",
    "âš ï¸ **Warning**: This will permanently delete the environment and all installed packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "if 'environment_created_by_notebook' not in globals():\n",
    "    print(\"âœ— No environment tracking found\")\n",
    "    print(\"This cell only works if you ran the environment setup cell at the beginning\")\n",
    "elif not environment_created_by_notebook:\n",
    "    print(\"âœ— No environment was created by this notebook\")\n",
    "    print(\"You can only delete environments that were created in this session\")\n",
    "else:\n",
    "    print(f\"Environment '{environment_name}' was created by this notebook\")\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"DELETE ENVIRONMENT\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    confirm = input(f\"\\nAre you sure you want to DELETE '{environment_name}'?\\nType 'yes' to confirm: \").strip().lower()\n",
    "    \n",
    "    if confirm == 'yes':\n",
    "        print(f\"\\nâ†’ Deleting environment '{environment_name}'...\")\n",
    "        print(\"  This may take a moment...\")\n",
    "        \n",
    "        try:\n",
    "            subprocess.run(['conda', 'env', 'remove', '-n', environment_name, '-y'],\n",
    "                           check=True, capture_output=True)\n",
    "            print(f\"âœ“ Environment '{environment_name}' deleted successfully!\")\n",
    "            print(\"  Storage space has been freed.\")\n",
    "            \n",
    "            environment_created_by_notebook = False\n",
    "            environment_name = None\n",
    "            \n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"âœ— Failed to delete environment: {e}\")\n",
    "            print(f\"You may need to delete it manually with: conda env remove -n {environment_name}\")\n",
    "    else:\n",
    "        print(\"\\nâœ— Deletion cancelled - environment preserved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "## Memory Management: View & Delete Models\n\n**View all locally cached models, their sizes, and manage storage.**\n\nThis section helps you:\n- See which models are downloaded and how much space they use\n- Delete specific models to free up storage\n- Clean PyTorch and HuggingFace caches\n- Clear GPU/MPS memory",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import os\nimport shutil\nfrom pathlib import Path\n\ndef get_dir_size(path):\n    \"\"\"Calculate total size of a directory in bytes.\"\"\"\n    total = 0\n    try:\n        for entry in os.scandir(path):\n            if entry.is_file(follow_symlinks=False):\n                total += entry.stat().size\n            elif entry.is_dir(follow_symlinks=False):\n                total += get_dir_size(entry.path)\n    except (PermissionError, FileNotFoundError):\n        pass\n    return total\n\ndef format_bytes(bytes_size):\n    \"\"\"Format bytes to human-readable size.\"\"\"\n    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:\n        if bytes_size < 1024.0:\n            return f\"{bytes_size:.2f} {unit}\"\n        bytes_size /= 1024.0\n    return f\"{bytes_size:.2f} PB\"\n\ndef scan_cached_models():\n    \"\"\"Scan for cached models in common locations.\"\"\"\n    home = Path.home()\n    \n    cache_locations = {\n        \"HuggingFace Cache\": home / \".cache\" / \"huggingface\",\n        \"Torch Hub\": home / \".cache\" / \"torch\" / \"hub\",\n        \"Torch Checkpoints\": home / \".cache\" / \"torch\" / \"checkpoints\",\n        \"Detectron2\": home / \".torch\" / \"fvcore_cache\" / \"detectron2\",\n        \"Kokoro Models\": home / \".cache\" / \"kokoro\",\n    }\n    \n    results = []\n    total_size = 0\n    \n    print(\"=\" * 80)\n    print(\"SCANNING CACHED MODELS\")\n    print(\"=\" * 80)\n    print()\n    \n    for name, path in cache_locations.items():\n        if path.exists():\n            size = get_dir_size(path)\n            if size > 0:\n                results.append({\n                    \"name\": name,\n                    \"path\": str(path),\n                    \"size\": size,\n                    \"size_formatted\": format_bytes(size)\n                })\n                total_size += size\n                print(f\"ðŸ“¦ {name}\")\n                print(f\"   Path: {path}\")\n                print(f\"   Size: {format_bytes(size)}\")\n                \n                # Try to list specific models if it's HuggingFace cache\n                if name == \"HuggingFace Cache\":\n                    models_dir = path / \"hub\"\n                    if models_dir.exists():\n                        model_folders = [d for d in models_dir.iterdir() if d.is_dir() and d.name.startswith(\"models--\")]\n                        if model_folders:\n                            print(f\"   Models found: {len(model_folders)}\")\n                            for model_folder in sorted(model_folders)[:5]:  # Show first 5\n                                model_name = model_folder.name.replace(\"models--\", \"\").replace(\"--\", \"/\")\n                                model_size = get_dir_size(model_folder)\n                                print(f\"     â€¢ {model_name}: {format_bytes(model_size)}\")\n                            if len(model_folders) > 5:\n                                print(f\"     ... and {len(model_folders) - 5} more\")\n                \n                # Try to list PyTorch Hub models\n                elif name == \"Torch Hub\":\n                    checkpoints = list(path.glob(\"checkpoints/*.pth\")) + list(path.glob(\"*.pth\"))\n                    if checkpoints:\n                        print(f\"   Checkpoints found: {len(checkpoints)}\")\n                        for ckpt in sorted(checkpoints)[:5]:\n                            ckpt_size = ckpt.stat().st_size\n                            print(f\"     â€¢ {ckpt.name}: {format_bytes(ckpt_size)}\")\n                        if len(checkpoints) > 5:\n                            print(f\"     ... and {len(checkpoints) - 5} more\")\n                \n                print()\n        else:\n            print(f\"âšª {name}\")\n            print(f\"   Path: {path}\")\n            print(f\"   Status: Not found\")\n            print()\n    \n    print(\"=\" * 80)\n    print(f\"TOTAL CACHED SIZE: {format_bytes(total_size)}\")\n    print(\"=\" * 80)\n    \n    return results, total_size\n\n# Run the scan\ncached_models, total_cache_size = scan_cached_models()",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Delete Cached Models\n\n**Select which caches to delete.**\n\nChoose what you want to clean up to free storage space.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "def delete_cache(cache_name):\n    \"\"\"Delete a specific cache directory.\"\"\"\n    home = Path.home()\n    \n    cache_paths = {\n        \"huggingface\": home / \".cache\" / \"huggingface\",\n        \"torch_hub\": home / \".cache\" / \"torch\" / \"hub\",\n        \"torch_checkpoints\": home / \".cache\" / \"torch\" / \"checkpoints\",\n        \"detectron2\": home / \".torch\" / \"fvcore_cache\" / \"detectron2\",\n        \"kokoro\": home / \".cache\" / \"kokoro\",\n        \"pip\": home / \".cache\" / \"pip\",\n    }\n    \n    if cache_name not in cache_paths:\n        print(f\"âœ— Unknown cache: {cache_name}\")\n        print(f\"Available caches: {', '.join(cache_paths.keys())}\")\n        return False\n    \n    cache_path = cache_paths[cache_name]\n    \n    if not cache_path.exists():\n        print(f\"âšª Cache not found: {cache_path}\")\n        return False\n    \n    size_before = get_dir_size(cache_path)\n    print(f\"â†’ Deleting {cache_name} cache...\")\n    print(f\"  Path: {cache_path}\")\n    print(f\"  Size: {format_bytes(size_before)}\")\n    \n    try:\n        shutil.rmtree(cache_path)\n        print(f\"âœ“ Successfully deleted {cache_name} cache\")\n        print(f\"  Freed: {format_bytes(size_before)}\")\n        return True\n    except Exception as e:\n        print(f\"âœ— Failed to delete cache: {e}\")\n        return False\n\n\n# Interactive deletion\nprint(\"=\" * 80)\nprint(\"DELETE CACHE OPTIONS\")\nprint(\"=\" * 80)\nprint()\nprint(\"Available caches to delete:\")\nprint(\"  [1] HuggingFace Cache\")\nprint(\"  [2] Torch Hub\")\nprint(\"  [3] Torch Checkpoints\")\nprint(\"  [4] Detectron2\")\nprint(\"  [5] Kokoro Models\")\nprint(\"  [6] Pip Cache\")\nprint(\"  [7] ALL caches (âš ï¸  WARNING: Deletes everything!)\")\nprint(\"  [0] Cancel\")\nprint()\n\nchoice = input(\"Enter choice (0-7): \").strip()\n\ncache_map = {\n    \"1\": \"huggingface\",\n    \"2\": \"torch_hub\",\n    \"3\": \"torch_checkpoints\",\n    \"4\": \"detectron2\",\n    \"5\": \"kokoro\",\n    \"6\": \"pip\",\n}\n\nif choice == \"0\":\n    print(\"\\nâœ— Deletion cancelled\")\nelif choice == \"7\":\n    confirm = input(\"\\nâš ï¸  Delete ALL caches? Type 'yes' to confirm: \").strip().lower()\n    if confirm == \"yes\":\n        print(\"\\nâ†’ Deleting all caches...\")\n        total_freed = 0\n        for cache_name in cache_map.values():\n            if delete_cache(cache_name):\n                print()\n        print(\"=\" * 80)\n        print(\"âœ“ All caches deleted\")\n        print(\"=\" * 80)\n    else:\n        print(\"\\nâœ— Deletion cancelled\")\nelif choice in cache_map:\n    cache_name = cache_map[choice]\n    confirm = input(f\"\\nDelete {cache_name} cache? Type 'yes' to confirm: \").strip().lower()\n    if confirm == \"yes\":\n        print()\n        delete_cache(cache_name)\n    else:\n        print(\"\\nâœ— Deletion cancelled\")\nelse:\n    print(\"\\nâœ— Invalid choice\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "### Clear GPU/MPS Memory\n\n**Free up GPU or MPS (Apple Silicon) memory.**\n\nRun this cell to clear PyTorch's memory cache and force garbage collection.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "import gc\nimport torch\n\nprint(\"=\" * 80)\nprint(\"CLEARING GPU/MPS MEMORY\")\nprint(\"=\" * 80)\nprint()\n\n# Check current memory usage (if applicable)\nif torch.cuda.is_available():\n    print(\"ðŸ“Š CUDA Memory Status (before cleanup):\")\n    for i in range(torch.cuda.device_count()):\n        allocated = torch.cuda.memory_allocated(i) / 1024**2\n        reserved = torch.cuda.memory_reserved(i) / 1024**2\n        print(f\"   GPU {i}: {allocated:.2f} MB allocated, {reserved:.2f} MB reserved\")\n    print()\nelif torch.backends.mps.is_available():\n    print(\"ðŸ“Š MPS (Apple Silicon) detected\")\n    print(\"   Note: MPS doesn't provide detailed memory stats\")\n    print()\nelse:\n    print(\"ðŸ“Š No GPU/MPS detected - running on CPU\")\n    print()\n\n# Clear PyTorch cache\nprint(\"â†’ Clearing PyTorch cache...\")\nif torch.cuda.is_available():\n    torch.cuda.empty_cache()\n    torch.cuda.synchronize()\n    print(\"âœ“ CUDA cache cleared\")\nelif torch.backends.mps.is_available():\n    torch.mps.empty_cache()\n    torch.mps.synchronize()\n    print(\"âœ“ MPS cache cleared\")\nelse:\n    print(\"âšª No GPU cache to clear (CPU mode)\")\n\n# Force garbage collection\nprint(\"\\nâ†’ Running garbage collection...\")\ngc.collect()\nprint(\"âœ“ Garbage collection completed\")\n\n# Check memory usage after cleanup\nprint()\nif torch.cuda.is_available():\n    print(\"ðŸ“Š CUDA Memory Status (after cleanup):\")\n    for i in range(torch.cuda.device_count()):\n        allocated = torch.cuda.memory_allocated(i) / 1024**2\n        reserved = torch.cuda.memory_reserved(i) / 1024**2\n        print(f\"   GPU {i}: {allocated:.2f} MB allocated, {reserved:.2f} MB reserved\")\nelif torch.backends.mps.is_available():\n    print(\"ðŸ“Š MPS cache has been cleared\")\n    print(\"   Memory should be freed for other applications\")\n\nprint()\nprint(\"=\" * 80)\nprint(\"âœ“ MEMORY CLEANUP COMPLETE\")\nprint(\"=\" * 80)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}