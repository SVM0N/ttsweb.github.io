{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unified TTS Notebook\n",
    "\n",
    "**Single notebook for all TTS models and PDF extraction strategies**\n",
    "\n",
    "This notebook provides a unified interface for:\n",
    "- **TTS Models**: Kokoro (v0.9, v1.0), Maya1 (expressive, 20+ emotions), Silero v5\n",
    "- **PDF Extractors**: Unstructured, PyMuPDF, Apple Vision, Nougat\n",
    "- **Input Formats**: Text strings, PDF files, EPUB books\n",
    "- **Output Formats**: WAV, MP3 with timeline manifests\n",
    "\n",
    "The notebook will automatically install only the dependencies you need based on your selections!\n",
    "\n",
    "‚úÖ **Works both locally and in Google Colab** - automatically detects environment and downloads required files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0a) Environment Detection & Setup\n",
    "\n",
    "**This cell automatically detects if you're running in Google Colab or locally.**\n",
    "\n",
    "If in Colab, it will download the required Python modules from the GitHub repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Detect if running in Google Colab\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    print(\"üåê Running in Google Colab\")\n",
    "except ImportError:\n",
    "    IN_COLAB = False\n",
    "    print(\"üíª Running locally\")\n",
    "\n",
    "# GitHub repository URL for downloading Python modules\n",
    "GITHUB_RAW_URL = \"https://raw.githubusercontent.com/SVM0N/ttsweb.github.io/main/\"\n",
    "\n",
    "# Required Python modules (in tts_lib folder)\n",
    "REQUIRED_MODULES = [\n",
    "    \"tts_lib/__init__.py\",\n",
    "    \"tts_lib/config.py\",\n",
    "    \"tts_lib/tts_backends.py\",\n",
    "    \"tts_lib/tts_utils.py\",\n",
    "    \"tts_lib/pdf_extractors.py\",\n",
    "    \"tts_lib/manifest.py\",\n",
    "    \"tts_lib/setup.py\",\n",
    "    \"tts_lib/init_system.py\",\n",
    "    \"tts_lib/synthesis.py\"\n",
    "]\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"\\nüì¶ Setting up Colab environment...\")\n",
    "    print(\"   Downloading required Python modules from GitHub...\")\n",
    "    \n",
    "    import urllib.request\n",
    "    \n",
    "    # Create tts_lib directory\n",
    "    Path(\"tts_lib\").mkdir(exist_ok=True)\n",
    "    \n",
    "    for module in REQUIRED_MODULES:\n",
    "        url = GITHUB_RAW_URL + module\n",
    "        try:\n",
    "            print(f\"   ‚Üí Downloading {module}...\")\n",
    "            urllib.request.urlretrieve(url, module)\n",
    "            print(f\"   ‚úì {module} downloaded\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚úó Failed to download {module}: {e}\")\n",
    "            print(f\"     URL: {url}\")\n",
    "    \n",
    "    # Create files directory for outputs\n",
    "    files_dir = Path(\"files\")\n",
    "    files_dir.mkdir(exist_ok=True)\n",
    "    print(f\"\\n‚úì Created output directory: {files_dir}\")\n",
    "    \n",
    "    print(\"\\n‚úì Colab environment setup complete!\")\n",
    "    print(\"  You can now proceed with the rest of the notebook.\")\n",
    "    print(\"\\nüìù Note: To upload PDFs or EPUBs, use the file upload button in the sidebar\")\n",
    "    print(\"  or run: from google.colab import files; uploaded = files.upload()\")\n",
    "    \n",
    "else:\n",
    "    print(\"\\n‚úì Local environment detected\")\n",
    "    print(\"  Using local Python modules\")\n",
    "    \n",
    "    # Check if required modules exist locally\n",
    "    missing_modules = []\n",
    "    for module in REQUIRED_MODULES:\n",
    "        if not Path(module).exists():\n",
    "            missing_modules.append(module)\n",
    "    \n",
    "    if missing_modules:\n",
    "        print(f\"\\n‚ö†Ô∏è  Warning: Missing modules: {', '.join(missing_modules)}\")\n",
    "        print(\"  Make sure you're running this notebook from the repository directory\")\n",
    "    else:\n",
    "        print(f\"  ‚úì All required modules found\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0b) Conda Environment Setup (Optional - Local Only)\n",
    "\n",
    "**This step helps you manage Python packages and avoid conflicts with your system installation.**\n",
    "\n",
    "- If you have **conda** installed, you can create a fresh environment for this notebook\n",
    "- Or use an existing environment by providing its name\n",
    "- At the end of the notebook, you can easily clean up and delete the environment to free storage\n",
    "- **Note**: This section is only relevant for local installations, not Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Flag to track if we created an environment in this notebook\n",
    "environment_created_by_notebook = False\n",
    "environment_name = None\n",
    "\n",
    "# Check if conda is installed\n",
    "try:\n",
    "    result = subprocess.run(['conda', '--version'], capture_output=True, text=True, check=True)\n",
    "    conda_available = True\n",
    "    print(f\"‚úì Conda detected: {result.stdout.strip()}\")\n",
    "except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "    conda_available = False\n",
    "    print(\"‚úó Conda not found - skipping environment management\")\n",
    "    print(\"Packages will be installed in your current Python environment\")\n",
    "\n",
    "if conda_available:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ENVIRONMENT SETUP OPTIONS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    choice = input(\"\\nDo you want to:\\n  [1] Create a NEW conda environment (recommended)\\n  [2] Use an EXISTING environment\\n  [3] Skip and use current environment\\n\\nEnter choice (1/2/3): \").strip()\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        env_name = input(\"\\nEnter name for new environment (default: tts_unified): \").strip()\n",
    "        if not env_name:\n",
    "            env_name = \"tts_unified\"\n",
    "        \n",
    "        print(f\"\\n‚Üí Creating conda environment: {env_name}\")\n",
    "        print(\"  This may take a few minutes...\")\n",
    "        \n",
    "        try:\n",
    "            subprocess.run(['conda', 'create', '-n', env_name, 'python=3.10', '-y'],\n",
    "                           check=True, capture_output=True)\n",
    "            \n",
    "            environment_created_by_notebook = True\n",
    "            environment_name = env_name\n",
    "            \n",
    "            print(f\"‚úì Environment '{env_name}' created successfully!\")\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(\"IMPORTANT: Restart your Jupyter kernel and select the new environment:\")\n",
    "            print(f\"  Kernel ‚Üí Change Kernel ‚Üí {env_name}\")\n",
    "            print(f\"{'='*60}\\n\")\n",
    "            \n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"‚úó Failed to create environment: {e}\")\n",
    "            print(\"Continuing with current environment...\")\n",
    "    \n",
    "    elif choice == \"2\":\n",
    "        env_name = input(\"\\nEnter name of existing environment: \").strip()\n",
    "        if env_name:\n",
    "            environment_name = env_name\n",
    "            print(f\"\\n‚úì Using existing environment: {env_name}\")\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(\"IMPORTANT: Make sure your kernel is using this environment:\")\n",
    "            print(f\"  Kernel ‚Üí Change Kernel ‚Üí {env_name}\")\n",
    "            print(f\"{'='*60}\\n\")\n",
    "        else:\n",
    "            print(\"‚úó No environment name provided - using current environment\")\n",
    "    \n",
    "    else:\n",
    "        print(\"\\n‚úì Using current environment\")\n",
    "\n",
    "print(\"\\nYou can now proceed with the rest of the notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Configuration - Choose Your Setup\n",
    "\n",
    "**Select which TTS model, PDF extractor, and formats you want to use.**\n",
    "\n",
    "The notebook will automatically install only the dependencies you need!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# TTS MODEL SELECTION\n",
    "# ========================================\n",
    "# Choose ONE of the following:\n",
    "#   - \"kokoro_0.9\": Kokoro v0.9+ (10 voices, English-focused, stable)\n",
    "#   - \"kokoro_1.0\": Kokoro v1.0 (54 voices, 8 languages, latest)\n",
    "#   - \"maya1\": Maya1 (20+ emotions, natural language voices, expressive, requires GPU)\n",
    "#   - \"silero_v5\": Silero v5 (Russian language, 6 speakers)\n",
    "\n",
    "TTS_MODEL = \"kokoro_1.0\"\n",
    "\n",
    "# ========================================\n",
    "# PDF EXTRACTOR SELECTION\n",
    "# ========================================\n",
    "# Choose ONE of the following:\n",
    "#   - \"unstructured\": Advanced layout analysis (recommended, ~500MB dependencies)\n",
    "#   - \"pymupdf\": Fast extraction for clean PDFs (~15MB, lightweight)\n",
    "#   - \"vision\": OCR for scanned PDFs (macOS only)\n",
    "#   - \"nougat\": Academic papers with equations (~1.5GB model)\n",
    "#   - None: Skip PDF extraction (only for text/EPUB input)\n",
    "\n",
    "PDF_EXTRACTOR = \"unstructured\"\n",
    "\n",
    "# ========================================\n",
    "# INPUT FORMATS\n",
    "# ========================================\n",
    "# Enable the input formats you plan to use:\n",
    "\n",
    "ENABLE_TEXT_INPUT = False    # Plain text strings\n",
    "ENABLE_PDF_INPUT = True     # PDF files (requires PDF_EXTRACTOR)\n",
    "ENABLE_EPUB_INPUT = False    # EPUB books\n",
    "\n",
    "# ========================================\n",
    "# OUTPUT FORMATS\n",
    "# ========================================\n",
    "# Enable the output formats you plan to use:\n",
    "\n",
    "ENABLE_WAV_OUTPUT = False    # WAV audio files\n",
    "ENABLE_MP3_OUTPUT = True    # MP3 audio files (requires ffmpeg and pydub)\n",
    "\n",
    "# ========================================\n",
    "# DEVICE CONFIGURATION\n",
    "# ========================================\n",
    "# Device to use for TTS synthesis:\n",
    "#   - \"auto\": Automatically select best device (CUDA > MPS > CPU)\n",
    "#   - \"cuda\": Force CUDA/GPU (required for Maya1)\n",
    "#   - \"cpu\": Force CPU\n",
    "#   - \"mps\": Force Apple Silicon MPS\n",
    "\n",
    "DEVICE = \"auto\"\n",
    "\n",
    "# ========================================\n",
    "# OUTPUT DIRECTORY\n",
    "# ========================================\n",
    "# Directory where generated files will be saved\n",
    "\n",
    "OUTPUT_DIR = \"files\"  # Files directory for PDFs and outputs\n",
    "\n",
    "# ========================================\n",
    "# VALIDATION\n",
    "# ========================================\n",
    "if ENABLE_PDF_INPUT and PDF_EXTRACTOR is None:\n",
    "    print(\"‚ö†Ô∏è  WARNING: PDF input enabled but no PDF extractor selected!\")\n",
    "    print(\"   Set PDF_EXTRACTOR to 'unstructured', 'pymupdf', 'vision', or 'nougat'\")\n",
    "\n",
    "if TTS_MODEL == \"maya1\":\n",
    "    import torch\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"‚ö†Ô∏è  WARNING: Maya1 requires CUDA GPU!\")\n",
    "        print(\"   Maya1 will not work properly on CPU or MPS.\")\n",
    "        print(\"   Consider using Kokoro or Silero models instead.\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CONFIGURATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"TTS Model: {TTS_MODEL}\")\n",
    "print(f\"PDF Extractor: {PDF_EXTRACTOR or 'None'}\")\n",
    "print(f\"Input Formats: Text={ENABLE_TEXT_INPUT}, PDF={ENABLE_PDF_INPUT}, EPUB={ENABLE_EPUB_INPUT}\")\n",
    "print(f\"Output Formats: WAV={ENABLE_WAV_OUTPUT}, MP3={ENABLE_MP3_OUTPUT}\")\n",
    "print(f\"Device: {DEVICE}\")\n",
    "print(f\"Output Directory: {OUTPUT_DIR}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5) Apple Silicon (MPS) Fix\n",
    "\n",
    "**Automatically detect and fix Apple Silicon compatibility issues.**\n",
    "\n",
    "If you're on Apple Silicon, this will enable CPU fallback for unsupported operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import platform\n",
    "\n",
    "# Check if we're on macOS with Apple Silicon\n",
    "is_apple_silicon = (\n",
    "    platform.system() == \"Darwin\" and \n",
    "    platform.machine() == \"arm64\"\n",
    ")\n",
    "\n",
    "if is_apple_silicon:\n",
    "    print(\"üçé Apple Silicon detected\")\n",
    "    print(\"   Enabling MPS fallback for unsupported operations...\")\n",
    "    \n",
    "    # Set environment variable to enable CPU fallback for unsupported MPS operations\n",
    "    # This fixes the 'aten::angle not implemented for MPS' error\n",
    "    os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "    \n",
    "    print(\"   ‚úì MPS fallback enabled\")\n",
    "    print(\"   Note: Some operations will fall back to CPU (slightly slower but works)\")\n",
    "else:\n",
    "    print(\"‚úì No Apple Silicon-specific fixes needed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Install Dependencies\n",
    "\n",
    "**Running automatic dependency installation...**\n",
    "\n",
    "This will install only what you need based on your configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tts_lib.setup import install_dependencies\n",
    "\n",
    "# Install dependencies based on configuration\n",
    "install_dependencies(\n",
    "    tts_model=TTS_MODEL,\n",
    "    pdf_extractor=PDF_EXTRACTOR,\n",
    "    enable_pdf_input=ENABLE_PDF_INPUT,\n",
    "    enable_epub_input=ENABLE_EPUB_INPUT,\n",
    "    enable_mp3_output=ENABLE_MP3_OUTPUT\n",
    ")\n",
    "\n",
    "print(\"\\nüöÄ Ready to initialize system!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Initialize TTS System\n",
    "\n",
    "**Loading TTS model and PDF extractor...**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tts_lib.init_system import initialize_system\n",
    "\n",
    "# Initialize TTS backend, config, and PDF extractor\n",
    "tts, config, pdf_extractor = initialize_system(\n",
    "    tts_model=TTS_MODEL,\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    device=DEVICE,\n",
    "    pdf_extractor_name=PDF_EXTRACTOR,\n",
    "    enable_pdf_input=ENABLE_PDF_INPUT\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Ready to Synthesize!\n",
    "\n",
    "All synthesis functions are loaded from the `synthesis.py` module.\n",
    "\n",
    "You can now use:\n",
    "- `synth_string()` - Convert text to audio\n",
    "- `synth_pdf()` - Convert PDF to audio  \n",
    "- `synth_epub()` - Convert EPUB to per-chapter audio ZIP\n",
    "\n",
    "Just run the example cells below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import synthesis functions from tts_lib\n",
    "from tts_lib.synthesis import synth_string, synth_pdf, synth_epub\n",
    "\n",
    "print(\"‚úì Synthesis functions ready:\")\n",
    "print(\"  ‚Ä¢ synth_string(text, voice, speed, format, ...)\")\n",
    "print(\"  ‚Ä¢ synth_pdf(pdf_path, voice, speed, format, pages, ...)\")\n",
    "print(\"  ‚Ä¢ synth_epub(epub_path, voice, speed, format, ...)\")\n",
    "print(\"\\nüí° See example cells below for usage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5) File Upload Helper (Colab Only)\n",
    "\n",
    "**If you're in Google Colab and want to upload PDFs or EPUBs, run this cell.**\n",
    "\n",
    "This provides an easy way to upload files to the Colab environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    print(\"üì§ File Upload for Google Colab\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"Run this cell to upload PDF or EPUB files to Colab\")\n",
    "    print()\n",
    "    \n",
    "    from google.colab import files\n",
    "    import shutil\n",
    "    \n",
    "    # Upload files\n",
    "    uploaded = files.upload()\n",
    "    \n",
    "    # Move uploaded files to 'files' directory\n",
    "    for filename in uploaded.keys():\n",
    "        dest_path = f\"files/{filename}\"\n",
    "        shutil.move(filename, dest_path)\n",
    "        print(f\"‚úì Moved {filename} to {dest_path}\")\n",
    "    \n",
    "    print()\n",
    "    print(\"‚úì Upload complete! You can now use these files in the examples below.\")\n",
    "    print(f\"  Uploaded files: {list(uploaded.keys())}\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  This cell is only for Google Colab\")\n",
    "    print(\"  You're running locally, so use your file system directly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage Examples\n",
    "\n",
    "Run the examples below to synthesize text, PDFs, and EPUBs.\n",
    "\n",
    "**Note:** Only the examples for enabled input/output formats will work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A) String ‚Üí Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ENABLE_TEXT_INPUT:\n",
    "    print(\"‚ö†Ô∏è  Text input is disabled. Set ENABLE_TEXT_INPUT=True to use this example.\")\n",
    "else:\n",
    "    # Configuration\n",
    "    VOICE = None  # Use default voice (or specify a voice description)\n",
    "    SPEED = 1.0   # Speech speed (Kokoro and Maya1 only)\n",
    "    FORMAT = \"mp3\" if ENABLE_MP3_OUTPUT else \"wav\"\n",
    "    BASENAME = \"tts_text\"\n",
    "\n",
    "    # Text to synthesize\n",
    "    # For Maya1: You can add emotion tags like <laugh>, <whisper>, <cry>, etc.\n",
    "    TEXT = \"\"\"Hello! This is a test of the unified TTS system.\n",
    "    It automatically installs only the dependencies you need.\n",
    "    \"\"\"\n",
    "\n",
    "    # Run synthesis\n",
    "    audio_path, manifest_path = synth_string(\n",
    "        tts=tts,\n",
    "        config=config,\n",
    "        text=TEXT,\n",
    "        voice=VOICE,\n",
    "        speed=SPEED,\n",
    "        out_format=FORMAT,\n",
    "        basename=BASENAME,\n",
    "        tts_model=TTS_MODEL,\n",
    "        enable_text_input=ENABLE_TEXT_INPUT,\n",
    "        enable_mp3_output=ENABLE_MP3_OUTPUT\n",
    "    )\n",
    "\n",
    "    print(f\"\\n‚úì Audio saved to: {audio_path}\")\n",
    "    print(f\"‚úì Manifest saved to: {manifest_path}\")\n",
    "    \n",
    "    if IN_COLAB:\n",
    "        print(\"\\nüí° To download the files, run:\")\n",
    "        print(f\"   from google.colab import files\")\n",
    "        print(f\"   files.download('{audio_path}')\")\n",
    "        print(f\"   files.download('{manifest_path}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) PDF ‚Üí Audio (with page selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ENABLE_PDF_INPUT:\n",
    "    print(\"‚ö†Ô∏è  PDF input is disabled. Set ENABLE_PDF_INPUT=True and PDF_EXTRACTOR to use this example.\")\n",
    "else:\n",
    "    # Configuration\n",
    "    VOICE = None  # Use default voice\n",
    "    SPEED = 1.0\n",
    "    FORMAT = \"mp3\" if ENABLE_MP3_OUTPUT else \"wav\"\n",
    "\n",
    "    # PDF file path\n",
    "    # For Google Colab: Upload your PDF first using the file upload button\n",
    "    # For local: Use the path to your PDF file\n",
    "    PDF_PATH = \"files/Case1Writeup.pdf\"  # Change this to your PDF filename\n",
    "    \n",
    "    # Check if file exists, provide helpful message if not\n",
    "    import os\n",
    "    if not os.path.exists(PDF_PATH):\n",
    "        print(f\"‚ö†Ô∏è  PDF file not found: {PDF_PATH}\")\n",
    "        if IN_COLAB:\n",
    "            print(\"\\nüì§ To upload a PDF in Colab, run:\")\n",
    "            print(\"   from google.colab import files\")\n",
    "            print(\"   uploaded = files.upload()\")\n",
    "            print(\"   # Then move it: !mv uploaded_file.pdf files/\")\n",
    "        else:\n",
    "            print(\"\\nüí° Make sure your PDF is in the 'files' directory\")\n",
    "            print(\"   Or update PDF_PATH to point to your PDF file\")\n",
    "    else:\n",
    "        # Page selection (optional)\n",
    "        # None = all pages (default)\n",
    "        # [1, 2, 3] = only pages 1, 2, and 3\n",
    "        # [5] = only page 5\n",
    "        PAGES = None\n",
    "\n",
    "        # Run synthesis\n",
    "        audio_path, manifest_path = synth_pdf(\n",
    "            tts=tts,\n",
    "            config=config,\n",
    "            pdf_extractor=pdf_extractor,\n",
    "            file_path_or_bytes=PDF_PATH,\n",
    "            voice=VOICE,\n",
    "            speed=SPEED,\n",
    "            out_format=FORMAT,\n",
    "            pages=PAGES,\n",
    "            tts_model=TTS_MODEL,\n",
    "            enable_pdf_input=ENABLE_PDF_INPUT,\n",
    "            enable_mp3_output=ENABLE_MP3_OUTPUT\n",
    "        )\n",
    "\n",
    "        print(f\"\\n‚úì Audio saved to: {audio_path}\")\n",
    "        print(f\"‚úì Manifest saved to: {manifest_path}\")\n",
    "        \n",
    "        if IN_COLAB:\n",
    "            print(\"\\nüí° To download the files, run:\")\n",
    "            print(f\"   from google.colab import files\")\n",
    "            print(f\"   files.download('{audio_path}')\")\n",
    "            print(f\"   files.download('{manifest_path}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) EPUB ‚Üí ZIP (Per-Chapter Audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not ENABLE_EPUB_INPUT:\n",
    "    print(\"‚ö†Ô∏è  EPUB input is disabled. Set ENABLE_EPUB_INPUT=True to use this example.\")\n",
    "else:\n",
    "    # Configuration\n",
    "    VOICE = None  # Use default voice\n",
    "    SPEED = 1.0\n",
    "    CHAPTER_FORMAT = \"mp3\" if ENABLE_MP3_OUTPUT else \"wav\"\n",
    "    ZIP_NAME = \"\"  # Optional: custom name for ZIP file\n",
    "\n",
    "    # EPUB file path\n",
    "    # For Google Colab: Upload your EPUB first\n",
    "    # For local: Use the path to your EPUB file\n",
    "    EPUB_PATH = \"book.epub\"  # Change this to your EPUB filename\n",
    "    \n",
    "    # Check if file exists, provide helpful message if not\n",
    "    import os\n",
    "    if not os.path.exists(EPUB_PATH):\n",
    "        print(f\"‚ö†Ô∏è  EPUB file not found: {EPUB_PATH}\")\n",
    "        if IN_COLAB:\n",
    "            print(\"\\nüì§ To upload an EPUB in Colab, run:\")\n",
    "            print(\"   from google.colab import files\")\n",
    "            print(\"   uploaded = files.upload()\")\n",
    "        else:\n",
    "            print(\"\\nüí° Make sure your EPUB file exists\")\n",
    "            print(\"   Or update EPUB_PATH to point to your EPUB file\")\n",
    "    else:\n",
    "        # Run synthesis\n",
    "        zip_path = synth_epub(\n",
    "            tts=tts,\n",
    "            config=config,\n",
    "            file_path_or_bytes=EPUB_PATH,\n",
    "            voice=VOICE,\n",
    "            speed=SPEED,\n",
    "            per_chapter_format=CHAPTER_FORMAT,\n",
    "            zip_name=(ZIP_NAME or None),\n",
    "            tts_model=TTS_MODEL,\n",
    "            enable_epub_input=ENABLE_EPUB_INPUT,\n",
    "            enable_mp3_output=ENABLE_MP3_OUTPUT\n",
    "        )\n",
    "\n",
    "        print(f\"\\n‚úì ZIP archive saved to: {zip_path}\")\n",
    "        \n",
    "        if IN_COLAB:\n",
    "            print(\"\\nüí° To download the ZIP file, run:\")\n",
    "            print(f\"   from google.colab import files\")\n",
    "            print(f\"   files.download('{zip_path}')\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- **Switching Models**: To use a different TTS model or PDF extractor, change the settings in Section 1 and re-run from there\n",
    "- **Voice Selection**: Each model has different voices. Check the output of Section 3 for available voices\n",
    "- **Manifest Files**: Each audio output includes a JSON manifest with sentence-level timing and coordinates\n",
    "- **Dependencies**: Only the packages needed for your selected configuration were installed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup: Delete Environment (Optional)\n",
    "\n",
    "**If you created a new environment at the beginning of this notebook**, you can delete it here to free up storage space.\n",
    "\n",
    "‚ö†Ô∏è **Warning**: This will permanently delete the environment and all installed packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "if 'environment_created_by_notebook' not in globals():\n",
    "    print(\"‚úó No environment tracking found\")\n",
    "    print(\"This cell only works if you ran the environment setup cell at the beginning\")\n",
    "elif not environment_created_by_notebook:\n",
    "    print(\"‚úó No environment was created by this notebook\")\n",
    "    print(\"You can only delete environments that were created in this session\")\n",
    "else:\n",
    "    print(f\"Environment '{environment_name}' was created by this notebook\")\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"DELETE ENVIRONMENT\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    confirm = input(f\"\\nAre you sure you want to DELETE '{environment_name}'?\\nType 'yes' to confirm: \").strip().lower()\n",
    "    \n",
    "    if confirm == 'yes':\n",
    "        print(f\"\\n‚Üí Deleting environment '{environment_name}'...\")\n",
    "        print(\"  This may take a moment...\")\n",
    "        \n",
    "        try:\n",
    "            subprocess.run(['conda', 'env', 'remove', '-n', environment_name, '-y'],\n",
    "                           check=True, capture_output=True)\n",
    "            print(f\"‚úì Environment '{environment_name}' deleted successfully!\")\n",
    "            print(\"  Storage space has been freed.\")\n",
    "            \n",
    "            environment_created_by_notebook = False\n",
    "            environment_name = None\n",
    "            \n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"‚úó Failed to delete environment: {e}\")\n",
    "            print(f\"You may need to delete it manually with: conda env remove -n {environment_name}\")\n",
    "    else:\n",
    "        print(\"\\n‚úó Deletion cancelled - environment preserved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Memory Management: View & Delete Models\n",
    "\n",
    "**View all locally cached models, their sizes, and manage storage.**\n",
    "\n",
    "This section helps you:\n",
    "- See which models are downloaded and how much space they use\n",
    "- Delete specific models to free up storage\n",
    "- Clean PyTorch and HuggingFace caches\n",
    "- Clear GPU/MPS memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "\n",
    "def get_dir_size(path):\n",
    "    \"\"\"Calculate total size of a directory in bytes.\"\"\"\n",
    "    total = 0\n",
    "    try:\n",
    "        for entry in os.scandir(path):\n",
    "            if entry.is_file(follow_symlinks=False):\n",
    "                total += entry.stat().st_size\n",
    "            elif entry.is_dir(follow_symlinks=False):\n",
    "                total += get_dir_size(entry.path)\n",
    "    except (PermissionError, FileNotFoundError):\n",
    "        pass\n",
    "    return total\n",
    "\n",
    "def format_bytes(bytes_size):\n",
    "    \"\"\"Format bytes to human-readable size.\"\"\"\n",
    "    for unit in ['B', 'KB', 'MB', 'GB', 'TB']:\n",
    "        if bytes_size < 1024.0:\n",
    "            return f\"{bytes_size:.2f} {unit}\"\n",
    "        bytes_size /= 1024.0\n",
    "    return f\"{bytes_size:.2f} PB\"\n",
    "\n",
    "def scan_cached_models():\n",
    "    \"\"\"Scan for cached models in common locations.\"\"\"\n",
    "    home = Path.home()\n",
    "    \n",
    "    cache_locations = {\n",
    "        \"HuggingFace Cache\": home / \".cache\" / \"huggingface\",\n",
    "        \"Torch Hub\": home / \".cache\" / \"torch\" / \"hub\",\n",
    "        \"Torch Checkpoints\": home / \".cache\" / \"torch\" / \"checkpoints\",\n",
    "        \"Detectron2\": home / \".torch\" / \"fvcore_cache\" / \"detectron2\",\n",
    "        \"Kokoro Models\": home / \".cache\" / \"kokoro\",\n",
    "    }\n",
    "    \n",
    "    results = []\n",
    "    total_size = 0\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(\"SCANNING CACHED MODELS\")\n",
    "    print(\"=\" * 80)\n",
    "    print()\n",
    "    \n",
    "    for name, path in cache_locations.items():\n",
    "        if path.exists():\n",
    "            size = get_dir_size(path)\n",
    "            if size > 0:\n",
    "                results.append({\n",
    "                    \"name\": name,\n",
    "                    \"path\": str(path),\n",
    "                    \"size\": size,\n",
    "                    \"size_formatted\": format_bytes(size)\n",
    "                })\n",
    "                total_size += size\n",
    "                print(f\"üì¶ {name}\")\n",
    "                print(f\"   Path: {path}\")\n",
    "                print(f\"   Size: {format_bytes(size)}\")\n",
    "                \n",
    "                # Try to list specific models if it's HuggingFace cache\n",
    "                if name == \"HuggingFace Cache\":\n",
    "                    models_dir = path / \"hub\"\n",
    "                    if models_dir.exists():\n",
    "                        model_folders = [d for d in models_dir.iterdir() if d.is_dir() and d.name.startswith(\"models--\")]\n",
    "                        if model_folders:\n",
    "                            print(f\"   Models found: {len(model_folders)}\")\n",
    "                            for model_folder in sorted(model_folders)[:5]:  # Show first 5\n",
    "                                model_name = model_folder.name.replace(\"models--\", \"\").replace(\"--\", \"/\")\n",
    "                                model_size = get_dir_size(model_folder)\n",
    "                                print(f\"     ‚Ä¢ {model_name}: {format_bytes(model_size)}\")\n",
    "                            if len(model_folders) > 5:\n",
    "                                print(f\"     ... and {len(model_folders) - 5} more\")\n",
    "                \n",
    "                # Try to list PyTorch Hub models\n",
    "                elif name == \"Torch Hub\":\n",
    "                    checkpoints = list(path.glob(\"checkpoints/*.pth\")) + list(path.glob(\"*.pth\"))\n",
    "                    if checkpoints:\n",
    "                        print(f\"   Checkpoints found: {len(checkpoints)}\")\n",
    "                        for ckpt in sorted(checkpoints)[:5]:\n",
    "                            ckpt_size = ckpt.stat().st_size\n",
    "                            print(f\"     ‚Ä¢ {ckpt.name}: {format_bytes(ckpt_size)}\")\n",
    "                        if len(checkpoints) > 5:\n",
    "                            print(f\"     ... and {len(checkpoints) - 5} more\")\n",
    "                \n",
    "                print()\n",
    "        else:\n",
    "            print(f\"‚ö™ {name}\")\n",
    "            print(f\"   Path: {path}\")\n",
    "            print(f\"   Status: Not found\")\n",
    "            print()\n",
    "    \n",
    "    print(\"=\" * 80)\n",
    "    print(f\"TOTAL CACHED SIZE: {format_bytes(total_size)}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    return results, total_size\n",
    "\n",
    "# Run the scan\n",
    "cached_models, total_cache_size = scan_cached_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Delete Cached Models\n",
    "\n",
    "**Select which caches to delete.**\n",
    "\n",
    "Choose what you want to clean up to free storage space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_cache(cache_name):\n",
    "    \"\"\"Delete a specific cache directory.\"\"\"\n",
    "    home = Path.home()\n",
    "    \n",
    "    cache_paths = {\n",
    "        \"huggingface\": home / \".cache\" / \"huggingface\",\n",
    "        \"torch_hub\": home / \".cache\" / \"torch\" / \"hub\",\n",
    "        \"torch_checkpoints\": home / \".cache\" / \"torch\" / \"checkpoints\",\n",
    "        \"detectron2\": home / \".torch\" / \"fvcore_cache\" / \"detectron2\",\n",
    "        \"kokoro\": home / \".cache\" / \"kokoro\",\n",
    "        \"pip\": home / \".cache\" / \"pip\",\n",
    "    }\n",
    "    \n",
    "    if cache_name not in cache_paths:\n",
    "        print(f\"‚úó Unknown cache: {cache_name}\")\n",
    "        print(f\"Available caches: {', '.join(cache_paths.keys())}\")\n",
    "        return False\n",
    "    \n",
    "    cache_path = cache_paths[cache_name]\n",
    "    \n",
    "    if not cache_path.exists():\n",
    "        print(f\"‚ö™ Cache not found: {cache_path}\")\n",
    "        return False\n",
    "    \n",
    "    size_before = get_dir_size(cache_path)\n",
    "    print(f\"‚Üí Deleting {cache_name} cache...\")\n",
    "    print(f\"  Path: {cache_path}\")\n",
    "    print(f\"  Size: {format_bytes(size_before)}\")\n",
    "    \n",
    "    try:\n",
    "        shutil.rmtree(cache_path)\n",
    "        print(f\"‚úì Successfully deleted {cache_name} cache\")\n",
    "        print(f\"  Freed: {format_bytes(size_before)}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚úó Failed to delete cache: {e}\")\n",
    "        return False\n",
    "\n",
    "\n",
    "# Interactive deletion\n",
    "print(\"=\" * 80)\n",
    "print(\"DELETE CACHE OPTIONS\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "print(\"Available caches to delete:\")\n",
    "print(\"  [1] HuggingFace Cache\")\n",
    "print(\"  [2] Torch Hub\")\n",
    "print(\"  [3] Torch Checkpoints\")\n",
    "print(\"  [4] Detectron2\")\n",
    "print(\"  [5] Kokoro Models\")\n",
    "print(\"  [6] Pip Cache\")\n",
    "print(\"  [7] ALL caches (‚ö†Ô∏è  WARNING: Deletes everything!)\")\n",
    "print(\"  [0] Cancel\")\n",
    "print()\n",
    "\n",
    "choice = input(\"Enter choice (0-7): \").strip()\n",
    "\n",
    "cache_map = {\n",
    "    \"1\": \"huggingface\",\n",
    "    \"2\": \"torch_hub\",\n",
    "    \"3\": \"torch_checkpoints\",\n",
    "    \"4\": \"detectron2\",\n",
    "    \"5\": \"kokoro\",\n",
    "    \"6\": \"pip\",\n",
    "}\n",
    "\n",
    "if choice == \"0\":\n",
    "    print(\"\\n‚úó Deletion cancelled\")\n",
    "elif choice == \"7\":\n",
    "    confirm = input(\"\\n‚ö†Ô∏è  Delete ALL caches? Type 'yes' to confirm: \").strip().lower()\n",
    "    if confirm == \"yes\":\n",
    "        print(\"\\n‚Üí Deleting all caches...\")\n",
    "        total_freed = 0\n",
    "        for cache_name in cache_map.values():\n",
    "            if delete_cache(cache_name):\n",
    "                print()\n",
    "        print(\"=\" * 80)\n",
    "        print(\"‚úì All caches deleted\")\n",
    "        print(\"=\" * 80)\n",
    "    else:\n",
    "        print(\"\\n‚úó Deletion cancelled\")\n",
    "elif choice in cache_map:\n",
    "    cache_name = cache_map[choice]\n",
    "    confirm = input(f\"\\nDelete {cache_name} cache? Type 'yes' to confirm: \").strip().lower()\n",
    "    if confirm == \"yes\":\n",
    "        print()\n",
    "        delete_cache(cache_name)\n",
    "    else:\n",
    "        print(\"\\n‚úó Deletion cancelled\")\n",
    "else:\n",
    "    print(\"\\n‚úó Invalid choice\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clear GPU/MPS Memory\n",
    "\n",
    "**Free up GPU or MPS (Apple Silicon) memory.**\n",
    "\n",
    "Run this cell to clear PyTorch's memory cache and force garbage collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CLEARING GPU/MPS MEMORY\")\n",
    "print(\"=\" * 80)\n",
    "print()\n",
    "\n",
    "# Check current memory usage (if applicable)\n",
    "if torch.cuda.is_available():\n",
    "    print(\"üìä CUDA Memory Status (before cleanup):\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        allocated = torch.cuda.memory_allocated(i) / 1024**2\n",
    "        reserved = torch.cuda.memory_reserved(i) / 1024**2\n",
    "        print(f\"   GPU {i}: {allocated:.2f} MB allocated, {reserved:.2f} MB reserved\")\n",
    "    print()\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"üìä MPS (Apple Silicon) detected\")\n",
    "    print(\"   Note: MPS doesn't provide detailed memory stats\")\n",
    "    print()\n",
    "else:\n",
    "    print(\"üìä No GPU/MPS detected - running on CPU\")\n",
    "    print()\n",
    "\n",
    "# Clear PyTorch cache\n",
    "print(\"‚Üí Clearing PyTorch cache...\")\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    print(\"‚úì CUDA cache cleared\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    torch.mps.empty_cache()\n",
    "    torch.mps.synchronize()\n",
    "    print(\"‚úì MPS cache cleared\")\n",
    "else:\n",
    "    print(\"‚ö™ No GPU cache to clear (CPU mode)\")\n",
    "\n",
    "# Force garbage collection\n",
    "print(\"\\n‚Üí Running garbage collection...\")\n",
    "gc.collect()\n",
    "print(\"‚úì Garbage collection completed\")\n",
    "\n",
    "# Check memory usage after cleanup\n",
    "print()\n",
    "if torch.cuda.is_available():\n",
    "    print(\"üìä CUDA Memory Status (after cleanup):\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        allocated = torch.cuda.memory_allocated(i) / 1024**2\n",
    "        reserved = torch.cuda.memory_reserved(i) / 1024**2\n",
    "        print(f\"   GPU {i}: {allocated:.2f} MB allocated, {reserved:.2f} MB reserved\")\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"üìä MPS cache has been cleared\")\n",
    "    print(\"   Memory should be freed for other applications\")\n",
    "\n",
    "print()\n",
    "print(\"=\" * 80)\n",
    "print(\"‚úì MEMORY CLEANUP COMPLETE\")\n",
    "print(\"=\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
