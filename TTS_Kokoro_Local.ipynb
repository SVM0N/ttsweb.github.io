{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# TTS v4 - Local Version (Kokoro)\n",
    "- Adapted for running locally with Kokoro TTS\n",
    "- Includes sentence tracking and timeline manifest generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gwu8vbbzwi",
   "source": "## 0) Environment Setup (Optional)\n\n**This step helps you manage Python packages and avoid conflicts with your system installation.**\n\n- If you have **conda** installed, you can create a fresh environment for this notebook\n- Or use an existing environment by providing its name\n- At the end of the notebook, you can easily clean up and delete the environment to free storage",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "nesi2km313s",
   "source": "import subprocess\nimport sys\nimport os\n\n# Flag to track if we created an environment in this notebook\nenvironment_created_by_notebook = False\nenvironment_name = None\n\n# Check if conda is installed\ntry:\n    result = subprocess.run(['conda', '--version'], capture_output=True, text=True, check=True)\n    conda_available = True\n    print(f\"✓ Conda detected: {result.stdout.strip()}\")\nexcept (subprocess.CalledProcessError, FileNotFoundError):\n    conda_available = False\n    print(\"✗ Conda not found - skipping environment management\")\n    print(\"Packages will be installed in your current Python environment\")\n\nif conda_available:\n    print(\"\\n\" + \"=\"*60)\n    print(\"ENVIRONMENT SETUP OPTIONS\")\n    print(\"=\"*60)\n    \n    choice = input(\"\\nDo you want to:\\n  [1] Create a NEW conda environment (recommended)\\n  [2] Use an EXISTING environment\\n  [3] Skip and use current environment\\n\\nEnter choice (1/2/3): \").strip()\n    \n    if choice == \"1\":\n        # Create new environment\n        env_name = input(\"\\nEnter name for new environment (default: kokoro_tts): \").strip()\n        if not env_name:\n            env_name = \"kokoro_tts\"\n        \n        print(f\"\\n→ Creating conda environment: {env_name}\")\n        print(\"  This may take a few minutes...\")\n        \n        try:\n            # Create environment with Python 3.10\n            subprocess.run(['conda', 'create', '-n', env_name, 'python=3.10', '-y'], \n                          check=True, capture_output=True)\n            \n            environment_created_by_notebook = True\n            environment_name = env_name\n            \n            print(f\"✓ Environment '{env_name}' created successfully!\")\n            print(f\"\\n{'='*60}\")\n            print(\"IMPORTANT: Restart your Jupyter kernel and select the new environment:\")\n            print(f\"  Kernel → Change Kernel → {env_name}\")\n            print(f\"{'='*60}\\n\")\n            \n        except subprocess.CalledProcessError as e:\n            print(f\"✗ Failed to create environment: {e}\")\n            print(\"Continuing with current environment...\")\n    \n    elif choice == \"2\":\n        # Use existing environment\n        env_name = input(\"\\nEnter name of existing environment: \").strip()\n        if env_name:\n            environment_name = env_name\n            print(f\"\\n✓ Using existing environment: {env_name}\")\n            print(f\"\\n{'='*60}\")\n            print(\"IMPORTANT: Make sure your kernel is using this environment:\")\n            print(f\"  Kernel → Change Kernel → {env_name}\")\n            print(f\"{'='*60}\\n\")\n        else:\n            print(\"✗ No environment name provided - using current environment\")\n    \n    else:\n        print(\"\\n✓ Using current environment\")\n\nprint(\"\\nYou can now proceed with the rest of the notebook.\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "install-header",
   "metadata": {},
   "source": [
    "## 1) Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core TTS + I/O deps\n",
    "!pip install \"kokoro>=0.9.4\" soundfile misaki[en] pypdf ebooklib pydub\n",
    "\n",
    "# Advanced PDF extraction\n",
    "!pip install \"unstructured[local-inference]\"\n",
    "!pip install \"detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2\"\n",
    "\n",
    "# Note: ffmpeg should be installed on your system for MP3 encoding\n",
    "# Linux: sudo apt-get install ffmpeg\n",
    "# macOS: brew install ffmpeg\n",
    "# Windows: Download from https://ffmpeg.org/\n",
    "\n",
    "# Silence overly chatty logs\n",
    "import logging\n",
    "logging.getLogger(\"phonemizer\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"unstructured\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"pypdf\").setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## 2) Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": "import os\nfrom pathlib import Path\n\n# --- Output directory setup ---\nOUTPUT_DIR = Path(\".\")  # Use current directory (same as notebook location)\nprint(f\"Output directory: {OUTPUT_DIR.resolve()}\")\n\n# --- Device selection ---\n# DEVICE_MODE: \"auto\" (default), \"cuda\", or \"cpu\"\nDEVICE_MODE = \"auto\"\n\nimport torch\ndef _pick_device():\n    if DEVICE_MODE == \"cuda\":\n        return \"cuda\"\n    if DEVICE_MODE == \"cpu\":\n        return \"cpu\"\n    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nDEVICE = _pick_device()\nprint(f\"Using device: {DEVICE}\")"
  },
  {
   "cell_type": "markdown",
   "id": "helpers-header",
   "metadata": {},
   "source": [
    "## 3) Helper Functions (PDF/EPUB extraction & TTS synthesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpers",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import re, io, zipfile, torch\n",
    "from pathlib import Path\n",
    "from typing import List, Tuple, Dict, Union\n",
    "from functools import lru_cache\n",
    "\n",
    "from pypdf import PdfReader\n",
    "from ebooklib import epub\n",
    "from kokoro import KPipeline\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# Imports for advanced PDF extraction\n",
    "from unstructured.partition.auto import partition\n",
    "\n",
    "# Sentence-ish split; keeps chunks small (avoids 510-phoneme truncation)\n",
    "SPLIT_PATTERN = r\"[.?!]\\s+|[\\n]{2,}\"\n",
    "SPLIT_PATTERN_CAP = r\"([.?!]\\s+|[\\n]{2,})\"\n",
    "\n",
    "\n",
    "# --- PDF Extraction using unstructured.io ---\n",
    "def extract_text_from_pdf(file_like: io.BytesIO) -> List[Dict]:\n",
    "    \"\"\"Extract text from PDF using unstructured.io with layout analysis.\"\"\"\n",
    "    print(\"Parsing PDF with layout analysis (strategy='hi_res')...\")\n",
    "    try:\n",
    "        partitioned_elements = partition(file=file_like, strategy=\"hi_res\", content_type=\"application/pdf\", include_page_breaks=True)\n",
    "        print(f\"Unstructured 'hi_res' returned {len(partitioned_elements)} raw elements.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Unstructured 'hi_res' strategy failed: {e}. Falling back to 'fast'.\")\n",
    "        try:\n",
    "            file_like.seek(0)\n",
    "            partitioned_elements = partition(file=file_like, strategy=\"fast\", content_type=\"application/pdf\", include_page_breaks=True)\n",
    "            print(f\"Unstructured 'fast' returned {len(partitioned_elements)} raw elements.\")\n",
    "        except Exception as e2:\n",
    "            print(f\"Unstructured 'fast' strategy also failed: {e2}.\")\n",
    "            return [{\"text\": \"Error: Unstructured parsing failed.\", \"metadata\": {\"page_number\": 1, \"points\": None}}]\n",
    "\n",
    "    element_list = []\n",
    "    current_page = 1\n",
    "    print(\"\\n--- Processing elements (checking for points) ---\")\n",
    "\n",
    "    for i, el in enumerate(partitioned_elements):\n",
    "        meta_dict = el.metadata.to_dict()\n",
    "\n",
    "        page_num_meta = meta_dict.get(\"page_number\")\n",
    "        if page_num_meta is not None:\n",
    "             current_page = page_num_meta\n",
    "\n",
    "        # Extract coordinate points if available\n",
    "        points = None\n",
    "        coords_meta = meta_dict.get(\"coordinates\")\n",
    "        if coords_meta:\n",
    "            points = coords_meta.get(\"points\")\n",
    "\n",
    "        location_data = {\n",
    "            \"page_number\": current_page,\n",
    "            \"points\": points\n",
    "        }\n",
    "\n",
    "        element_text = str(el).strip()\n",
    "        if element_text:\n",
    "            element_list.append({\n",
    "                \"text\": element_text,\n",
    "                \"metadata\": location_data\n",
    "            })\n",
    "\n",
    "    print(\"--- Finished processing elements ---\")\n",
    "    print(f\"Unstructured: Found {len(element_list)} text elements.\")\n",
    "    if not element_list:\n",
    "         return [{\"text\": \"Warning: Unstructured found no text elements.\", \"metadata\": {\"page_number\": 1, \"points\": None}}]\n",
    "    return element_list\n",
    "\n",
    "\n",
    "# --- EPUB Extraction ---\n",
    "def extract_chapters_from_epub(file_like: io.BytesIO):\n",
    "    bk = epub.read_epub(file_like)\n",
    "    chapters = []\n",
    "    for item in bk.get_items_of_type(epub.ITEM_DOCUMENT):\n",
    "        if getattr(item, \"is_nav\", False): continue\n",
    "        html = item.get_content().decode(\"utf-8\", errors=\"ignore\")\n",
    "        text = re.sub(r\"<(script|style).*?>.*?</\\1>\", \" \", html, flags=re.S|re.I)\n",
    "        text = re.sub(r\"<br\\s*/?>\", \"\\n\", text, flags=re.I)\n",
    "        text = re.sub(r\"</p>|</div>|</h\\d>\", \"\\n\\n\", text, flags=re.I)\n",
    "        text = re.sub(r\"<[^>]+>\", \" \", text)\n",
    "        text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "        text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text).strip()\n",
    "        if text:\n",
    "            title = Path(item.file_name).stem\n",
    "            first = text.splitlines()[0] if text else \"\"; m = re.match(r\"(?i)\\s*(chapter|part|book)\\b[^\\n]{0,80}\", first)\n",
    "            if m: title = first[:60]\n",
    "            chapters.append((title, text))\n",
    "    if not chapters:\n",
    "        blobs = [];\n",
    "        for item in bk.get_items_of_type(epub.ITEM_DOCUMENT):\n",
    "             if getattr(item, \"is_nav\", False): continue\n",
    "             blobs.append(item.get_content().decode(\"utf-8\", errors=\"ignore\"))\n",
    "        html = \" \".join(blobs)\n",
    "        text = re.sub(r\"<(script|style).*?>.*?</\\1>\", \" \", html, flags=re.S|re.I)\n",
    "        text = re.sub(r\"<br\\s*/?>\", \"\\n\", text, flags=re.I)\n",
    "        text = re.sub(r\"</p>|</div>|</h\\d>\", \"\\n\\n\", text, flags=re.I)\n",
    "        text = re.sub(r\"<[^>]+>\", \" \", text)\n",
    "        text = re.sub(r\"[ \\t]+\", \" \", text)\n",
    "        text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text).strip()\n",
    "        if text: chapters = [(\"Chapter 1\", text)]\n",
    "    return chapters\n",
    "\n",
    "def safe_name(s: str) -> str:\n",
    "    s = re.sub(r\"[^\\w\\-]+\", \"_\", s).strip(\"_\"); return s or \"chapter\"\n",
    "\n",
    "# --- Pipeline cache ---\n",
    "@lru_cache(maxsize=4)\n",
    "def get_pipeline(lang_code='a', device=DEVICE):\n",
    "    return KPipeline(lang_code=lang_code, device=device)\n",
    "\n",
    "def _synthesize_sentence(pipe: KPipeline, sentence: str, voice='af_heart', speed=1.0) -> np.ndarray:\n",
    "    subchunks = [];\n",
    "    for _, _, audio in pipe(sentence, voice=voice, speed=speed, split_pattern=None): subchunks.append(audio)\n",
    "    if not subchunks: return np.zeros((0,), dtype=np.float32)\n",
    "    return np.concatenate(subchunks, axis=0)\n",
    "\n",
    "def split_sentences_keep_delim(text: str) -> List[str]:\n",
    "    parts = re.split(SPLIT_PATTERN_CAP, text); sents = []\n",
    "    for i in range(0, len(parts), 2):\n",
    "        chunk = (parts[i] or \"\").strip(); sep = parts[i+1] if i+1 < len(parts) else \"\"\n",
    "        if not chunk: continue\n",
    "        if sep and not sep.isspace(): chunk = (chunk + \" \" + sep.strip()).strip()\n",
    "        sents.append(chunk)\n",
    "    return sents\n",
    "\n",
    "# --- Synthesizer ---\n",
    "def synth_text_to_wav_and_manifest(\n",
    "    text_or_elements: Union[str, List[Dict]],\n",
    "    voice='af_heart',\n",
    "    speed=1.0,\n",
    "    lang_code='a',\n",
    "    device=DEVICE) -> Tuple[bytes, Dict]:\n",
    "    pipe = get_pipeline(lang_code=lang_code, device=device)\n",
    "    sr = 24000\n",
    "\n",
    "    if isinstance(text_or_elements, str):\n",
    "        elements = [{\"text\": text_or_elements, \"metadata\": {\"page_number\": 1, \"points\": None}}]\n",
    "    else:\n",
    "        elements = text_or_elements\n",
    "\n",
    "    pcm_all = []; timeline = []; t = 0.0; sentence_index = 0\n",
    "    print(f\"Synthesizing {len(elements)} text elements...\")\n",
    "\n",
    "    for element in elements:\n",
    "        element_text = element.get(\"text\", \"\")\n",
    "        element_meta = element.get(\"metadata\", {})\n",
    "\n",
    "        sentences = split_sentences_keep_delim(element_text)\n",
    "\n",
    "        for sent in sentences:\n",
    "            if not sent: continue\n",
    "            pcm = _synthesize_sentence(pipe, sent, voice=voice, speed=speed)\n",
    "            dur = pcm.shape[0] / sr\n",
    "            timeline.append({\n",
    "                \"i\": sentence_index,\n",
    "                \"start\": round(t, 3),\n",
    "                \"end\": round(t + dur, 3),\n",
    "                \"text\": sent.strip(),\n",
    "                \"location\": element_meta\n",
    "            })\n",
    "            pcm_all.append(pcm); t += dur; sentence_index += 1\n",
    "\n",
    "    pcm_cat = np.concatenate(pcm_all, axis=0) if pcm_all else np.zeros((sr//10,), dtype=np.float32)\n",
    "    buf = io.BytesIO(); sf.write(buf, pcm_cat, sr, format='WAV'); buf.seek(0)\n",
    "    manifest = {\"audioUrl\": \"\", \"sentences\": timeline}\n",
    "    return buf.read(), manifest\n",
    "\n",
    "def wav_to_mp3_bytes(wav_bytes: bytes, bitrate=\"128k\") -> bytes:\n",
    "    audio = AudioSegment.from_file(io.BytesIO(wav_bytes), format=\"wav\"); out = io.BytesIO()\n",
    "    audio.export(out, format=\"mp3\", bitrate=bitrate); out.seek(0); return out.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthesis-header",
   "metadata": {},
   "source": [
    "## 4) High-Level Synthesis Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthesis-wrappers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synth_string(text: str,\n",
    "                 voice=\"af_heart\",\n",
    "                 speed=1.0,\n",
    "                 out_format=\"wav\",\n",
    "                 lang_code=\"a\",\n",
    "                 device=None,\n",
    "                 basename=\"kokoro_text\",\n",
    "                 output_dir=None):\n",
    "    device = device or DEVICE\n",
    "    output_dir = Path(output_dir) if output_dir else OUTPUT_DIR\n",
    "\n",
    "    elements = [{\n",
    "        \"text\": text,\n",
    "        \"metadata\": {\"page_number\": 1, \"source\": \"string\", \"coordinates\": None}\n",
    "    }]\n",
    "\n",
    "    wav_bytes, manifest = synth_text_to_wav_and_manifest(\n",
    "        elements,\n",
    "        voice=voice, speed=speed, lang_code=lang_code, device=device\n",
    "    )\n",
    "\n",
    "    out_base = output_dir / basename\n",
    "\n",
    "    if out_format.lower() == \"mp3\":\n",
    "        mp3 = wav_to_mp3_bytes(wav_bytes)\n",
    "        audio_path = str(out_base) + \".mp3\"\n",
    "        with open(audio_path, \"wb\") as f: f.write(mp3)\n",
    "    else:\n",
    "        audio_path = str(out_base) + \".wav\"\n",
    "        with open(audio_path, \"wb\") as f: f.write(wav_bytes)\n",
    "\n",
    "    manifest_path = str(out_base) + \"_manifest.json\"\n",
    "    manifest[\"audioUrl\"] = Path(audio_path).name\n",
    "    with open(manifest_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        import json; json.dump(manifest, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return audio_path, manifest_path\n",
    "\n",
    "def synth_pdf(file_path_or_bytes,\n",
    "              voice=\"af_heart\",\n",
    "              speed=1.0,\n",
    "              out_format=\"wav\",\n",
    "              lang_code=\"a\",\n",
    "              device=None,\n",
    "              basename=None,\n",
    "              output_dir=None):\n",
    "    device = device or DEVICE\n",
    "    output_dir = Path(output_dir) if output_dir else OUTPUT_DIR\n",
    "    \n",
    "    if isinstance(file_path_or_bytes, (str, Path)):\n",
    "        with open(file_path_or_bytes, \"rb\") as fh:\n",
    "            pdf_bytes = io.BytesIO(fh.read())\n",
    "        stem = Path(file_path_or_bytes).stem\n",
    "    else:\n",
    "        pdf_bytes = file_path_or_bytes\n",
    "        stem = basename or \"document\"\n",
    "\n",
    "    elements = extract_text_from_pdf(pdf_bytes)\n",
    "\n",
    "    wav_bytes, manifest = synth_text_to_wav_and_manifest(\n",
    "        elements,\n",
    "        voice=voice, speed=speed, lang_code=lang_code, device=device\n",
    "    )\n",
    "\n",
    "    out_base = output_dir / f\"{(basename or stem)}_tts\"\n",
    "\n",
    "    if out_format.lower() == \"mp3\":\n",
    "        mp3 = wav_to_mp3_bytes(wav_bytes)\n",
    "        audio_path = str(out_base) + \".mp3\"\n",
    "        with open(audio_path, \"wb\") as f: f.write(mp3)\n",
    "    else:\n",
    "        audio_path = str(out_base) + \".wav\"\n",
    "        with open(audio_path, \"wb\") as f: f.write(wav_bytes)\n",
    "\n",
    "    manifest_path = str(out_base) + \"_manifest.json\"\n",
    "    manifest[\"audioUrl\"] = Path(audio_path).name\n",
    "    with open(manifest_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        import json; json.dump(manifest, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return audio_path, manifest_path\n",
    "\n",
    "def synth_epub(file_path_or_bytes,\n",
    "               voice=\"af_heart\",\n",
    "               speed=1.0,\n",
    "               per_chapter_format=\"wav\",\n",
    "               lang_code=\"a\",\n",
    "               device=None,\n",
    "               zip_name=None,\n",
    "               output_dir=None):\n",
    "    device = device or DEVICE\n",
    "    output_dir = Path(output_dir) if output_dir else OUTPUT_DIR\n",
    "\n",
    "    if isinstance(file_path_or_bytes, (str, Path)):\n",
    "        with open(file_path_or_bytes, \"rb\") as fh:\n",
    "            epub_bytes = io.BytesIO(fh.read())\n",
    "        stem = Path(file_path_or_bytes).stem\n",
    "    else:\n",
    "        epub_bytes = file_path_or_bytes\n",
    "        stem = \"book\"\n",
    "\n",
    "    chapters = extract_chapters_from_epub(epub_bytes)\n",
    "    assert chapters, \"No chapters detected in EPUB.\"\n",
    "\n",
    "    zip_buf = io.BytesIO()\n",
    "    with zipfile.ZipFile(zip_buf, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
    "        for idx, (title, body) in enumerate(chapters, 1):\n",
    "            name = f\"{idx:02d}_{safe_name(title)[:40]}\"\n",
    "\n",
    "            chapter_elements = [{\n",
    "                \"text\": body,\n",
    "                \"metadata\": {\n",
    "                    \"chapter_index\": idx,\n",
    "                    \"chapter_title\": title,\n",
    "                    \"page_number\": 1,\n",
    "                    \"coordinates\": None\n",
    "                }\n",
    "            }]\n",
    "\n",
    "            wav_bytes, manifest = synth_text_to_wav_and_manifest(\n",
    "                chapter_elements,\n",
    "                voice=voice, speed=speed, lang_code=lang_code, device=device\n",
    "            )\n",
    "\n",
    "            if per_chapter_format.lower() == \"mp3\":\n",
    "                data = wav_to_mp3_bytes(wav_bytes)\n",
    "                audio_name = f\"{name}.mp3\"\n",
    "                zf.writestr(audio_name, data)\n",
    "            else:\n",
    "                audio_name = f\"{name}.wav\"\n",
    "                zf.writestr(audio_name, wav_bytes)\n",
    "\n",
    "            manifest[\"audioUrl\"] = audio_name\n",
    "            import json\n",
    "            zf.writestr(f\"{name}_manifest.json\", json.dumps(manifest, ensure_ascii=False, indent=2))\n",
    "\n",
    "    zip_buf.seek(0)\n",
    "    zpath = str(output_dir / f\"{zip_name or (stem + '_chapters')}.zip\")\n",
    "    with open(zpath, \"wb\") as f:\n",
    "        f.write(zip_buf.read())\n",
    "    return zpath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage-header",
   "metadata": {},
   "source": [
    "## Usage Examples\n",
    "\n",
    "Below are examples for synthesizing text, PDFs, and EPUBs locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-a-header",
   "metadata": {},
   "source": [
    "### A) String → Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "VOICE = \"af_heart\"\n",
    "SPEED = 1.0\n",
    "FORMAT = \"mp3\"  # \"wav\" or \"mp3\"\n",
    "LANG = \"a\"\n",
    "BASENAME = \"kokoro_text\"\n",
    "\n",
    "# Text to synthesize\n",
    "TEXT = \"\"\"Paste or type your text here.\n",
    "It can be multiple paragraphs. Chapters aren't needed for this path.\n",
    "\"\"\"\n",
    "\n",
    "# Run synthesis\n",
    "audio_path, manifest_path = synth_string(\n",
    "    TEXT, \n",
    "    voice=VOICE, \n",
    "    speed=SPEED,\n",
    "    out_format=FORMAT, \n",
    "    lang_code=LANG,\n",
    "    basename=BASENAME\n",
    ")\n",
    "\n",
    "print(f\"Audio saved to: {audio_path}\")\n",
    "print(f\"Manifest saved to: {manifest_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-b-header",
   "metadata": {},
   "source": [
    "### B) PDF → Audio (with manifest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example-pdf",
   "metadata": {},
   "outputs": [],
   "source": "# Configuration\nVOICE = \"af_heart\"\nSPEED = 1.0\nFORMAT = \"mp3\"  # \"wav\" or \"mp3\"\nLANG = \"a\"\n\n# Specify the path to your PDF file (relative to notebook location)\nPDF_PATH = \"document.pdf\"  # Change this to your PDF filename\n\n# Run synthesis\naudio_path, manifest_path = synth_pdf(\n    PDF_PATH, \n    voice=VOICE, \n    speed=SPEED,\n    out_format=FORMAT, \n    lang_code=LANG\n)\n\nprint(f\"Audio saved to: {audio_path}\")\nprint(f\"Manifest saved to: {manifest_path}\")"
  },
  {
   "cell_type": "markdown",
   "id": "example-c-header",
   "metadata": {},
   "source": [
    "### C) EPUB → ZIP (Per-Chapter Audio + Manifests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example-epub",
   "metadata": {},
   "outputs": [],
   "source": "# Configuration\nVOICE = \"af_heart\"\nSPEED = 1.0\nCHAPTER_FORMAT = \"wav\"  # \"wav\" or \"mp3\"\nLANG = \"a\"\nZIP_NAME = \"\"  # Optional: custom name for the output ZIP file\n\n# Specify the path to your EPUB file (relative to notebook location)\nEPUB_PATH = \"book.epub\"  # Change this to your EPUB filename\n\n# Run synthesis\nzip_path = synth_epub(\n    EPUB_PATH, \n    voice=VOICE, \n    speed=SPEED,\n    per_chapter_format=CHAPTER_FORMAT,\n    lang_code=LANG,\n    zip_name=(ZIP_NAME or None)\n)\n\nprint(f\"ZIP archive saved to: {zip_path}\")"
  },
  {
   "cell_type": "markdown",
   "id": "notes-header",
   "metadata": {},
   "source": "## Notes\n\n- **Output Directory**: By default, all outputs are saved to the same directory as the notebook. You can change this by modifying `OUTPUT_DIR` in the Configuration cell.\n- **Input Files**: Place your PDF/EPUB files in the same directory as the notebook, or provide relative/absolute paths.\n- **Device Selection**: The notebook will automatically use CUDA if available, otherwise CPU. You can override this by setting `DEVICE_MODE` in the Configuration cell.\n- **Voice Options**: Kokoro supports various voices. Check the Kokoro documentation for available voices.\n- **PDF Extraction**: The notebook uses `unstructured.io` for advanced PDF extraction with layout analysis. This may take longer but provides better results.\n- **Manifest Files**: Each audio output includes a JSON manifest file with sentence-level timing information and metadata."
  },
  {
   "cell_type": "markdown",
   "id": "859upsh4e3",
   "source": "## Cleanup: Delete Environment (Optional)\n\n**If you created a new environment at the beginning of this notebook**, you can delete it here to free up storage space.\n\n⚠️ **Warning**: This will permanently delete the environment and all installed packages!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "imcvxhn684f",
   "source": "import subprocess\n\n# Check if we created an environment in this notebook\nif 'environment_created_by_notebook' not in globals():\n    print(\"✗ No environment tracking found\")\n    print(\"This cell only works if you ran the environment setup cell at the beginning\")\nelif not environment_created_by_notebook:\n    print(\"✗ No environment was created by this notebook\")\n    print(\"You can only delete environments that were created in this session\")\nelse:\n    print(f\"Environment '{environment_name}' was created by this notebook\")\n    print(f\"\\n{'='*60}\")\n    print(\"DELETE ENVIRONMENT\")\n    print(f\"{'='*60}\")\n    \n    confirm = input(f\"\\nAre you sure you want to DELETE '{environment_name}'?\\nType 'yes' to confirm: \").strip().lower()\n    \n    if confirm == 'yes':\n        print(f\"\\n→ Deleting environment '{environment_name}'...\")\n        print(\"  This may take a moment...\")\n        \n        try:\n            subprocess.run(['conda', 'env', 'remove', '-n', environment_name, '-y'], \n                          check=True, capture_output=True)\n            print(f\"✓ Environment '{environment_name}' deleted successfully!\")\n            print(\"  Storage space has been freed.\")\n            \n            # Reset the flag\n            environment_created_by_notebook = False\n            environment_name = None\n            \n        except subprocess.CalledProcessError as e:\n            print(f\"✗ Failed to delete environment: {e}\")\n            print(\"You may need to delete it manually with: conda env remove -n {environment_name}\")\n    else:\n        print(\"\\n✗ Deletion cancelled - environment preserved\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}