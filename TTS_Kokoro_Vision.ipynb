{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# TTS v4 - Apple Vision Framework + Kokoro (macOS)\n",
    "- Uses Apple Vision Framework for fast, accurate PDF text extraction with locations\n",
    "- Uses Kokoro for high-quality text-to-speech synthesis\n",
    "- Includes sentence tracking and timeline manifest generation\n",
    "- **Requires macOS** (Vision Framework is Apple-only)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fsulk9h8k1m",
   "source": [
    "## 0) Environment Setup (Optional)",
    "",
    "**This step helps you manage Python packages and avoid conflicts with your system installation.**",
    "",
    "- If you have **conda** installed, you can create a fresh environment for this notebook",
    "- Or use an existing environment by providing its name",
    "- At the end of the notebook, you can easily clean up and delete the environment to free storage"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "9n9x8socdmh",
   "source": [
    "import subprocess",
    "import sys",
    "import os",
    "",
    "# Flag to track if we created an environment in this notebook",
    "environment_created_by_notebook = False",
    "environment_name = None",
    "",
    "# Check if conda is installed",
    "try:",
    "    result = subprocess.run(['conda', '--version'], capture_output=True, text=True, check=True)",
    "    conda_available = True",
    "    print(f\"\u2713 Conda detected: {result.stdout.strip()}\")",
    "except (subprocess.CalledProcessError, FileNotFoundError):",
    "    conda_available = False",
    "    print(\"\u2717 Conda not found - skipping environment management\")",
    "    print(\"Packages will be installed in your current Python environment\")",
    "",
    "if conda_available:",
    "    print(\"\\n\" + \"=\"*60)",
    "    print(\"ENVIRONMENT SETUP OPTIONS\")",
    "    print(\"=\"*60)",
    "    ",
    "    choice = input(\"\\nDo you want to:\\n  [1] Create a NEW conda environment (recommended)\\n  [2] Use an EXISTING environment\\n  [3] Skip and use current environment\\n\\nEnter choice (1/2/3): \").strip()",
    "    ",
    "    if choice == \"1\":",
    "        # Create new environment",
    "        env_name = input(\"\\nEnter name for new environment (default: kokoro_vision): \").strip()",
    "        if not env_name:",
    "            env_name = \"kokoro_vision\"",
    "        ",
    "        print(f\"\\n\u2192 Creating conda environment: {env_name}\")",
    "        print(\"  This may take a few minutes...\")",
    "        ",
    "        try:",
    "            # Create environment with Python 3.10",
    "            subprocess.run(['conda', 'create', '-n', env_name, 'python=3.10', '-y'], ",
    "                          check=True, capture_output=True)",
    "            ",
    "            environment_created_by_notebook = True",
    "            environment_name = env_name",
    "            ",
    "            print(f\"\u2713 Environment '{env_name}' created successfully!\")",
    "            print(f\"\\n{'='*60}\")",
    "            print(\"IMPORTANT: Restart your Jupyter kernel and select the new environment:\")",
    "            print(f\"  Kernel \u2192 Change Kernel \u2192 {env_name}\")",
    "            print(f\"{'='*60}\\n\")",
    "            ",
    "        except subprocess.CalledProcessError as e:",
    "            print(f\"\u2717 Failed to create environment: {e}\")",
    "            print(\"Continuing with current environment...\")",
    "    ",
    "    elif choice == \"2\":",
    "        # Use existing environment",
    "        env_name = input(\"\\nEnter name of existing environment: \").strip()",
    "        if env_name:",
    "            environment_name = env_name",
    "            print(f\"\\n\u2713 Using existing environment: {env_name}\")",
    "            print(f\"\\n{'='*60}\")",
    "            print(\"IMPORTANT: Make sure your kernel is using this environment:\")",
    "            print(f\"  Kernel \u2192 Change Kernel \u2192 {env_name}\")",
    "            print(f\"{'='*60}\\n\")",
    "        else:",
    "            print(\"\u2717 No environment name provided - using current environment\")",
    "    ",
    "    else:",
    "        print(\"\\n\u2713 Using current environment\")",
    "",
    "print(\"\\nYou can now proceed with the rest of the notebook.\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "install-header",
   "metadata": {},
   "source": [
    "## 1) Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core TTS + I/O deps",
    "!pip install \"kokoro>=0.9.4\" soundfile \"misaki[en]\" pypdf ebooklib pydub",
    "",
    "# PyObjC for Apple Vision Framework access",
    "!pip install pyobjc-framework-Vision pyobjc-framework-Quartz pyobjc-framework-Cocoa",
    "",
    "# Note: ffmpeg should be installed on your system for MP3 encoding",
    "# macOS: brew install ffmpeg",
    "",
    "# Silence overly chatty logs",
    "import logging",
    "logging.getLogger(\"phonemizer\").setLevel(logging.ERROR)",
    "logging.getLogger(\"pypdf\").setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## 2) Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os",
    "import sys",
    "from pathlib import Path",
    "",
    "# Check if running on macOS",
    "if sys.platform != \"darwin\":",
    "    print(\"WARNING: This notebook requires macOS for Vision Framework support!\")",
    "    print(\"For other platforms, use TTS_Kokoro_Local.ipynb instead.\")",
    "",
    "# --- MPS Fallback for Apple Silicon ---",
    "# Enable CPU fallback for operations not yet implemented on MPS",
    "# (specifically torch.angle used in Kokoro's STFT operations)",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'",
    "",
    "# --- Output directory setup ---",
    "OUTPUT_DIR = Path(\".\")  # Use current directory (same as notebook location)",
    "print(f\"Output directory: {OUTPUT_DIR.resolve()}\")",
    "",
    "# --- Device selection ---",
    "# DEVICE_MODE: \"auto\" (default), \"cuda\", \"cpu\", or \"mps\" (Apple Silicon)",
    "DEVICE_MODE = \"auto\"",
    "",
    "import torch",
    "def _pick_device():",
    "    if DEVICE_MODE == \"cuda\":",
    "        return \"cuda\"",
    "    if DEVICE_MODE == \"cpu\":",
    "        return \"cpu\"",
    "    if DEVICE_MODE == \"mps\":",
    "        return \"mps\"",
    "    # Auto mode: prefer MPS on Apple Silicon, then CUDA, then CPU",
    "    if torch.backends.mps.is_available():",
    "        return \"mps\"",
    "    return \"cuda\" if torch.cuda.is_available() else \"cpu\"",
    "",
    "DEVICE = _pick_device()",
    "print(f\"Using device: {DEVICE}\")",
    "if DEVICE == \"mps\":",
    "    print(\"Note: MPS will fall back to CPU for unsupported operations (like torch.angle)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpers-header",
   "metadata": {},
   "source": [
    "## 3) Helper Functions (PDF/EPUB extraction & TTS synthesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpers",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np",
    "import soundfile as sf",
    "import re, io, zipfile, torch",
    "from pathlib import Path",
    "from typing import List, Tuple, Dict, Union",
    "from functools import lru_cache",
    "",
    "from ebooklib import epub",
    "from kokoro import KPipeline",
    "from pydub import AudioSegment",
    "",
    "# Apple Vision Framework imports",
    "import Quartz",
    "import Vision",
    "from Foundation import NSURL",
    "",
    "# Sentence-ish split; keeps chunks small (avoids 510-phoneme truncation)",
    "SPLIT_PATTERN = r\"[.?!]\\s+|[\\n]{2,}\"",
    "SPLIT_PATTERN_CAP = r\"([.?!]\\s+|[\\n]{2,})\"",
    "",
    "",
    "# --- PDF Extraction using Apple Vision Framework ---",
    "def extract_text_from_pdf_vision(pdf_path: str) -> List[Dict]:",
    "    \"\"\"Extract text from PDF using Apple Vision Framework with precise bounding boxes.\"\"\"",
    "    print(f\"Parsing PDF with Apple Vision Framework: {pdf_path}\")",
    "    ",
    "    # Load PDF",
    "    pdf_url = NSURL.fileURLWithPath_(pdf_path)",
    "    pdf_doc = Quartz.PDFDocument.alloc().initWithURL_(pdf_url)",
    "    ",
    "    if pdf_doc is None:",
    "        print(\"Error: Could not load PDF\")",
    "        return [{\"text\": \"Error: Could not load PDF.\", \"metadata\": {\"page_number\": 1, \"bounds\": None}}]",
    "    ",
    "    page_count = pdf_doc.pageCount()",
    "    print(f\"Processing {page_count} pages...\")",
    "    ",
    "    element_list = []",
    "    ",
    "    for page_idx in range(page_count):",
    "        page = pdf_doc.pageAtIndex_(page_idx)",
    "        page_num = page_idx + 1",
    "        ",
    "        try:",
    "            # Get page bounds for rendering",
    "            page_rect = page.boundsForBox_(Quartz.kPDFDisplayBoxMediaBox)",
    "            ",
    "            # Render PDF page to image data using NSImage/NSBitmapImageRep",
    "            # This is more reliable than manual CGContext creation",
    "            from AppKit import NSImage, NSBitmapImageRep, NSCompositingOperationCopy",
    "            from Cocoa import NSMakeRect, NSZeroPoint",
    "            ",
    "            # Scale for better OCR quality (2x)",
    "            scale = 2.0",
    "            width = int(page_rect.size.width * scale)",
    "            height = int(page_rect.size.height * scale)",
    "            ",
    "            # Create an NSImage and render the PDF page into it",
    "            ns_image = NSImage.alloc().initWithSize_((width, height))",
    "            ns_image.lockFocus()",
    "            ",
    "            # Set up transform for rendering",
    "            import AppKit",
    "            context = AppKit.NSGraphicsContext.currentContext().graphicsPort()",
    "            Quartz.CGContextSaveGState(context)",
    "            Quartz.CGContextScaleCTM(context, scale, scale)",
    "            ",
    "            # Draw the PDF page",
    "            page.drawWithBox_(Quartz.kPDFDisplayBoxMediaBox)",
    "            ",
    "            Quartz.CGContextRestoreGState(context)",
    "            ns_image.unlockFocus()",
    "            ",
    "            # Get TIFF representation and create bitmap",
    "            tiff_data = ns_image.TIFFRepresentation()",
    "            bitmap = NSBitmapImageRep.imageRepWithData_(tiff_data)",
    "            ",
    "            # Convert to PNG data for Vision Framework",
    "            from AppKit import NSPNGFileType",
    "            png_data = bitmap.representationUsingType_properties_(NSPNGFileType, None)",
    "            ",
    "            # Create a list to collect results from completion handler",
    "            page_results = []",
    "            ",
    "            def make_handler(results_container):",
    "                \"\"\"Create completion handler that captures results.\"\"\"",
    "                def handler(request, error):",
    "                    if error:",
    "                        print(f\"  OCR error: {error}\")",
    "                        return",
    "                    ",
    "                    observations = request.results()",
    "                    if not observations:",
    "                        return",
    "                    ",
    "                    # Sort by Y coordinate (top to bottom)",
    "                    sorted_obs = sorted(observations, key=lambda obs: -obs.boundingBox().origin.y)",
    "                    ",
    "                    for observation in sorted_obs:",
    "                        top_candidates = observation.topCandidates_(1)",
    "                        if not top_candidates:",
    "                            continue",
    "                        ",
    "                        text = top_candidates[0].string()",
    "                        confidence = top_candidates[0].confidence()",
    "                        bbox = observation.boundingBox()",
    "                        ",
    "                        if text.strip():",
    "                            results_container.append({",
    "                                \"text\": text,",
    "                                \"confidence\": confidence,",
    "                                \"bbox\": bbox",
    "                            })",
    "                ",
    "                return handler",
    "            ",
    "            # Create Vision request with completion handler",
    "            handler = make_handler(page_results)",
    "            vision_request = Vision.VNRecognizeTextRequest.alloc().initWithCompletionHandler_(handler)",
    "            vision_request.setRecognitionLevel_(Vision.VNRequestTextRecognitionLevelAccurate)",
    "            vision_request.setUsesLanguageCorrection_(True)",
    "            ",
    "            # Create Vision handler from image data",
    "            vision_handler = Vision.VNImageRequestHandler.alloc().initWithData_options_(",
    "                png_data, None",
    "            )",
    "            ",
    "            # Perform OCR",
    "            success, error = vision_handler.performRequests_error_([vision_request], None)",
    "            ",
    "            if error:",
    "                print(f\"  Warning: Vision request failed for page {page_num}: {error}\")",
    "                continue",
    "            ",
    "            if not success:",
    "                print(f\"  Warning: Vision request returned false for page {page_num}\")",
    "                continue",
    "            ",
    "            # Process results from completion handler",
    "            for result in page_results:",
    "                element_list.append({",
    "                    \"text\": result[\"text\"],",
    "                    \"metadata\": {",
    "                        \"page_number\": page_num,",
    "                        \"bounds\": {",
    "                            \"x\": result[\"bbox\"].origin.x,",
    "                            \"y\": result[\"bbox\"].origin.y,",
    "                            \"width\": result[\"bbox\"].size.width,",
    "                            \"height\": result[\"bbox\"].size.height,",
    "                            \"confidence\": result[\"confidence\"]",
    "                        }",
    "                    }",
    "                })",
    "            ",
    "            print(f\"  Page {page_num}: Found {len(page_results)} text elements\")",
    "            ",
    "        except Exception as e:",
    "            print(f\"  Error processing page {page_num}: {e}\")",
    "            import traceback",
    "            traceback.print_exc()",
    "            continue",
    "    ",
    "    print(f\"Vision Framework: Found {len(element_list)} total text elements.\")",
    "    if not element_list:",
    "        return [{\"text\": \"Warning: Vision Framework found no text elements.\", \"metadata\": {\"page_number\": 1, \"bounds\": None}}]",
    "    ",
    "    return element_list",
    "",
    "",
    "# --- EPUB Extraction ---",
    "def extract_chapters_from_epub(file_like: io.BytesIO):",
    "    bk = epub.read_epub(file_like)",
    "    chapters = []",
    "    for item in bk.get_items_of_type(epub.ITEM_DOCUMENT):",
    "        if getattr(item, \"is_nav\", False): continue",
    "        html = item.get_content().decode(\"utf-8\", errors=\"ignore\")",
    "        text = re.sub(r\"<(script|style).*?>.*?</\\1>\", \" \", html, flags=re.S|re.I)",
    "        text = re.sub(r\"<br\\s*/?>\", \"\\n\", text, flags=re.I)",
    "        text = re.sub(r\"</p>|</div>|</h\\d>\", \"\\n\\n\", text, flags=re.I)",
    "        text = re.sub(r\"<[^>]+>\", \" \", text)",
    "        text = re.sub(r\"[ \\t]+\", \" \", text)",
    "        text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text).strip()",
    "        if text:",
    "            title = Path(item.file_name).stem",
    "            first = text.splitlines()[0] if text else \"\"; m = re.match(r\"(?i)\\s*(chapter|part|book)\\b[^\\n]{0,80}\", first)",
    "            if m: title = first[:60]",
    "            chapters.append((title, text))",
    "    if not chapters:",
    "        blobs = [];",
    "        for item in bk.get_items_of_type(epub.ITEM_DOCUMENT):",
    "             if getattr(item, \"is_nav\", False): continue",
    "             blobs.append(item.get_content().decode(\"utf-8\", errors=\"ignore\"))",
    "        html = \" \".join(blobs)",
    "        text = re.sub(r\"<(script|style).*?>.*?</\\1>\", \" \", html, flags=re.S|re.I)",
    "        text = re.sub(r\"<br\\s*/?>\", \"\\n\", text, flags=re.I)",
    "        text = re.sub(r\"</p>|</div>|</h\\d>\", \"\\n\\n\", text, flags=re.I)",
    "        text = re.sub(r\"<[^>]+>\", \" \", text)",
    "        text = re.sub(r\"[ \\t]+\", \" \", text)",
    "        text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text).strip()",
    "        if text: chapters = [(\"Chapter 1\", text)]",
    "    return chapters",
    "",
    "def safe_name(s: str) -> str:",
    "    s = re.sub(r\"[^\\w\\-]+\", \"_\", s).strip(\"_\"); return s or \"chapter\"",
    "",
    "# --- Pipeline cache ---",
    "@lru_cache(maxsize=4)",
    "def get_pipeline(lang_code='a', device=DEVICE):",
    "    return KPipeline(lang_code=lang_code, device=device)",
    "",
    "def _synthesize_sentence(pipe: KPipeline, sentence: str, voice='af_heart', speed=1.0) -> np.ndarray:",
    "    subchunks = [];",
    "    for _, _, audio in pipe(sentence, voice=voice, speed=speed, split_pattern=None): subchunks.append(audio)",
    "    if not subchunks: return np.zeros((0,), dtype=np.float32)",
    "    return np.concatenate(subchunks, axis=0)",
    "",
    "def split_sentences_keep_delim(text: str) -> List[str]:",
    "    parts = re.split(SPLIT_PATTERN_CAP, text); sents = []",
    "    for i in range(0, len(parts), 2):",
    "        chunk = (parts[i] or \"\").strip(); sep = parts[i+1] if i+1 < len(parts) else \"\"",
    "        if not chunk: continue",
    "        if sep and not sep.isspace(): chunk = (chunk + \" \" + sep.strip()).strip()",
    "        sents.append(chunk)",
    "    return sents",
    "",
    "# --- Synthesizer ---",
    "def synth_text_to_wav_and_manifest(",
    "    text_or_elements: Union[str, List[Dict]],",
    "    voice='af_heart',",
    "    speed=1.0,",
    "    lang_code='a',",
    "    device=DEVICE) -> Tuple[bytes, Dict]:",
    "    pipe = get_pipeline(lang_code=lang_code, device=device)",
    "    sr = 24000",
    "",
    "    if isinstance(text_or_elements, str):",
    "        elements = [{\"text\": text_or_elements, \"metadata\": {\"page_number\": 1, \"bounds\": None}}]",
    "    else:",
    "        elements = text_or_elements",
    "",
    "    pcm_all = []; timeline = []; t = 0.0; sentence_index = 0",
    "    print(f\"Synthesizing {len(elements)} text elements...\")",
    "",
    "    for element in elements:",
    "        element_text = element.get(\"text\", \"\")",
    "        element_meta = element.get(\"metadata\", {})",
    "",
    "        sentences = split_sentences_keep_delim(element_text)",
    "",
    "        for sent in sentences:",
    "            if not sent: continue",
    "            pcm = _synthesize_sentence(pipe, sent, voice=voice, speed=speed)",
    "            dur = pcm.shape[0] / sr",
    "            timeline.append({",
    "                \"i\": sentence_index,",
    "                \"start\": round(t, 3),",
    "                \"end\": round(t + dur, 3),",
    "                \"text\": sent.strip(),",
    "                \"location\": element_meta",
    "            })",
    "            pcm_all.append(pcm); t += dur; sentence_index += 1",
    "",
    "    pcm_cat = np.concatenate(pcm_all, axis=0) if pcm_all else np.zeros((sr//10,), dtype=np.float32)",
    "    buf = io.BytesIO(); sf.write(buf, pcm_cat, sr, format='WAV'); buf.seek(0)",
    "    manifest = {\"audioUrl\": \"\", \"sentences\": timeline}",
    "    return buf.read(), manifest",
    "",
    "def wav_to_mp3_bytes(wav_bytes: bytes, bitrate=\"128k\") -> bytes:",
    "    audio = AudioSegment.from_file(io.BytesIO(wav_bytes), format=\"wav\"); out = io.BytesIO()",
    "    audio.export(out, format=\"mp3\", bitrate=bitrate); out.seek(0); return out.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "synthesis-header",
   "metadata": {},
   "source": [
    "## 4) High-Level Synthesis Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthesis-wrappers",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synth_string(text: str,\n",
    "                 voice=\"af_heart\",\n",
    "                 speed=1.0,\n",
    "                 out_format=\"wav\",\n",
    "                 lang_code=\"a\",\n",
    "                 device=None,\n",
    "                 basename=\"kokoro_text\",\n",
    "                 output_dir=None):\n",
    "    device = device or DEVICE\n",
    "    output_dir = Path(output_dir) if output_dir else OUTPUT_DIR\n",
    "\n",
    "    elements = [{\n",
    "        \"text\": text,\n",
    "        \"metadata\": {\"page_number\": 1, \"source\": \"string\", \"bounds\": None}\n",
    "    }]\n",
    "\n",
    "    wav_bytes, manifest = synth_text_to_wav_and_manifest(\n",
    "        elements,\n",
    "        voice=voice, speed=speed, lang_code=lang_code, device=device\n",
    "    )\n",
    "\n",
    "    out_base = output_dir / basename\n",
    "\n",
    "    if out_format.lower() == \"mp3\":\n",
    "        mp3 = wav_to_mp3_bytes(wav_bytes)\n",
    "        audio_path = str(out_base) + \".mp3\"\n",
    "        with open(audio_path, \"wb\") as f: f.write(mp3)\n",
    "    else:\n",
    "        audio_path = str(out_base) + \".wav\"\n",
    "        with open(audio_path, \"wb\") as f: f.write(wav_bytes)\n",
    "\n",
    "    manifest_path = str(out_base) + \"_manifest.json\"\n",
    "    manifest[\"audioUrl\"] = Path(audio_path).name\n",
    "    with open(manifest_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        import json; json.dump(manifest, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return audio_path, manifest_path\n",
    "\n",
    "def synth_pdf(file_path: str,\n",
    "              voice=\"af_heart\",\n",
    "              speed=1.0,\n",
    "              out_format=\"wav\",\n",
    "              lang_code=\"a\",\n",
    "              device=None,\n",
    "              basename=None,\n",
    "              output_dir=None):\n",
    "    \"\"\"Extract text from PDF using Vision Framework and synthesize with Kokoro.\"\"\"\n",
    "    device = device or DEVICE\n",
    "    output_dir = Path(output_dir) if output_dir else OUTPUT_DIR\n",
    "    \n",
    "    stem = Path(file_path).stem\n",
    "\n",
    "    # Extract text using Vision Framework\n",
    "    elements = extract_text_from_pdf_vision(file_path)\n",
    "\n",
    "    wav_bytes, manifest = synth_text_to_wav_and_manifest(\n",
    "        elements,\n",
    "        voice=voice, speed=speed, lang_code=lang_code, device=device\n",
    "    )\n",
    "\n",
    "    out_base = output_dir / f\"{(basename or stem)}_tts\"\n",
    "\n",
    "    if out_format.lower() == \"mp3\":\n",
    "        mp3 = wav_to_mp3_bytes(wav_bytes)\n",
    "        audio_path = str(out_base) + \".mp3\"\n",
    "        with open(audio_path, \"wb\") as f: f.write(mp3)\n",
    "    else:\n",
    "        audio_path = str(out_base) + \".wav\"\n",
    "        with open(audio_path, \"wb\") as f: f.write(wav_bytes)\n",
    "\n",
    "    manifest_path = str(out_base) + \"_manifest.json\"\n",
    "    manifest[\"audioUrl\"] = Path(audio_path).name\n",
    "    with open(manifest_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        import json; json.dump(manifest, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "    return audio_path, manifest_path\n",
    "\n",
    "def synth_epub(file_path_or_bytes,\n",
    "               voice=\"af_heart\",\n",
    "               speed=1.0,\n",
    "               per_chapter_format=\"wav\",\n",
    "               lang_code=\"a\",\n",
    "               device=None,\n",
    "               zip_name=None,\n",
    "               output_dir=None):\n",
    "    device = device or DEVICE\n",
    "    output_dir = Path(output_dir) if output_dir else OUTPUT_DIR\n",
    "\n",
    "    if isinstance(file_path_or_bytes, (str, Path)):\n",
    "        with open(file_path_or_bytes, \"rb\") as fh:\n",
    "            epub_bytes = io.BytesIO(fh.read())\n",
    "        stem = Path(file_path_or_bytes).stem\n",
    "    else:\n",
    "        epub_bytes = file_path_or_bytes\n",
    "        stem = \"book\"\n",
    "\n",
    "    chapters = extract_chapters_from_epub(epub_bytes)\n",
    "    assert chapters, \"No chapters detected in EPUB.\"\n",
    "\n",
    "    zip_buf = io.BytesIO()\n",
    "    with zipfile.ZipFile(zip_buf, \"w\", zipfile.ZIP_DEFLATED) as zf:\n",
    "        for idx, (title, body) in enumerate(chapters, 1):\n",
    "            name = f\"{idx:02d}_{safe_name(title)[:40]}\"\n",
    "\n",
    "            chapter_elements = [{\n",
    "                \"text\": body,\n",
    "                \"metadata\": {\n",
    "                    \"chapter_index\": idx,\n",
    "                    \"chapter_title\": title,\n",
    "                    \"page_number\": 1,\n",
    "                    \"bounds\": None\n",
    "                }\n",
    "            }]\n",
    "\n",
    "            wav_bytes, manifest = synth_text_to_wav_and_manifest(\n",
    "                chapter_elements,\n",
    "                voice=voice, speed=speed, lang_code=lang_code, device=device\n",
    "            )\n",
    "\n",
    "            if per_chapter_format.lower() == \"mp3\":\n",
    "                data = wav_to_mp3_bytes(wav_bytes)\n",
    "                audio_name = f\"{name}.mp3\"\n",
    "                zf.writestr(audio_name, data)\n",
    "            else:\n",
    "                audio_name = f\"{name}.wav\"\n",
    "                zf.writestr(audio_name, wav_bytes)\n",
    "\n",
    "            manifest[\"audioUrl\"] = audio_name\n",
    "            import json\n",
    "            zf.writestr(f\"{name}_manifest.json\", json.dumps(manifest, ensure_ascii=False, indent=2))\n",
    "\n",
    "    zip_buf.seek(0)\n",
    "    zpath = str(output_dir / f\"{zip_name or (stem + '_chapters')}.zip\")\n",
    "    with open(zpath, \"wb\") as f:\n",
    "        f.write(zip_buf.read())\n",
    "    return zpath"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usage-header",
   "metadata": {},
   "source": [
    "## Usage Examples\n",
    "\n",
    "Below are examples for synthesizing text, PDFs, and EPUBs locally using Vision Framework + Kokoro."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-a-header",
   "metadata": {},
   "source": [
    "### A) String \u2192 Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "VOICE = \"af_heart\"\n",
    "SPEED = 1.0\n",
    "FORMAT = \"mp3\"  # \"wav\" or \"mp3\"\n",
    "LANG = \"a\"\n",
    "BASENAME = \"kokoro_text\"\n",
    "\n",
    "# Text to synthesize\n",
    "TEXT = \"\"\"Paste or type your text here.\n",
    "It can be multiple paragraphs. Chapters aren't needed for this path.\n",
    "\"\"\"\n",
    "\n",
    "# Run synthesis\n",
    "audio_path, manifest_path = synth_string(\n",
    "    TEXT, \n",
    "    voice=VOICE, \n",
    "    speed=SPEED,\n",
    "    out_format=FORMAT, \n",
    "    lang_code=LANG,\n",
    "    basename=BASENAME\n",
    ")\n",
    "\n",
    "print(f\"Audio saved to: {audio_path}\")\n",
    "print(f\"Manifest saved to: {manifest_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-b-header",
   "metadata": {},
   "source": [
    "### B) PDF \u2192 Audio (with Vision Framework OCR)\n",
    "\n",
    "**Vision Framework advantages:**\n",
    "- Native macOS integration (very fast)\n",
    "- Precise bounding boxes for each text element\n",
    "- High accuracy text recognition\n",
    "- No heavy dependencies (no detectron2, unstructured, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example-pdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration",
    "VOICE = \"af_heart\"",
    "SPEED = 1.0",
    "FORMAT = \"mp3\"  # \"wav\" or \"mp3\"",
    "LANG = \"a\"",
    "",
    "# Specify the path to your PDF file (relative to notebook location)",
    "PDF_PATH = \"document.pdf\"  # Change this to your PDF filename",
    "",
    "# Run synthesis (Vision Framework will extract text with locations)",
    "audio_path, manifest_path = synth_pdf(",
    "    PDF_PATH, ",
    "    voice=VOICE, ",
    "    speed=SPEED,",
    "    out_format=FORMAT, ",
    "    lang_code=LANG",
    ")",
    "",
    "print(f\"Audio saved to: {audio_path}\")",
    "print(f\"Manifest saved to: {manifest_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-c-header",
   "metadata": {},
   "source": [
    "### C) EPUB \u2192 ZIP (Per-Chapter Audio + Manifests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example-epub",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration",
    "VOICE = \"af_heart\"",
    "SPEED = 1.0",
    "CHAPTER_FORMAT = \"wav\"  # \"wav\" or \"mp3\"",
    "LANG = \"a\"",
    "ZIP_NAME = \"\"  # Optional: custom name for the output ZIP file",
    "",
    "# Specify the path to your EPUB file (relative to notebook location)",
    "EPUB_PATH = \"book.epub\"  # Change this to your EPUB filename",
    "",
    "# Run synthesis",
    "zip_path = synth_epub(",
    "    EPUB_PATH, ",
    "    voice=VOICE, ",
    "    speed=SPEED,",
    "    per_chapter_format=CHAPTER_FORMAT,",
    "    lang_code=LANG,",
    "    zip_name=(ZIP_NAME or None)",
    ")",
    "",
    "print(f\"ZIP archive saved to: {zip_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "notes-header",
   "metadata": {},
   "source": [
    "## Notes",
    "",
    "### Vision Framework Benefits:",
    "- **Speed**: Native macOS framework - much faster than unstructured.io",
    "- **Accuracy**: Excellent OCR quality with language correction",
    "- **Bounding Boxes**: Precise normalized coordinates (0-1) for each text element",
    "- **Confidence Scores**: Each text element includes confidence level",
    "- **No Heavy Dependencies**: No need for detectron2 or complex ML models",
    "",
    "### System Requirements:",
    "- **macOS only** (Vision Framework is Apple-exclusive)",
    "- For Apple Silicon Macs, the notebook will automatically use MPS acceleration",
    "- Requires PyObjC for Vision Framework access",
    "",
    "### Apple Silicon (M1/M2/M3) Performance:",
    "- **MPS Backend**: Uses Apple's Metal Performance Shaders for GPU acceleration",
    "- **CPU Fallback**: Some operations (like `torch.angle` in STFT) aren't yet implemented on MPS and will automatically fall back to CPU",
    "- **Overall Performance**: Still faster than pure CPU mode due to GPU acceleration for supported operations",
    "- To force CPU-only mode, set `DEVICE_MODE = \"cpu\"` in the Configuration cell",
    "",
    "### Output:",
    "- **Output Directory**: By default, all outputs are saved to the same directory as the notebook",
    "- **Input Files**: Place your PDF/EPUB files in the same directory as the notebook, or provide relative/absolute paths",
    "- **Device Selection**: Auto-detects MPS (Apple Silicon), CUDA, or CPU",
    "- **Manifest Format**: JSON files with precise bounding box coordinates for each sentence",
    "",
    "### Comparison with Other Approaches:",
    "- **Vision Framework** (this notebook): Best for general documents on macOS, fastest OCR",
    "- **Nougat** (TTS_Nougat.ipynb): Best for scientific papers with equations",
    "- **Unstructured.io** (TTS_Kokoro_Local.ipynb): Cross-platform, slower but works anywhere"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tq1bpsta3e",
   "source": [
    "## Cleanup: Delete Environment (Optional)",
    "",
    "**If you created a new environment at the beginning of this notebook**, you can delete it here to free up storage space.",
    "",
    "\u26a0\ufe0f **Warning**: This will permanently delete the environment and all installed packages!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "6zjuaa1r01l",
   "source": [
    "import subprocess",
    "",
    "# Check if we created an environment in this notebook",
    "if 'environment_created_by_notebook' not in globals():",
    "    print(\"\u2717 No environment tracking found\")",
    "    print(\"This cell only works if you ran the environment setup cell at the beginning\")",
    "elif not environment_created_by_notebook:",
    "    print(\"\u2717 No environment was created by this notebook\")",
    "    print(\"You can only delete environments that were created in this session\")",
    "else:",
    "    print(f\"Environment '{environment_name}' was created by this notebook\")",
    "    print(f\"\\n{'='*60}\")",
    "    print(\"DELETE ENVIRONMENT\")",
    "    print(f\"{'='*60}\")",
    "    ",
    "    confirm = input(f\"\\nAre you sure you want to DELETE '{environment_name}'?\\nType 'yes' to confirm: \").strip().lower()",
    "    ",
    "    if confirm == 'yes':",
    "        print(f\"\\n\u2192 Deleting environment '{environment_name}'...\")",
    "        print(\"  This may take a moment...\")",
    "        ",
    "        try:",
    "            subprocess.run(['conda', 'env', 'remove', '-n', environment_name, '-y'], ",
    "                          check=True, capture_output=True)",
    "            print(f\"\u2713 Environment '{environment_name}' deleted successfully!\")",
    "            print(\"  Storage space has been freed.\")",
    "            ",
    "            # Reset the flag",
    "            environment_created_by_notebook = False",
    "            environment_name = None",
    "            ",
    "        except subprocess.CalledProcessError as e:",
    "            print(f\"\u2717 Failed to delete environment: {e}\")",
    "            print(f\"You may need to delete it manually with: conda env remove -n {environment_name}\")",
    "    else:",
    "        print(\"\\n\u2717 Deletion cancelled - environment preserved\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}