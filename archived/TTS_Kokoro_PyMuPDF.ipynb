{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# TTS v4 - PyMuPDF Version (Kokoro)\n",
    "- Uses PyMuPDF for fast, accurate PDF text extraction with precise coordinates\n",
    "- Direct text extraction from PDF (no image conversion or OCR)\n",
    "- Character-level bounding boxes in native PDF coordinate space\n",
    "- Includes sentence tracking and timeline manifest generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "jfy82ow5stc",
   "source": [
    "## 0) Environment Setup (Optional)",
    "",
    "**This step helps you manage Python packages and avoid conflicts with your system installation.**",
    "",
    "- If you have **conda** installed, you can create a fresh environment for this notebook",
    "- Or use an existing environment by providing its name",
    "- At the end of the notebook, you can easily clean up and delete the environment to free storage"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "cw6x2xpjh5h",
   "source": [
    "import subprocess",
    "import sys",
    "import os",
    "",
    "# Flag to track if we created an environment in this notebook",
    "environment_created_by_notebook = False",
    "environment_name = None",
    "",
    "# Check if conda is installed",
    "try:",
    "    result = subprocess.run(['conda', '--version'], capture_output=True, text=True, check=True)",
    "    conda_available = True",
    "    print(f\"✓ Conda detected: {result.stdout.strip()}\")",
    "except (subprocess.CalledProcessError, FileNotFoundError):",
    "    conda_available = False",
    "    print(\"✗ Conda not found - skipping environment management\")",
    "    print(\"Packages will be installed in your current Python environment\")",
    "",
    "if conda_available:",
    "    print(\"\\n\" + \"=\"*60)",
    "    print(\"ENVIRONMENT SETUP OPTIONS\")",
    "    print(\"=\"*60)",
    "    ",
    "    choice = input(\"\\nDo you want to:\\n  [1] Create a NEW conda environment (recommended)\\n  [2] Use an EXISTING environment\\n  [3] Skip and use current environment\\n\\nEnter choice (1/2/3): \").strip()",
    "    ",
    "    if choice == \"1\":",
    "        # Create new environment",
    "        env_name = input(\"\\nEnter name for new environment (default: kokoro_pymupdf): \").strip()",
    "        if not env_name:",
    "            env_name = \"kokoro_pymupdf\"",
    "        ",
    "        print(f\"\\n→ Creating conda environment: {env_name}\")",
    "        print(\"  This may take a few minutes...\")",
    "        ",
    "        try:",
    "            # Create environment with Python 3.10",
    "            subprocess.run(['conda', 'create', '-n', env_name, 'python=3.10', '-y'], ",
    "                          check=True, capture_output=True)",
    "            ",
    "            environment_created_by_notebook = True",
    "            environment_name = env_name",
    "            ",
    "            print(f\"✓ Environment '{env_name}' created successfully!\")",
    "            print(f\"\\n{'='*60}\")",
    "            print(\"IMPORTANT: Restart your Jupyter kernel and select the new environment:\")",
    "            print(f\"  Kernel → Change Kernel → {env_name}\")",
    "            print(f\"{'='*60}\\n\")",
    "            ",
    "        except subprocess.CalledProcessError as e:",
    "            print(f\"✗ Failed to create environment: {e}\")",
    "            print(\"Continuing with current environment...\")",
    "    ",
    "    elif choice == \"2\":",
    "        # Use existing environment",
    "        env_name = input(\"\\nEnter name of existing environment: \").strip()",
    "        if env_name:",
    "            environment_name = env_name",
    "            print(f\"\\n✓ Using existing environment: {env_name}\")",
    "            print(f\"\\n{'='*60}\")",
    "            print(\"IMPORTANT: Make sure your kernel is using this environment:\")",
    "            print(f\"  Kernel → Change Kernel → {env_name}\")",
    "            print(f\"{'='*60}\\n\")",
    "        else:",
    "            print(\"✗ No environment name provided - using current environment\")",
    "    ",
    "    else:",
    "        print(\"\\n✓ Using current environment\")",
    "",
    "print(\"\\nYou can now proceed with the rest of the notebook.\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "install-header",
   "metadata": {},
   "source": [
    "## 1) Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "install",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: no matches found: misaki[en]\n",
      "Requirement already satisfied: pymupdf in /opt/anaconda3/envs/tts/lib/python3.12/site-packages (1.26.6)\n"
     ]
    }
   ],
   "source": [
    "# Core TTS + I/O deps\n",
    "!pip install \"kokoro>=0.9.4\" soundfile misaki[en] ebooklib pydub\n",
    "\n",
    "# PyMuPDF for fast, accurate PDF extraction with precise coordinates\n",
    "!pip install pymupdf\n",
    "\n",
    "# Note: ffmpeg should be installed on your system for MP3 encoding\n",
    "# Linux: sudo apt-get install ffmpeg\n",
    "# macOS: brew install ffmpeg\n",
    "# Windows: Download from https://ffmpeg.org/\n",
    "\n",
    "# Silence overly chatty logs\n",
    "import logging\n",
    "logging.getLogger(\"phonemizer\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"fitz\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## 2) Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "config",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output directory: /Users/simon/Documents/GitHub/ttsweb.github.io\n",
      "Using device: mps\n",
      "Note: MPS will fall back to CPU for unsupported operations (like torch.angle)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# --- MPS Fallback for Apple Silicon ---\n",
    "# Enable CPU fallback for operations not yet implemented on MPS\n",
    "# (specifically torch.angle used in Kokoro's STFT operations)\n",
    "os.environ['PYTORCH_ENABLE_MPS_FALLBACK'] = '1'\n",
    "\n",
    "# --- Output directory setup ---\n",
    "OUTPUT_DIR = Path(\".\")  # Use current directory (same as notebook location)\n",
    "print(f\"Output directory: {OUTPUT_DIR.resolve()}\")\n",
    "\n",
    "# --- Device selection ---\n",
    "# DEVICE_MODE: \"auto\" (default), \"cuda\", \"cpu\", or \"mps\" (Apple Silicon)\n",
    "DEVICE_MODE = \"auto\"\n",
    "\n",
    "import torch\n",
    "def _pick_device():\n",
    "    if DEVICE_MODE == \"cuda\":\n",
    "        return \"cuda\"\n",
    "    if DEVICE_MODE == \"cpu\":\n",
    "        return \"cpu\"\n",
    "    if DEVICE_MODE == \"mps\":\n",
    "        return \"mps\"\n",
    "    # Auto mode: prefer MPS on Apple Silicon, then CUDA, then CPU\n",
    "    if torch.backends.mps.is_available():\n",
    "        return \"mps\"\n",
    "    return \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "DEVICE = _pick_device()\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "if DEVICE == \"mps\":\n",
    "    print(\"Note: MPS will fall back to CPU for unsupported operations (like torch.angle)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpers-header",
   "metadata": {},
   "source": [
    "## 3) Helper Functions (PDF/EPUB extraction & TTS synthesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpers",
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport soundfile as sf\nimport re, io, zipfile, torch\nfrom pathlib import Path\nfrom typing import List, Tuple, Dict, Union, Optional\nfrom functools import lru_cache\n\nimport fitz  # PyMuPDF\nfrom ebooklib import epub\nfrom kokoro import KPipeline\nfrom pydub import AudioSegment\n\n# Sentence-ish split; keeps chunks small (avoids 510-phoneme truncation)\nSPLIT_PATTERN = r\"[.?!]\\s+|[\\n]{2,}\"\nSPLIT_PATTERN_CAP = r\"([.?!]\\s+|[\\n]{2,})\"\n\n\n# --- PDF Extraction using PyMuPDF ---\ndef extract_text_from_pdf_pymupdf(file_path_or_bytes: Union[str, io.BytesIO], pages: Optional[List[int]] = None) -> List[Dict]:\n    \"\"\"Extract text from PDF using PyMuPDF with precise character-level bounding boxes.\n    \n    Args:\n        file_path_or_bytes: Path to PDF file or BytesIO object\n        pages: Optional list of page numbers to extract (1-indexed). None = all pages.\n        \n    Returns:\n        List of dicts with 'text' and 'metadata' (including points for HTML compatibility)\n    \"\"\"\n    print(\"Parsing PDF with PyMuPDF (direct text extraction)...\")\n    \n    # Open PDF\n    if isinstance(file_path_or_bytes, (str, Path)):\n        doc = fitz.open(file_path_or_bytes)\n    else:\n        doc = fitz.open(stream=file_path_or_bytes.read(), filetype=\"pdf\")\n    \n    # Convert pages to set for faster lookup\n    pages_set = set(pages) if pages else None\n    \n    element_list = []\n    \n    if pages_set:\n        print(f\"Processing pages {sorted(pages_set)} out of {len(doc)} total pages...\")\n    else:\n        print(f\"Processing {len(doc)} pages...\")\n    \n    for page_num in range(len(doc)):\n        page_number = page_num + 1\n        \n        # Skip if page filtering is enabled and current page not in list\n        if pages_set and page_number not in pages_set:\n            continue\n        \n        page = doc[page_num]\n        \n        # Get page dimensions\n        page_rect = page.rect\n        page_width = page_rect.width\n        page_height = page_rect.height\n        \n        # Extract text blocks with detailed information\n        blocks = page.get_text(\"dict\", flags=fitz.TEXT_PRESERVE_WHITESPACE)[\"blocks\"]\n        \n        block_count = 0\n        \n        for block in blocks:\n            # Skip non-text blocks (images, etc.)\n            if block.get(\"type\") != 0:  # 0 = text block\n                continue\n            \n            # Extract text from all lines in block\n            block_text_parts = []\n            block_bbox = block.get(\"bbox\")  # (x0, y0, x1, y1)\n            \n            for line in block.get(\"lines\", []):\n                line_text_parts = []\n                for span in line.get(\"spans\", []):\n                    span_text = span.get(\"text\", \"\")\n                    if span_text.strip():\n                        line_text_parts.append(span_text)\n                \n                if line_text_parts:\n                    block_text_parts.append(\"\".join(line_text_parts))\n            \n            block_text = \"\\n\".join(block_text_parts).strip()\n            \n            if block_text:\n                # Convert bbox to points format for HTML player compatibility\n                # Format: [[x0, y0], [x1, y0], [x1, y1], [x0, y1]]\n                # Using absolute coordinates (HTML will infer page dimensions)\n                points = [\n                    [block_bbox[0], block_bbox[1]],  # top-left\n                    [block_bbox[2], block_bbox[1]],  # top-right\n                    [block_bbox[2], block_bbox[3]],  # bottom-right\n                    [block_bbox[0], block_bbox[3]]   # bottom-left\n                ]\n                \n                element_list.append({\n                    \"text\": block_text,\n                    \"metadata\": {\n                        \"page_number\": page_number,\n                        \"points\": points\n                    }\n                })\n                block_count += 1\n        \n        print(f\"  Page {page_number}: Found {block_count} text blocks\")\n    \n    doc.close()\n    \n    if pages_set:\n        print(f\"PyMuPDF: Found {len(element_list)} total text elements from pages {sorted(pages_set)}.\")\n    else:\n        print(f\"PyMuPDF: Found {len(element_list)} total text elements.\")\n    if not element_list:\n        return [{\"text\": \"Warning: PyMuPDF found no text elements.\", \"metadata\": {\"page_number\": 1, \"points\": None}}]\n    \n    return element_list\n\n\n# --- EPUB Extraction ---\ndef extract_chapters_from_epub(file_like: io.BytesIO):\n    bk = epub.read_epub(file_like)\n    chapters = []\n    for item in bk.get_items_of_type(epub.ITEM_DOCUMENT):\n        if getattr(item, \"is_nav\", False): continue\n        html = item.get_content().decode(\"utf-8\", errors=\"ignore\")\n        text = re.sub(r\"<(script|style).*?>.*?</\\1>\", \" \", html, flags=re.S|re.I)\n        text = re.sub(r\"<br\\s*/?>\", \"\\n\", text, flags=re.I)\n        text = re.sub(r\"</p>|</div>|</h\\d>\", \"\\n\\n\", text, flags=re.I)\n        text = re.sub(r\"<[^>]+>\", \" \", text)\n        text = re.sub(r\"[ \\t]+\", \" \", text)\n        text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text).strip()\n        if text:\n            title = Path(item.file_name).stem\n            first = text.splitlines()[0] if text else \"\"; m = re.match(r\"(?i)\\s*(chapter|part|book)\\b[^\\n]{0,80}\", first)\n            if m: title = first[:60]\n            chapters.append((title, text))\n    if not chapters:\n        blobs = [];\n        for item in bk.get_items_of_type(epub.ITEM_DOCUMENT):\n             if getattr(item, \"is_nav\", False): continue\n             blobs.append(item.get_content().decode(\"utf-8\", errors=\"ignore\"))\n        html = \" \".join(blobs)\n        text = re.sub(r\"<(script|style).*?>.*?</\\1>\", \" \", html, flags=re.S|re.I)\n        text = re.sub(r\"<br\\s*/?>\", \"\\n\", text, flags=re.I)\n        text = re.sub(r\"</p>|</div>|</h\\d>\", \"\\n\\n\", text, flags=re.I)\n        text = re.sub(r\"<[^>]+>\", \" \", text)\n        text = re.sub(r\"[ \\t]+\", \" \", text)\n        text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text).strip()\n        if text: chapters = [(\"Chapter 1\", text)]\n    return chapters\n\ndef safe_name(s: str) -> str:\n    s = re.sub(r\"[^\\w\\-]+\", \"_\", s).strip(\"_\"); return s or \"chapter\"\n\n# --- Pipeline cache ---\n@lru_cache(maxsize=4)\ndef get_pipeline(lang_code='a', device=DEVICE):\n    return KPipeline(lang_code=lang_code, device=device)\n\ndef _synthesize_sentence(pipe: KPipeline, sentence: str, voice='af_heart', speed=1.0) -> np.ndarray:\n    subchunks = [];\n    for _, _, audio in pipe(sentence, voice=voice, speed=speed, split_pattern=None): subchunks.append(audio)\n    if not subchunks: return np.zeros((0,), dtype=np.float32)\n    return np.concatenate(subchunks, axis=0)\n\ndef split_sentences_keep_delim(text: str) -> List[str]:\n    parts = re.split(SPLIT_PATTERN_CAP, text); sents = []\n    for i in range(0, len(parts), 2):\n        chunk = (parts[i] or \"\").strip(); sep = parts[i+1] if i+1 < len(parts) else \"\"\n        if not chunk: continue\n        if sep and not sep.isspace(): chunk = (chunk + \" \" + sep.strip()).strip()\n        sents.append(chunk)\n    return sents\n\n# --- Synthesizer ---\ndef synth_text_to_wav_and_manifest(\n    text_or_elements: Union[str, List[Dict]],\n    voice='af_heart',\n    speed=1.0,\n    lang_code='a',\n    device=DEVICE) -> Tuple[bytes, Dict]:\n    pipe = get_pipeline(lang_code=lang_code, device=device)\n    sr = 24000\n\n    if isinstance(text_or_elements, str):\n        elements = [{\"text\": text_or_elements, \"metadata\": {\"page_number\": 1, \"points\": None}}]\n    else:\n        elements = text_or_elements\n\n    pcm_all = []; timeline = []; t = 0.0; sentence_index = 0\n    print(f\"Synthesizing {len(elements)} text elements...\")\n\n    for element in elements:\n        element_text = element.get(\"text\", \"\")\n        element_meta = element.get(\"metadata\", {})\n\n        sentences = split_sentences_keep_delim(element_text)\n\n        for sent in sentences:\n            if not sent: continue\n            pcm = _synthesize_sentence(pipe, sent, voice=voice, speed=speed)\n            dur = pcm.shape[0] / sr\n            timeline.append({\n                \"i\": sentence_index,\n                \"start\": round(t, 3),\n                \"end\": round(t + dur, 3),\n                \"text\": sent.strip(),\n                \"location\": element_meta  # Note: renamed from \"metadata\" to \"location\" for HTML compatibility\n            })\n            pcm_all.append(pcm); t += dur; sentence_index += 1\n\n    pcm_cat = np.concatenate(pcm_all, axis=0) if pcm_all else np.zeros((sr//10,), dtype=np.float32)\n    buf = io.BytesIO(); sf.write(buf, pcm_cat, sr, format='WAV'); buf.seek(0)\n    manifest = {\"audioUrl\": \"\", \"sentences\": timeline}\n    return buf.read(), manifest\n\ndef wav_to_mp3_bytes(wav_bytes: bytes, bitrate=\"128k\") -> bytes:\n    audio = AudioSegment.from_file(io.BytesIO(wav_bytes), format=\"wav\"); out = io.BytesIO()\n    audio.export(out, format=\"mp3\", bitrate=bitrate); out.seek(0); return out.read()\n"
  },
  {
   "cell_type": "markdown",
   "id": "synthesis-header",
   "metadata": {},
   "source": [
    "## 4) High-Level Synthesis Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthesis-wrappers",
   "metadata": {},
   "outputs": [],
   "source": "def synth_string(text: str,\n                 voice=\"af_heart\",\n                 speed=1.0,\n                 out_format=\"wav\",\n                 lang_code=\"a\",\n                 device=None,\n                 basename=\"kokoro_text\",\n                 output_dir=None):\n    device = device or DEVICE\n    output_dir = Path(output_dir) if output_dir else OUTPUT_DIR\n\n    elements = [{\n        \"text\": text,\n        \"metadata\": {\"page_number\": 1, \"source\": \"string\", \"points\": None}\n    }]\n\n    wav_bytes, manifest = synth_text_to_wav_and_manifest(\n        elements,\n        voice=voice, speed=speed, lang_code=lang_code, device=device\n    )\n\n    out_base = output_dir / basename\n\n    if out_format.lower() == \"mp3\":\n        mp3 = wav_to_mp3_bytes(wav_bytes)\n        audio_path = str(out_base) + \".mp3\"\n        with open(audio_path, \"wb\") as f: f.write(mp3)\n    else:\n        audio_path = str(out_base) + \".wav\"\n        with open(audio_path, \"wb\") as f: f.write(wav_bytes)\n\n    manifest_path = str(out_base) + \"_manifest.json\"\n    manifest[\"audioUrl\"] = Path(audio_path).name\n    with open(manifest_path, \"w\", encoding=\"utf-8\") as f:\n        import json; json.dump(manifest, f, ensure_ascii=False, indent=2)\n\n    return audio_path, manifest_path\n\ndef synth_pdf(file_path_or_bytes,\n              voice=\"af_heart\",\n              speed=1.0,\n              out_format=\"wav\",\n              lang_code=\"a\",\n              device=None,\n              basename=None,\n              output_dir=None,\n              pages=None):\n    \"\"\"Extract text from PDF using PyMuPDF and synthesize with Kokoro.\n    \n    Args:\n        file_path_or_bytes: Path to PDF file or BytesIO object\n        voice: Voice to use for synthesis\n        speed: Speech speed (1.0 = normal)\n        out_format: Output format (\"wav\" or \"mp3\")\n        lang_code: Language code for synthesis\n        device: Device to use (\"cuda\", \"mps\", or \"cpu\")\n        basename: Base name for output files\n        output_dir: Directory for output files\n        pages: Optional list of page numbers to synthesize (1-indexed). None = all pages.\n               Examples: [1, 2, 3] or [5] or None\n    \n    Returns:\n        Tuple of (audio_path, manifest_path)\n    \"\"\"\n    device = device or DEVICE\n    output_dir = Path(output_dir) if output_dir else OUTPUT_DIR\n    \n    if isinstance(file_path_or_bytes, (str, Path)):\n        stem = Path(file_path_or_bytes).stem\n    else:\n        stem = basename or \"document\"\n\n    # Extract text using PyMuPDF with optional page filtering\n    elements = extract_text_from_pdf_pymupdf(file_path_or_bytes, pages=pages)\n\n    wav_bytes, manifest = synth_text_to_wav_and_manifest(\n        elements,\n        voice=voice, speed=speed, lang_code=lang_code, device=device\n    )\n\n    out_base = output_dir / f\"{(basename or stem)}_tts\"\n\n    if out_format.lower() == \"mp3\":\n        mp3 = wav_to_mp3_bytes(wav_bytes)\n        audio_path = str(out_base) + \".mp3\"\n        with open(audio_path, \"wb\") as f: f.write(mp3)\n    else:\n        audio_path = str(out_base) + \".wav\"\n        with open(audio_path, \"wb\") as f: f.write(wav_bytes)\n\n    manifest_path = str(out_base) + \"_manifest.json\"\n    manifest[\"audioUrl\"] = Path(audio_path).name\n    with open(manifest_path, \"w\", encoding=\"utf-8\") as f:\n        import json; json.dump(manifest, f, ensure_ascii=False, indent=2)\n\n    return audio_path, manifest_path\n\ndef synth_epub(file_path_or_bytes,\n               voice=\"af_heart\",\n               speed=1.0,\n               per_chapter_format=\"wav\",\n               lang_code=\"a\",\n               device=None,\n               zip_name=None,\n               output_dir=None):\n    device = device or DEVICE\n    output_dir = Path(output_dir) if output_dir else OUTPUT_DIR\n\n    if isinstance(file_path_or_bytes, (str, Path)):\n        with open(file_path_or_bytes, \"rb\") as fh:\n            epub_bytes = io.BytesIO(fh.read())\n        stem = Path(file_path_or_bytes).stem\n    else:\n        epub_bytes = file_path_or_bytes\n        stem = \"book\"\n\n    chapters = extract_chapters_from_epub(epub_bytes)\n    assert chapters, \"No chapters detected in EPUB.\"\n\n    zip_buf = io.BytesIO()\n    with zipfile.ZipFile(zip_buf, \"w\", zipfile.ZIP_DEFLATED) as zf:\n        for idx, (title, body) in enumerate(chapters, 1):\n            name = f\"{idx:02d}_{safe_name(title)[:40]}\"\n\n            chapter_elements = [{\n                \"text\": body,\n                \"metadata\": {\n                    \"chapter_index\": idx,\n                    \"chapter_title\": title,\n                    \"page_number\": 1,\n                    \"points\": None\n                }\n            }]\n\n            wav_bytes, manifest = synth_text_to_wav_and_manifest(\n                chapter_elements,\n                voice=voice, speed=speed, lang_code=lang_code, device=device\n            )\n\n            if per_chapter_format.lower() == \"mp3\":\n                data = wav_to_mp3_bytes(wav_bytes)\n                audio_name = f\"{name}.mp3\"\n                zf.writestr(audio_name, data)\n            else:\n                audio_name = f\"{name}.wav\"\n                zf.writestr(audio_name, wav_bytes)\n\n            manifest[\"audioUrl\"] = audio_name\n            import json\n            zf.writestr(f\"{name}_manifest.json\", json.dumps(manifest, ensure_ascii=False, indent=2))\n\n    zip_buf.seek(0)\n    zpath = str(output_dir / f\"{zip_name or (stem + '_chapters')}.zip\")\n    with open(zpath, \"wb\") as f:\n        f.write(zip_buf.read())\n    return zpath\n"
  },
  {
   "cell_type": "markdown",
   "id": "usage-header",
   "metadata": {},
   "source": [
    "## Usage Examples\n",
    "\n",
    "Below are examples for synthesizing text, PDFs, and EPUBs locally."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-a-header",
   "metadata": {},
   "source": [
    "### A) String → Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "example-string",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Defaulting repo_id to hexgrad/Kokoro-82M. Pass repo_id='hexgrad/Kokoro-82M' to suppress this warning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tts/lib/python3.12/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/envs/tts/lib/python3.12/site-packages/torch/nn/utils/weight_norm.py:143: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
      "  WeightNorm.apply(module, name, dim)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Synthesizing 1 text elements...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/tts/lib/python3.12/site-packages/kokoro/istftnet.py:94: UserWarning: The operator 'aten::angle' is not currently supported on the MPS backend and will fall back to run on the CPU. This may have performance implications. (Triggered internally at /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1729646995093/work/aten/src/ATen/mps/MPSFallback.mm:13.)\n",
      "  return torch.abs(forward_transform), torch.angle(forward_transform)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Audio saved to: /Users/simon/kokoro_outputs/kokoro_text.mp3\n",
      "Manifest saved to: /Users/simon/kokoro_outputs/kokoro_text_manifest.json\n"
     ]
    }
   ],
   "source": [
    "# Configuration\n",
    "VOICE = \"af_heart\"\n",
    "SPEED = 1.0\n",
    "FORMAT = \"mp3\"  # \"wav\" or \"mp3\"\n",
    "LANG = \"a\"\n",
    "BASENAME = \"kokoro_text\"\n",
    "\n",
    "# Text to synthesize\n",
    "TEXT = \"\"\"Paste or type your text here.\n",
    "It can be multiple paragraphs. Chapters aren't needed for this path.\n",
    "\"\"\"\n",
    "\n",
    "# Run synthesis\n",
    "audio_path, manifest_path = synth_string(\n",
    "    TEXT, \n",
    "    voice=VOICE, \n",
    "    speed=SPEED,\n",
    "    out_format=FORMAT, \n",
    "    lang_code=LANG,\n",
    "    basename=BASENAME\n",
    ")\n",
    "\n",
    "print(f\"Audio saved to: {audio_path}\")\n",
    "print(f\"Manifest saved to: {manifest_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-b-header",
   "metadata": {},
   "source": [
    "### B) PDF → Audio (with PyMuPDF extraction)\n",
    "\n",
    "**PyMuPDF advantages:**\n",
    "- Direct text extraction (no OCR needed)\n",
    "- Character-level precise bounding boxes\n",
    "- Native PDF coordinate space (no scaling issues)\n",
    "- Fast and lightweight\n",
    "- Cross-platform support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example-pdf",
   "metadata": {},
   "outputs": [],
   "source": "# Configuration\nVOICE = \"af_heart\"\nSPEED = 1.0\nFORMAT = \"mp3\"  # \"wav\" or \"mp3\"\nLANG = \"a\"\n\n# Specify the path to your PDF file (relative to notebook location)\nPDF_PATH = \"document.pdf\"  # Change this to your PDF filename\n\n# Page selection (optional)\n# None = all pages (default)\n# [1, 2, 3] = only pages 1, 2, and 3\n# [5] = only page 5\n# [1, 3, 5, 7] = only odd pages 1, 3, 5, 7\nPAGES = None  # Change to a list like [1, 2, 3] to select specific pages\n\n# Run synthesis (PyMuPDF will extract text with precise coordinates)\naudio_path, manifest_path = synth_pdf(\n    PDF_PATH, \n    voice=VOICE, \n    speed=SPEED,\n    out_format=FORMAT, \n    lang_code=LANG,\n    pages=PAGES\n)\n\nprint(f\"Audio saved to: {audio_path}\")\nprint(f\"Manifest saved to: {manifest_path}\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "example-c-header",
   "metadata": {},
   "source": [
    "### C) EPUB → ZIP (Per-Chapter Audio + Manifests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example-epub",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "VOICE = \"af_heart\"\n",
    "SPEED = 1.0\n",
    "CHAPTER_FORMAT = \"wav\"  # \"wav\" or \"mp3\"\n",
    "LANG = \"a\"\n",
    "ZIP_NAME = \"\"  # Optional: custom name for the output ZIP file\n",
    "\n",
    "# Specify the path to your EPUB file (relative to notebook location)\n",
    "EPUB_PATH = \"book.epub\"  # Change this to your EPUB filename\n",
    "\n",
    "# Run synthesis\n",
    "zip_path = synth_epub(\n",
    "    EPUB_PATH, \n",
    "    voice=VOICE, \n",
    "    speed=SPEED,\n",
    "    per_chapter_format=CHAPTER_FORMAT,\n",
    "    lang_code=LANG,\n",
    "    zip_name=(ZIP_NAME or None)\n",
    ")\n",
    "\n",
    "print(f\"ZIP archive saved to: {zip_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "notes-header",
   "metadata": {},
   "source": [
    "## Notes",
    "",
    "### PyMuPDF Benefits:",
    "- **Direct Text Extraction**: No OCR overhead - extracts text directly from PDF structure",
    "- **Precise Coordinates**: Character-level bounding boxes in native PDF coordinate space",
    "- **No Scaling Issues**: Uses absolute PDF coordinates - no normalization problems",
    "- **Fast**: C++ backend, much faster than image-based OCR approaches",
    "- **Lightweight**: ~15MB vs detectron2's ~500MB",
    "- **Cross-Platform**: Works on Linux, macOS, Windows",
    "- **HTML Compatible**: Outputs coordinates in the same format as unstructured.io",
    "",
    "### Coordinate Format:",
    "Each text element includes coordinates compatible with the HTML player:",
    "```json",
    "{",
    "  \"metadata\": {",
    "    \"page_number\": 1,",
    "    \"points\": [",
    "      [x0, y0],  // top-left",
    "      [x1, y0],  // top-right",
    "      [x1, y1],  // bottom-right",
    "      [x0, y1]   // bottom-left",
    "    ]",
    "  }",
    "}",
    "```",
    "- Absolute coordinates in PDF points",
    "- HTML player automatically infers page dimensions",
    "- Compatible with existing highlighting system",
    "",
    "### Apple Silicon (M1/M2/M3) Performance:",
    "- **MPS Backend**: Uses Apple's Metal Performance Shaders for GPU acceleration",
    "- **CPU Fallback**: Some operations (like `torch.angle` in STFT) aren't yet implemented on MPS and will automatically fall back to CPU",
    "- **Overall Performance**: Still faster than pure CPU mode due to GPU acceleration for supported operations",
    "- To force CPU-only mode, set `DEVICE_MODE = \"cpu\"` in the Configuration cell",
    "",
    "### System Requirements:",
    "- Works on all platforms (Linux, macOS, Windows)",
    "- Automatic device detection (CUDA, MPS for Apple Silicon, or CPU)",
    "",
    "### Output:",
    "- **Output Directory**: By default, all outputs are saved to `~/kokoro_outputs/`",
    "- **Device Selection**: Auto-detects best available device",
    "- **Manifest Format**: JSON files with precise bounding box coordinates for each sentence",
    "",
    "### Comparison with Other Approaches:",
    "- **PyMuPDF** (this notebook): Best for PDFs with text layer, fastest, most accurate coordinates",
    "- **Unstructured.io** (TTS_Kokoro_Local.ipynb): Best for complex layout analysis, slower",
    "- **Vision Framework** (TTS_Kokoro_Vision.ipynb): OCR-based, macOS only, for scanned PDFs",
    "- **Nougat** (TTS_Nougat.ipynb): Best for scientific papers with equations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "m2sohq57gvr",
   "source": [
    "## Cleanup: Delete Environment (Optional)",
    "",
    "**If you created a new environment at the beginning of this notebook**, you can delete it here to free up storage space.",
    "",
    "⚠️ **Warning**: This will permanently delete the environment and all installed packages!"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "phivhcqnqjf",
   "source": [
    "import subprocess",
    "",
    "# Check if we created an environment in this notebook",
    "if 'environment_created_by_notebook' not in globals():",
    "    print(\"✗ No environment tracking found\")",
    "    print(\"This cell only works if you ran the environment setup cell at the beginning\")",
    "elif not environment_created_by_notebook:",
    "    print(\"✗ No environment was created by this notebook\")",
    "    print(\"You can only delete environments that were created in this session\")",
    "else:",
    "    print(f\"Environment '{environment_name}' was created by this notebook\")",
    "    print(f\"\\n{'='*60}\")",
    "    print(\"DELETE ENVIRONMENT\")",
    "    print(f\"{'='*60}\")",
    "    ",
    "    confirm = input(f\"\\nAre you sure you want to DELETE '{environment_name}'?\\nType 'yes' to confirm: \").strip().lower()",
    "    ",
    "    if confirm == 'yes':",
    "        print(f\"\\n→ Deleting environment '{environment_name}'...\")",
    "        print(\"  This may take a moment...\")",
    "        ",
    "        try:",
    "            subprocess.run(['conda', 'env', 'remove', '-n', environment_name, '-y'], ",
    "                          check=True, capture_output=True)",
    "            print(f\"✓ Environment '{environment_name}' deleted successfully!\")",
    "            print(\"  Storage space has been freed.\")",
    "            ",
    "            # Reset the flag",
    "            environment_created_by_notebook = False",
    "            environment_name = None",
    "            ",
    "        except subprocess.CalledProcessError as e:",
    "            print(f\"✗ Failed to delete environment: {e}\")",
    "            print(f\"You may need to delete it manually with: conda env remove -n {environment_name}\")",
    "    else:",
    "        print(\"\\n✗ Deletion cancelled - environment preserved\")"
   ],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tts",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}