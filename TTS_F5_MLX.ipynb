{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# TTS v5 - F5-TTS-MLX (Apple Silicon Optimized)\n",
    "- Adapted for running locally with F5-TTS-MLX\n",
    "- Optimized for Apple Silicon (M1/M2/M3/M4) with MLX framework\n",
    "- Includes sentence tracking and timeline manifest generation\n",
    "- CPU fallback support for compatibility"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gwu8vbbzwi",
   "metadata": {},
   "source": [
    "## 0) Environment Setup (Optional)\n",
    "\n",
    "**This step helps you manage Python packages and avoid conflicts with your system installation.**\n",
    "\n",
    "- If you have **conda** installed, you can create a fresh environment for this notebook\n",
    "- Or use an existing environment by providing its name\n",
    "- At the end of the notebook, you can easily clean up and delete the environment to free storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nesi2km313s",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Flag to track if we created an environment in this notebook\n",
    "environment_created_by_notebook = False\n",
    "environment_name = None\n",
    "\n",
    "# Check if conda is installed\n",
    "try:\n",
    "    result = subprocess.run(['conda', '--version'], capture_output=True, text=True, check=True)\n",
    "    conda_available = True\n",
    "    print(f\"✓ Conda detected: {result.stdout.strip()}\")\n",
    "except (subprocess.CalledProcessError, FileNotFoundError):\n",
    "    conda_available = False\n",
    "    print(\"✗ Conda not found - skipping environment management\")\n",
    "    print(\"Packages will be installed in your current Python environment\")\n",
    "\n",
    "if conda_available:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"ENVIRONMENT SETUP OPTIONS\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    choice = input(\"\\nDo you want to:\\n  [1] Create a NEW conda environment (recommended)\\n  [2] Use an EXISTING environment\\n  [3] Skip and use current environment\\n\\nEnter choice (1/2/3): \").strip()\n",
    "    \n",
    "    if choice == \"1\":\n",
    "        # Create new environment\n",
    "        env_name = input(\"\\nEnter name for new environment (default: f5_tts_mlx): \").strip()\n",
    "        if not env_name:\n",
    "            env_name = \"f5_tts_mlx\"\n",
    "        \n",
    "        print(f\"\\n→ Creating conda environment: {env_name}\")\n",
    "        print(\"  This may take a few minutes...\")\n",
    "        \n",
    "        try:\n",
    "            # Create environment with Python 3.10\n",
    "            subprocess.run(['conda', 'create', '-n', env_name, 'python=3.10', '-y'],\n",
    "                           check=True, capture_output=True)\n",
    "            \n",
    "            environment_created_by_notebook = True\n",
    "            environment_name = env_name\n",
    "            \n",
    "            print(f\"✓ Environment '{env_name}' created successfully!\")\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(\"IMPORTANT: Restart your Jupyter kernel and select the new environment:\")\n",
    "            print(f\"  Kernel → Change Kernel → {env_name}\")\n",
    "            print(f\"{'='*60}\\n\")\n",
    "        \n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"✗ Failed to create environment: {e}\")\n",
    "            print(\"Continuing with current environment...\")\n",
    "    \n",
    "    elif choice == \"2\":\n",
    "        # Use existing environment\n",
    "        env_name = input(\"\\nEnter name of existing environment: \").strip()\n",
    "        if env_name:\n",
    "            environment_name = env_name\n",
    "            print(f\"\\n✓ Using existing environment: {env_name}\")\n",
    "            print(f\"\\n{'='*60}\")\n",
    "            print(\"IMPORTANT: Make sure your kernel is using this environment:\")\n",
    "            print(f\"  Kernel → Change Kernel → {env_name}\")\n",
    "            print(f\"{'='*60}\\n\")\n",
    "        else:\n",
    "            print(\"✗ No environment name provided - using current environment\")\n",
    "    \n",
    "    else:\n",
    "        print(\"\\n✓ Using current environment\")\n",
    "\n",
    "print(\"\\nYou can now proceed with the rest of the notebook.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "install-header",
   "metadata": {},
   "source": [
    "## 1) Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core TTS + I/O deps\n",
    "!pip install f5-tts-mlx soundfile pypdf ebooklib pydub\n",
    "\n",
    "# Advanced PDF extraction\n",
    "!pip install \"unstructured[local-inference]\"\n",
    "!pip install \"detectron2@git+https://github.com/facebookresearch/detectron2.git@v0.6#egg=detectron2\"\n",
    "\n",
    "# Note: ffmpeg should be installed on your system for MP3 encoding\n",
    "# macOS: brew install ffmpeg\n",
    "# Linux: sudo apt-get install ffmpeg\n",
    "# Windows: Download from https://ffmpeg.org/\n",
    "\n",
    "# Silence overly chatty logs\n",
    "import logging\n",
    "logging.getLogger(\"unstructured\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"pypdf\").setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config-header",
   "metadata": {},
   "source": [
    "## 2) Configuration and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "config",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "import platform\n",
    "\n",
    "# --- Output directory setup ---\n",
    "OUTPUT_DIR = Path(\".\")  # Use current directory (same as notebook location)\n",
    "print(f\"Output directory: {OUTPUT_DIR.resolve()}\")\n",
    "\n",
    "# --- Device detection ---\n",
    "# F5-TTS-MLX is optimized for Apple Silicon but can fall back to CPU\n",
    "SYSTEM = platform.system()\n",
    "MACHINE = platform.machine()\n",
    "\n",
    "if SYSTEM == \"Darwin\" and MACHINE == \"arm64\":\n",
    "    DEVICE = \"mlx\"  # Apple Silicon (M1/M2/M3/M4)\n",
    "    print(f\"Detected Apple Silicon ({MACHINE})\")\n",
    "    print(\"Using MLX framework for optimal performance\")\n",
    "else:\n",
    "    DEVICE = \"cpu\"  # Fallback to CPU\n",
    "    print(f\"Detected {SYSTEM} on {MACHINE}\")\n",
    "    print(\"MLX is optimized for Apple Silicon. Performance may be limited on this platform.\")\n",
    "    print(\"Using CPU fallback mode\")\n",
    "\n",
    "print(f\"\\nDevice mode: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpers-header",
   "metadata": {},
   "source": [
    "## 3) Helper Functions (PDF/EPUB extraction & TTS synthesis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "helpers",
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport soundfile as sf\nimport re, io, zipfile, tempfile, os\nfrom pathlib import Path\nfrom typing import List, Tuple, Dict, Union, Optional\nfrom functools import lru_cache\n\nfrom pypdf import PdfReader\nfrom ebooklib import epub\nfrom pydub import AudioSegment\n\n# Imports for advanced PDF extraction\nfrom unstructured.partition.auto import partition\n\n# Import F5-TTS-MLX\ntry:\n    from f5_tts_mlx.generate import generate\n    F5_AVAILABLE = True\nexcept ImportError as e:\n    F5_AVAILABLE = False\n    print(f\"Warning: F5-TTS-MLX not available: {e}\")\n    print(\"Please install with: pip install f5-tts-mlx\")\n\n# Sentence-ish split; keeps chunks small\nSPLIT_PATTERN = r\"[.?!]\\s+|[\\n]{2,}\"\nSPLIT_PATTERN_CAP = r\"([.?!]\\s+|[\\n]{2,})\"\n\n\n# --- PDF Extraction using unstructured.io ---\ndef extract_text_from_pdf(file_like: io.BytesIO, pages: Optional[List[int]] = None) -> List[Dict]:\n    \"\"\"Extract text from PDF using unstructured.io with layout analysis.\n\n    Args:\n        file_like: PDF file as BytesIO object\n        pages: Optional list of page numbers to extract (1-indexed). None = all pages.\n\n    Returns:\n        List of text elements with metadata\n    \"\"\"\n    print(\"Parsing PDF with layout analysis (strategy='hi_res')...\")\n    try:\n        partitioned_elements = partition(file=file_like, strategy=\"hi_res\", content_type=\"application/pdf\", include_page_breaks=True)\n        print(f\"Unstructured 'hi_res' returned {len(partitioned_elements)} raw elements.\")\n    except Exception as e:\n        print(f\"Unstructured 'hi_res' strategy failed: {e}. Falling back to 'fast'.\")\n        try:\n            file_like.seek(0)\n            partitioned_elements = partition(file=file_like, strategy=\"fast\", content_type=\"application/pdf\", include_page_breaks=True)\n            print(f\"Unstructured 'fast' returned {len(partitioned_elements)} raw elements.\")\n        except Exception as e2:\n            print(f\"Unstructured 'fast' strategy also failed: {e2}.\")\n            return [{\"text\": \"Error: Unstructured parsing failed.\", \"metadata\": {\"page_number\": 1, \"points\": None}}]\n\n    # Convert pages to set for faster lookup\n    pages_set = set(pages) if pages else None\n\n    element_list = []\n    current_page = 1\n    print(\"\\n--- Processing elements (checking for points) ---\")\n\n    for i, el in enumerate(partitioned_elements):\n        meta_dict = el.metadata.to_dict()\n\n        page_num_meta = meta_dict.get(\"page_number\")\n        if page_num_meta is not None:\n             current_page = page_num_meta\n\n        # Skip if page filtering is enabled and current page not in list\n        if pages_set and current_page not in pages_set:\n            continue\n\n        # Extract coordinate points if available\n        points = None\n        coords_meta = meta_dict.get(\"coordinates\")\n        if coords_meta:\n            points = coords_meta.get(\"points\")\n\n        location_data = {\n            \"page_number\": current_page,\n            \"points\": points\n        }\n\n        element_text = str(el).strip()\n        if element_text:\n            element_list.append({\n                \"text\": element_text,\n                \"metadata\": location_data\n            })\n\n    print(\"--- Finished processing elements ---\")\n    if pages_set:\n        print(f\"Unstructured: Found {len(element_list)} text elements from pages {sorted(pages_set)}.\")\n    else:\n        print(f\"Unstructured: Found {len(element_list)} text elements from all pages.\")\n    if not element_list:\n         return [{\"text\": \"Warning: Unstructured found no text elements.\", \"metadata\": {\"page_number\": 1, \"points\": None}}]\n    return element_list\n\n\n# --- EPUB Extraction ---\ndef extract_chapters_from_epub(file_like: io.BytesIO):\n    bk = epub.read_epub(file_like)\n    chapters = []\n    for item in bk.get_items_of_type(epub.ITEM_DOCUMENT):\n        if getattr(item, \"is_nav\", False): continue\n        html = item.get_content().decode(\"utf-8\", errors=\"ignore\")\n        text = re.sub(r\"<(script|style).*?>.*?</\\1>\", \" \", html, flags=re.S|re.I)\n        text = re.sub(r\"<br\\s*/?>\", \"\\n\", text, flags=re.I)\n        text = re.sub(r\"</p>|</div>|</h\\d>\", \"\\n\\n\", text, flags=re.I)\n        text = re.sub(r\"<[^>]+>\", \" \", text)\n        text = re.sub(r\"[ \\t]+\", \" \", text)\n        text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text).strip()\n        if text:\n            title = Path(item.file_name).stem\n            first = text.splitlines()[0] if text else \"\"; m = re.match(r\"(?i)\\s*(chapter|part|book)\\b[^\\n]{0,80}\", first)\n            if m: title = first[:60]\n            chapters.append((title, text))\n    if not chapters:\n        blobs = [];\n        for item in bk.get_items_of_type(epub.ITEM_DOCUMENT):\n             if getattr(item, \"is_nav\", False): continue\n             blobs.append(item.get_content().decode(\"utf-8\", errors=\"ignore\"))\n        html = \" \".join(blobs)\n        text = re.sub(r\"<(script|style).*?>.*?</\\1>\", \" \", html, flags=re.S|re.I)\n        text = re.sub(r\"<br\\s*/?>\", \"\\n\", text, flags=re.I)\n        text = re.sub(r\"</p>|</div>|</h\\d>\", \"\\n\\n\", text, flags=re.I)\n        text = re.sub(r\"<[^>]+>\", \" \", text)\n        text = re.sub(r\"[ \\t]+\", \" \", text)\n        text = re.sub(r\"\\n{3,}\", \"\\n\\n\", text).strip()\n        if text: chapters = [(\"Chapter 1\", text)]\n    return chapters\n\ndef safe_name(s: str) -> str:\n    s = re.sub(r\"[^\\w\\-]+\", \"_\", s).strip(\"_\"); return s or \"chapter\"\n\ndef _synthesize_sentence_f5(\n    sentence: str,\n    ref_audio: Optional[str] = None,\n    ref_text: Optional[str] = None,\n    sample_rate: int = 24000\n) -> np.ndarray:\n    \"\"\"\n    Synthesize a single sentence using F5-TTS-MLX.\n\n    Args:\n        sentence: Text to synthesize\n        ref_audio: Optional path to reference audio for voice cloning\n        ref_text: Optional transcription of reference audio\n        sample_rate: Output sample rate (default: 24000 Hz)\n\n    Returns:\n        Audio samples as numpy array\n    \"\"\"\n    if not F5_AVAILABLE:\n        raise RuntimeError(\"F5-TTS-MLX is not available. Please install with: pip install f5-tts-mlx\")\n\n    try:\n        # Create a temporary file for output\n        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp_file:\n            temp_path = tmp_file.name\n\n        try:\n            # Generate audio using F5-TTS-MLX with correct parameter names\n            generate(\n                generation_text=sentence,\n                ref_audio_path=ref_audio,\n                ref_audio_text=ref_text,\n                output_path=temp_path,\n                estimate_duration=True  # Auto-estimate duration for natural speech\n            )\n\n            # Read the generated audio file\n            audio, sr = sf.read(temp_path)\n\n            # Ensure we have float32 mono audio\n            if audio.ndim > 1:\n                audio = audio[:, 0]  # Take first channel if stereo\n            audio = audio.astype(np.float32)\n\n            return audio\n\n        finally:\n            # Clean up temp file\n            if os.path.exists(temp_path):\n                os.unlink(temp_path)\n\n    except Exception as e:\n        print(f\"Error in F5-TTS-MLX synthesis: {e}\")\n        print(f\"Sentence that failed: {sentence[:50]}...\")\n        # Return silence on error\n        return np.zeros((sample_rate // 10,), dtype=np.float32)\n\ndef split_sentences_keep_delim(text: str) -> List[str]:\n    parts = re.split(SPLIT_PATTERN_CAP, text); sents = []\n    for i in range(0, len(parts), 2):\n        chunk = (parts[i] or \"\").strip(); sep = parts[i+1] if i+1 < len(parts) else \"\"\n        if not chunk: continue\n        if sep and not sep.isspace(): chunk = (chunk + \" \" + sep.strip()).strip()\n        sents.append(chunk)\n    return sents\n\n# --- Synthesizer ---\ndef synth_text_to_wav_and_manifest(\n    text_or_elements: Union[str, List[Dict]],\n    ref_audio: Optional[str] = None,\n    ref_text: Optional[str] = None,\n    device: str = DEVICE) -> Tuple[bytes, Dict]:\n    \"\"\"\n    Synthesize text to WAV audio with timeline manifest.\n\n    Args:\n        text_or_elements: Either a string or list of text elements with metadata\n        ref_audio: Optional path to reference audio for voice cloning\n        ref_text: Optional transcription of reference audio\n        device: Device to use (mlx or cpu)\n\n    Returns:\n        Tuple of (wav_bytes, manifest_dict)\n    \"\"\"\n    sr = 24000  # F5-TTS-MLX uses 24kHz\n\n    if isinstance(text_or_elements, str):\n        elements = [{\"text\": text_or_elements, \"metadata\": {\"page_number\": 1, \"points\": None}}]\n    else:\n        elements = text_or_elements\n\n    pcm_all = []; timeline = []; t = 0.0; sentence_index = 0\n    print(f\"Synthesizing {len(elements)} text elements...\")\n\n    for element in elements:\n        element_text = element.get(\"text\", \"\")\n        element_meta = element.get(\"metadata\", {})\n\n        sentences = split_sentences_keep_delim(element_text)\n\n        for sent in sentences:\n            if not sent: continue\n\n            pcm = _synthesize_sentence_f5(\n                sent,\n                ref_audio=ref_audio,\n                ref_text=ref_text,\n                sample_rate=sr\n            )\n\n            dur = pcm.shape[0] / sr\n            timeline.append({\n                \"i\": sentence_index,\n                \"start\": round(t, 3),\n                \"end\": round(t + dur, 3),\n                \"text\": sent.strip(),\n                \"location\": element_meta\n            })\n            pcm_all.append(pcm); t += dur; sentence_index += 1\n\n    pcm_cat = np.concatenate(pcm_all, axis=0) if pcm_all else np.zeros((sr//10,), dtype=np.float32)\n    buf = io.BytesIO(); sf.write(buf, pcm_cat, sr, format='WAV'); buf.seek(0)\n    manifest = {\"audioUrl\": \"\", \"sentences\": timeline}\n    return buf.read(), manifest\n\ndef wav_to_mp3_bytes(wav_bytes: bytes, bitrate=\"128k\") -> bytes:\n    audio = AudioSegment.from_file(io.BytesIO(wav_bytes), format=\"wav\"); out = io.BytesIO()\n    audio.export(out, format=\"mp3\", bitrate=bitrate); out.seek(0); return out.read()\n"
  },
  {
   "cell_type": "markdown",
   "id": "synthesis-header",
   "metadata": {},
   "source": [
    "## 4) High-Level Synthesis Wrappers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthesis-wrappers",
   "metadata": {},
   "outputs": [],
   "source": "def synth_string(text: str,\n                 ref_audio: Optional[str] = None,\n                 ref_text: Optional[str] = None,\n                 out_format=\"wav\",\n                 device=None,\n                 basename=\"f5_text\",\n                 output_dir=None):\n    \"\"\"\n    Synthesize a text string to audio.\n    \n    Args:\n        text: Text to synthesize\n        ref_audio: Optional path to reference audio for voice cloning (mono, 24kHz, 5-10s WAV)\n        ref_text: Optional transcription of reference audio\n        out_format: Output format (\"wav\" or \"mp3\")\n        device: Device to use (None = auto-detect)\n        basename: Base name for output files\n        output_dir: Output directory (None = use OUTPUT_DIR)\n    \n    Returns:\n        Tuple of (audio_path, manifest_path)\n    \"\"\"\n    device = device or DEVICE\n    output_dir = Path(output_dir) if output_dir else OUTPUT_DIR\n\n    elements = [{\n        \"text\": text,\n        \"metadata\": {\"page_number\": 1, \"source\": \"string\", \"coordinates\": None}\n    }]\n\n    wav_bytes, manifest = synth_text_to_wav_and_manifest(\n        elements,\n        ref_audio=ref_audio,\n        ref_text=ref_text,\n        device=device\n    )\n\n    out_base = output_dir / basename\n\n    if out_format.lower() == \"mp3\":\n        mp3 = wav_to_mp3_bytes(wav_bytes)\n        audio_path = str(out_base) + \".mp3\"\n        with open(audio_path, \"wb\") as f: f.write(mp3)\n    else:\n        audio_path = str(out_base) + \".wav\"\n        with open(audio_path, \"wb\") as f: f.write(wav_bytes)\n\n    manifest_path = str(out_base) + \"_manifest.json\"\n    manifest[\"audioUrl\"] = Path(audio_path).name\n    with open(manifest_path, \"w\", encoding=\"utf-8\") as f:\n        import json; json.dump(manifest, f, ensure_ascii=False, indent=2)\n\n    return audio_path, manifest_path\n\ndef synth_pdf(file_path_or_bytes,\n              ref_audio: Optional[str] = None,\n              ref_text: Optional[str] = None,\n              out_format=\"wav\",\n              device=None,\n              basename=None,\n              output_dir=None,\n              pages=None):\n    \"\"\"\n    Synthesize a PDF document to audio with timeline manifest.\n    \n    Args:\n        file_path_or_bytes: Path to PDF file or BytesIO object\n        ref_audio: Optional path to reference audio for voice cloning (mono, 24kHz, 5-10s WAV)\n        ref_text: Optional transcription of reference audio\n        out_format: Output format (\"wav\" or \"mp3\")\n        device: Device to use (None = auto-detect)\n        basename: Base name for output files (None = use PDF filename)\n        output_dir: Output directory (None = use OUTPUT_DIR)\n        pages: Optional list of page numbers to synthesize (1-indexed). None = all pages.\n               Examples: [1, 2, 3] or [5] or None\n    \n    Returns:\n        Tuple of (audio_path, manifest_path)\n    \"\"\"\n    device = device or DEVICE\n    output_dir = Path(output_dir) if output_dir else OUTPUT_DIR\n    \n    if isinstance(file_path_or_bytes, (str, Path)):\n        with open(file_path_or_bytes, \"rb\") as fh:\n            pdf_bytes = io.BytesIO(fh.read())\n        stem = Path(file_path_or_bytes).stem\n    else:\n        pdf_bytes = file_path_or_bytes\n        stem = basename or \"document\"\n\n    elements = extract_text_from_pdf(pdf_bytes, pages=pages)\n\n    wav_bytes, manifest = synth_text_to_wav_and_manifest(\n        elements,\n        ref_audio=ref_audio,\n        ref_text=ref_text,\n        device=device\n    )\n\n    out_base = output_dir / f\"{(basename or stem)}_tts\"\n\n    if out_format.lower() == \"mp3\":\n        mp3 = wav_to_mp3_bytes(wav_bytes)\n        audio_path = str(out_base) + \".mp3\"\n        with open(audio_path, \"wb\") as f: f.write(mp3)\n    else:\n        audio_path = str(out_base) + \".wav\"\n        with open(audio_path, \"wb\") as f: f.write(wav_bytes)\n\n    manifest_path = str(out_base) + \"_manifest.json\"\n    manifest[\"audioUrl\"] = Path(audio_path).name\n    with open(manifest_path, \"w\", encoding=\"utf-8\") as f:\n        import json; json.dump(manifest, f, ensure_ascii=False, indent=2)\n\n    return audio_path, manifest_path\n\ndef synth_epub(file_path_or_bytes,\n               ref_audio: Optional[str] = None,\n               ref_text: Optional[str] = None,\n               per_chapter_format=\"wav\",\n               device=None,\n               zip_name=None,\n               output_dir=None):\n    \"\"\"\n    Synthesize an EPUB book to audio, creating one audio file per chapter in a ZIP.\n    \n    Args:\n        file_path_or_bytes: Path to EPUB file or BytesIO object\n        ref_audio: Optional path to reference audio for voice cloning (mono, 24kHz, 5-10s WAV)\n        ref_text: Optional transcription of reference audio\n        per_chapter_format: Format for chapter audio files (\"wav\" or \"mp3\")\n        device: Device to use (None = auto-detect)\n        zip_name: Name for output ZIP file (None = use EPUB filename + '_chapters')\n        output_dir: Output directory (None = use OUTPUT_DIR)\n    \n    Returns:\n        Path to ZIP file containing chapter audio and manifest files\n    \"\"\"\n    device = device or DEVICE\n    output_dir = Path(output_dir) if output_dir else OUTPUT_DIR\n\n    if isinstance(file_path_or_bytes, (str, Path)):\n        with open(file_path_or_bytes, \"rb\") as fh:\n            epub_bytes = io.BytesIO(fh.read())\n        stem = Path(file_path_or_bytes).stem\n    else:\n        epub_bytes = file_path_or_bytes\n        stem = \"book\"\n\n    chapters = extract_chapters_from_epub(epub_bytes)\n    assert chapters, \"No chapters detected in EPUB.\"\n\n    zip_buf = io.BytesIO()\n    with zipfile.ZipFile(zip_buf, \"w\", zipfile.ZIP_DEFLATED) as zf:\n        for idx, (title, body) in enumerate(chapters, 1):\n            name = f\"{idx:02d}_{safe_name(title)[:40]}\"\n\n            chapter_elements = [{\n                \"text\": body,\n                \"metadata\": {\n                    \"chapter_index\": idx,\n                    \"chapter_title\": title,\n                    \"page_number\": 1,\n                    \"coordinates\": None\n                }\n            }]\n\n            wav_bytes, manifest = synth_text_to_wav_and_manifest(\n                chapter_elements,\n                ref_audio=ref_audio,\n                ref_text=ref_text,\n                device=device\n            )\n\n            if per_chapter_format.lower() == \"mp3\":\n                data = wav_to_mp3_bytes(wav_bytes)\n                audio_name = f\"{name}.mp3\"\n                zf.writestr(audio_name, data)\n            else:\n                audio_name = f\"{name}.wav\"\n                zf.writestr(audio_name, wav_bytes)\n\n            manifest[\"audioUrl\"] = audio_name\n            import json\n            zf.writestr(f\"{name}_manifest.json\", json.dumps(manifest, ensure_ascii=False, indent=2))\n\n    zip_buf.seek(0)\n    zpath = str(output_dir / f\"{zip_name or (stem + '_chapters')}.zip\")\n    with open(zpath, \"wb\") as f:\n        f.write(zip_buf.read())\n    return zpath\n"
  },
  {
   "cell_type": "markdown",
   "id": "usage-header",
   "metadata": {},
   "source": [
    "## Usage Examples\n",
    "\n",
    "Below are examples for synthesizing text, PDFs, and EPUBs locally with F5-TTS-MLX.\n",
    "\n",
    "**Voice Cloning (Optional)**:\n",
    "- You can provide a reference audio file (`ref_audio`) and its transcription (`ref_text`) to clone a voice\n",
    "- Reference audio should be: mono, 24kHz sample rate, 5-10 seconds duration, WAV format\n",
    "- If you don't provide reference audio, F5-TTS will use its default voice"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-a-header",
   "metadata": {},
   "source": [
    "### A) String → Audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example-string",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "FORMAT = \"mp3\"  # \"wav\" or \"mp3\"\n",
    "BASENAME = \"f5_text\"\n",
    "\n",
    "# Optional: Voice cloning (leave as None to use default voice)\n",
    "REF_AUDIO = None  # Path to reference audio file (e.g., \"reference.wav\")\n",
    "REF_TEXT = None   # Transcription of reference audio\n",
    "\n",
    "# Text to synthesize\n",
    "TEXT = \"\"\"Paste or type your text here.\n",
    "It can be multiple paragraphs. Chapters aren't needed for this path.\n",
    "\"\"\"\n",
    "\n",
    "# Run synthesis\n",
    "audio_path, manifest_path = synth_string(\n",
    "    TEXT, \n",
    "    ref_audio=REF_AUDIO,\n",
    "    ref_text=REF_TEXT,\n",
    "    out_format=FORMAT,\n",
    "    basename=BASENAME\n",
    ")\n",
    "\n",
    "print(f\"Audio saved to: {audio_path}\")\n",
    "print(f\"Manifest saved to: {manifest_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "example-b-header",
   "metadata": {},
   "source": [
    "### B) PDF → Audio (with manifest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example-pdf",
   "metadata": {},
   "outputs": [],
   "source": "# Configuration\nFORMAT = \"mp3\"  # \"wav\" or \"mp3\"\n\n# Optional: Voice cloning (leave as None to use default voice)\nREF_AUDIO = None  # Path to reference audio file (e.g., \"reference.wav\")\nREF_TEXT = None   # Transcription of reference audio\n\n# Specify the path to your PDF file (relative to notebook location)\nPDF_PATH = \"document.pdf\"  # Change this to your PDF filename\n\n# Page selection (optional)\n# None = all pages (default)\n# [1, 2, 3] = only pages 1, 2, and 3\n# [5] = only page 5\n# [1, 3, 5, 7] = only odd pages 1, 3, 5, 7\nPAGES = None  # Change to a list like [1, 2, 3] to select specific pages\n\n# Run synthesis\naudio_path, manifest_path = synth_pdf(\n    PDF_PATH,\n    ref_audio=REF_AUDIO,\n    ref_text=REF_TEXT,\n    out_format=FORMAT,\n    pages=PAGES\n)\n\nprint(f\"Audio saved to: {audio_path}\")\nprint(f\"Manifest saved to: {manifest_path}\")\n"
  },
  {
   "cell_type": "markdown",
   "id": "example-c-header",
   "metadata": {},
   "source": [
    "### C) EPUB → ZIP (Per-Chapter Audio + Manifests)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "example-epub",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CHAPTER_FORMAT = \"wav\"  # \"wav\" or \"mp3\"\n",
    "ZIP_NAME = \"\"  # Optional: custom name for the output ZIP file\n",
    "\n",
    "# Optional: Voice cloning (leave as None to use default voice)\n",
    "REF_AUDIO = None  # Path to reference audio file (e.g., \"reference.wav\")\n",
    "REF_TEXT = None   # Transcription of reference audio\n",
    "\n",
    "# Specify the path to your EPUB file (relative to notebook location)\n",
    "EPUB_PATH = \"book.epub\"  # Change this to your EPUB filename\n",
    "\n",
    "# Run synthesis\n",
    "zip_path = synth_epub(\n",
    "    EPUB_PATH,\n",
    "    ref_audio=REF_AUDIO,\n",
    "    ref_text=REF_TEXT,\n",
    "    per_chapter_format=CHAPTER_FORMAT,\n",
    "    zip_name=(ZIP_NAME or None)\n",
    ")\n",
    "\n",
    "print(f\"ZIP archive saved to: {zip_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "notes-header",
   "metadata": {},
   "source": [
    "## Notes\n",
    "\n",
    "- **Output Directory**: By default, all outputs are saved to the same directory as the notebook. You can change this by modifying `OUTPUT_DIR` in the Configuration cell.\n",
    "- **Input Files**: Place your PDF/EPUB files in the same directory as the notebook, or provide relative/absolute paths.\n",
    "- **Device Selection**: The notebook will automatically detect Apple Silicon (M1/M2/M3/M4) and use MLX for optimal performance. On other platforms, it will fall back to CPU mode.\n",
    "- **Voice Cloning**: F5-TTS-MLX supports zero-shot voice cloning. Provide a reference audio file (mono, 24kHz, 5-10s WAV) and its transcription to clone a voice.\n",
    "  - To convert audio to the required format: `ffmpeg -i input.wav -ac 1 -ar 24000 -sample_fmt s16 -t 10 output.wav`\n",
    "- **PDF Extraction**: The notebook uses `unstructured.io` for advanced PDF extraction with layout analysis. This may take longer but provides better results.\n",
    "- **Manifest Files**: Each audio output includes a JSON manifest file with sentence-level timing information and metadata.\n",
    "- **Performance**: On Apple Silicon (M4 MacBook Air), generation typically takes ~4 seconds per sentence. Performance scales with the number of CPU cores.\n",
    "- **Error Handling**: The notebook includes CPU fallback for errors. If synthesis fails on a particular sentence, it will insert silence and continue."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "859upsh4e3",
   "metadata": {},
   "source": [
    "## Cleanup: Delete Environment (Optional)\n",
    "\n",
    "**If you created a new environment at the beginning of this notebook**, you can delete it here to free up storage space.\n",
    "\n",
    "⚠️ **Warning**: This will permanently delete the environment and all installed packages!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imcvxhn684f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "# Check if we created an environment in this notebook\n",
    "if 'environment_created_by_notebook' not in globals():\n",
    "    print(\"✗ No environment tracking found\")\n",
    "    print(\"This cell only works if you ran the environment setup cell at the beginning\")\n",
    "elif not environment_created_by_notebook:\n",
    "    print(\"✗ No environment was created by this notebook\")\n",
    "    print(\"You can only delete environments that were created in this session\")\n",
    "else:\n",
    "    print(f\"Environment '{environment_name}' was created by this notebook\")\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(\"DELETE ENVIRONMENT\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    confirm = input(f\"\\nAre you sure you want to DELETE '{environment_name}'?\\nType 'yes' to confirm: \").strip().lower()\n",
    "    \n",
    "    if confirm == 'yes':\n",
    "        print(f\"\\n→ Deleting environment '{environment_name}'...\")\n",
    "        print(\"  This may take a moment...\")\n",
    "        \n",
    "        try:\n",
    "            subprocess.run(['conda', 'env', 'remove', '-n', environment_name, '-y'],\n",
    "                           check=True, capture_output=True)\n",
    "            print(f\"✓ Environment '{environment_name}' deleted successfully!\")\n",
    "            print(\"  Storage space has been freed.\")\n",
    "            \n",
    "            # Reset the flag\n",
    "            environment_created_by_notebook = False\n",
    "            environment_name = None\n",
    "        \n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"✗ Failed to delete environment: {e}\")\n",
    "            print(\"You may need to delete it manually with: conda env remove -n {environment_name}\")\n",
    "    else:\n",
    "        print(\"\\n✗ Deletion cancelled - environment preserved\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bmn3980qb",
   "source": "## Manage Model Caches (Optional)\n\n**View and delete cached TTS models to free up storage space.**\n\nTTS models are cached in several locations:\n- HuggingFace models: `~/.cache/huggingface/`\n- PyTorch models: `~/.cache/torch/`\n- Pip package cache\n- MLX models (for F5-TTS-MLX)\n\n⚠️ **Warning**: Deleting caches will require re-downloading models next time you run the notebook!",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "25xut7ztqvk",
   "source": "import subprocess\nimport os\nfrom pathlib import Path\n\ndef get_dir_size(path):\n    \"\"\"Calculate total size of a directory in bytes.\"\"\"\n    total = 0\n    try:\n        for entry in os.scandir(path):\n            if entry.is_file(follow_symlinks=False):\n                total += entry.stat().st_size\n            elif entry.is_dir(follow_symlinks=False):\n                total += get_dir_size(entry.path)\n    except (PermissionError, FileNotFoundError):\n        pass\n    return total\n\ndef format_size(bytes_size):\n    \"\"\"Format bytes to human-readable size.\"\"\"\n    for unit in ['B', 'KB', 'MB', 'GB']:\n        if bytes_size < 1024.0:\n            return f\"{bytes_size:.2f} {unit}\"\n        bytes_size /= 1024.0\n    return f\"{bytes_size:.2f} TB\"\n\n# Define cache locations\nhome = Path.home()\ncache_locations = {\n    \"HuggingFace Models\": home / \".cache\" / \"huggingface\",\n    \"PyTorch Models\": home / \".cache\" / \"torch\",\n    \"Pip Cache\": home / \".cache\" / \"pip\",\n}\n\nprint(\"=\"*60)\nprint(\"MODEL CACHE INFORMATION\")\nprint(\"=\"*60)\n\ntotal_cache_size = 0\nexisting_caches = {}\n\nfor name, path in cache_locations.items():\n    if path.exists():\n        size = get_dir_size(path)\n        total_cache_size += size\n        existing_caches[name] = (path, size)\n        print(f\"\\n{name}:\")\n        print(f\"  Location: {path}\")\n        print(f\"  Size: {format_size(size)}\")\n    else:\n        print(f\"\\n{name}: Not found\")\n\nprint(f\"\\n{'='*60}\")\nprint(f\"Total cache size: {format_size(total_cache_size)}\")\nprint(f\"{'='*60}\")\n\nif existing_caches:\n    print(\"\\n⚠️  You can delete these caches to free up storage space.\")\n    print(\"Note: Models will be re-downloaded when needed.\")\n    \n    choice = input(\"\\nDo you want to delete caches? (yes/no): \").strip().lower()\n    \n    if choice == 'yes':\n        print(\"\\nSelect which caches to delete:\")\n        print(\"  [1] HuggingFace only\")\n        print(\"  [2] PyTorch only\")\n        print(\"  [3] Pip only\")\n        print(\"  [4] All caches\")\n        print(\"  [5] Cancel\")\n        \n        delete_choice = input(\"\\nEnter choice (1-5): \").strip()\n        \n        to_delete = []\n        if delete_choice == \"1\" and \"HuggingFace Models\" in existing_caches:\n            to_delete = [(\"HuggingFace Models\", existing_caches[\"HuggingFace Models\"])]\n        elif delete_choice == \"2\" and \"PyTorch Models\" in existing_caches:\n            to_delete = [(\"PyTorch Models\", existing_caches[\"PyTorch Models\"])]\n        elif delete_choice == \"3\" and \"Pip Cache\" in existing_caches:\n            to_delete = [(\"Pip Cache\", existing_caches[\"Pip Cache\"])]\n        elif delete_choice == \"4\":\n            to_delete = list(existing_caches.items())\n        \n        if to_delete:\n            confirm = input(f\"\\n⚠️  Really delete {len(to_delete)} cache(s)? Type 'DELETE' to confirm: \").strip()\n            \n            if confirm == \"DELETE\":\n                freed_space = 0\n                for name, (path, size) in to_delete:\n                    print(f\"\\n→ Deleting {name}...\")\n                    try:\n                        import shutil\n                        shutil.rmtree(path)\n                        freed_space += size\n                        print(f\"✓ Deleted {name} ({format_size(size)})\")\n                    except Exception as e:\n                        print(f\"✗ Failed to delete {name}: {e}\")\n                \n                print(f\"\\n{'='*60}\")\n                print(f\"✓ Total space freed: {format_size(freed_space)}\")\n                print(f\"{'='*60}\")\n            else:\n                print(\"\\n✗ Deletion cancelled\")\n        else:\n            print(\"\\n✗ Invalid choice or cache not found\")\n    else:\n        print(\"\\n✓ Caches preserved\")\nelse:\n    print(\"\\n✓ No caches found\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}